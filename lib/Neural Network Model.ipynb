{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../output/feature_extraction.csv',index=False)\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set predictors\n",
    "from keras.utils import to_categorical\n",
    "Y = to_categorical(data[:,6006])\n",
    "Y = Y[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data[:,:6006],Y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 6006)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 6006)              24024     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 96)                576672    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 96)                384       \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 16)                1552      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 22)                374       \n",
      "=================================================================\n",
      "Total params: 603,006\n",
      "Trainable params: 590,802\n",
      "Non-trainable params: 12,204\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, Flatten, Input,Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "input_shape = [6006] \n",
    "input_layer = Input(input_shape)\n",
    "x = BatchNormalization()(input_layer) \n",
    "x = Dense(96,activation='relu',kernel_initializer=initializers.glorot_normal(seed=None))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dense(16,activation='relu',kernel_initializer=initializers.glorot_normal(seed=None))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(22,activation='softmax',kernel_initializer=initializers.glorot_normal(seed=None))(x) \n",
    "model = Model(input_layer,output_layer)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 1s 587us/step - loss: 3.3418 - accuracy: 0.0636\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 3.0517 - accuracy: 0.0908\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 2.9649 - accuracy: 0.0980\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 2.8688 - accuracy: 0.1124\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 2.7420 - accuracy: 0.1464\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 2.6294 - accuracy: 0.1540\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 2.5351 - accuracy: 0.1848\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 2.4992 - accuracy: 0.1688\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 2.4182 - accuracy: 0.1896\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 2.3275 - accuracy: 0.2164\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 2.2968 - accuracy: 0.2256\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 2.2294 - accuracy: 0.2372\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 2.1957 - accuracy: 0.2392\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 2.1570 - accuracy: 0.2500\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 2.1733 - accuracy: 0.2364\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 2.1287 - accuracy: 0.2556\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 2.0861 - accuracy: 0.2620\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 2.0753 - accuracy: 0.2720\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 2.0598 - accuracy: 0.2924\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 2.0650 - accuracy: 0.2728\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 2.0172 - accuracy: 0.2832\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 2.0178 - accuracy: 0.2916\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.9643 - accuracy: 0.28920s - loss: 1.9295 - accuracy\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.9719 - accuracy: 0.2896\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.9771 - accuracy: 0.2972\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.9504 - accuracy: 0.3052\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.9465 - accuracy: 0.2888\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.9179 - accuracy: 0.3156\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.8904 - accuracy: 0.3276\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.8765 - accuracy: 0.3344\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.8893 - accuracy: 0.3204\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.8739 - accuracy: 0.3256\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.8581 - accuracy: 0.3216\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.8315 - accuracy: 0.3380\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.8291 - accuracy: 0.3392\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.7920 - accuracy: 0.34 - 0s 162us/step - loss: 1.7857 - accuracy: 0.3472\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.8002 - accuracy: 0.3528\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.8427 - accuracy: 0.3224\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.7797 - accuracy: 0.3508\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.7751 - accuracy: 0.3588\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.7985 - accuracy: 0.3520\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.7514 - accuracy: 0.3576\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.7639 - accuracy: 0.3428\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.7677 - accuracy: 0.3444\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.7281 - accuracy: 0.3616\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.7080 - accuracy: 0.3528\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.7087 - accuracy: 0.3636\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.7076 - accuracy: 0.3608\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.6909 - accuracy: 0.3764\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.7275 - accuracy: 0.3776\n",
      "lr=0.01, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 548us/step - loss: 1.6537 - accuracy: 0.3852\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.6272 - accuracy: 0.3948\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.6262 - accuracy: 0.3924\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.6329 - accuracy: 0.3944\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.6173 - accuracy: 0.4056\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.6248 - accuracy: 0.3952\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.6237 - accuracy: 0.3992\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.5974 - accuracy: 0.3956\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.5866 - accuracy: 0.4052\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.6056 - accuracy: 0.4000\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.5758 - accuracy: 0.4108\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.6086 - accuracy: 0.4040\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.5632 - accuracy: 0.4060\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.5673 - accuracy: 0.4104\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.5777 - accuracy: 0.4188\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.5590 - accuracy: 0.4224\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.5453 - accuracy: 0.4128\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.5650 - accuracy: 0.4216\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.5763 - accuracy: 0.40760s - loss: 1.5760 - accuracy: 0.\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.5264 - accuracy: 0.4160\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.5563 - accuracy: 0.4120\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.5070 - accuracy: 0.4244\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 194us/step - loss: 1.5676 - accuracy: 0.4208\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.5439 - accuracy: 0.4200\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.5375 - accuracy: 0.4184\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.5397 - accuracy: 0.4140\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.5331 - accuracy: 0.4184\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.5269 - accuracy: 0.4244\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.5108 - accuracy: 0.4236\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.4998 - accuracy: 0.4472\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.5271 - accuracy: 0.4308\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.5263 - accuracy: 0.4116\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.5122 - accuracy: 0.4132\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.5413 - accuracy: 0.4228\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.5118 - accuracy: 0.4216\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.5110 - accuracy: 0.4264\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.5157 - accuracy: 0.4276\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.5169 - accuracy: 0.4348\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.5288 - accuracy: 0.4344\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.5367 - accuracy: 0.4144\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.4974 - accuracy: 0.4256\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.5155 - accuracy: 0.4212\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.4747 - accuracy: 0.4352\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.4948 - accuracy: 0.4424\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.4940 - accuracy: 0.4340\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.4697 - accuracy: 0.4596\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.4957 - accuracy: 0.4372\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.4894 - accuracy: 0.4292\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.4929 - accuracy: 0.4228\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.4755 - accuracy: 0.4360\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.4515 - accuracy: 0.4588\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.4459 - accuracy: 0.4628\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.4681 - accuracy: 0.4580\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.4731 - accuracy: 0.4404\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.4798 - accuracy: 0.4364\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.4660 - accuracy: 0.4548\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.4752 - accuracy: 0.4500\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.4489 - accuracy: 0.4440\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.4484 - accuracy: 0.4368\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.4774 - accuracy: 0.4348\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.4785 - accuracy: 0.44560s - loss: 1.4532 - accuracy: 0.45\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.4536 - accuracy: 0.4464\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.4231 - accuracy: 0.4588\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.4542 - accuracy: 0.4540\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.4795 - accuracy: 0.4460\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.4563 - accuracy: 0.4484\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.4233 - accuracy: 0.4524\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.4479 - accuracy: 0.4588\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.4392 - accuracy: 0.4444\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.4319 - accuracy: 0.4652\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.4563 - accuracy: 0.4532\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.4134 - accuracy: 0.4680\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.4589 - accuracy: 0.4556\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 1s 215us/step - loss: 1.4299 - accuracy: 0.4668\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.4604 - accuracy: 0.4352\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.4613 - accuracy: 0.4328\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.4533 - accuracy: 0.4448\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.4284 - accuracy: 0.4464\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.4480 - accuracy: 0.4496\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.4208 - accuracy: 0.4552\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.4362 - accuracy: 0.4520\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.4015 - accuracy: 0.4692\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.4132 - accuracy: 0.4640\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.3748 - accuracy: 0.4696\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.4052 - accuracy: 0.4660\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.4298 - accuracy: 0.4536\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.4419 - accuracy: 0.4468\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.4122 - accuracy: 0.4596\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.4133 - accuracy: 0.4652\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 1s 215us/step - loss: 1.3942 - accuracy: 0.4664\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.4031 - accuracy: 0.4728\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.4149 - accuracy: 0.4592\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3856 - accuracy: 0.4652\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.4072 - accuracy: 0.4660\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.4094 - accuracy: 0.4772\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.3947 - accuracy: 0.4580\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.4346 - accuracy: 0.4532\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.3796 - accuracy: 0.4764\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.4010 - accuracy: 0.4644\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.4040 - accuracy: 0.4640\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.3998 - accuracy: 0.4592\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.3913 - accuracy: 0.4648\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.4012 - accuracy: 0.4732\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3827 - accuracy: 0.4656\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.3893 - accuracy: 0.4756\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.3808 - accuracy: 0.4784\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3937 - accuracy: 0.4636\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3715 - accuracy: 0.4704\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3804 - accuracy: 0.4616\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.3962 - accuracy: 0.4632\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.3802 - accuracy: 0.4804\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.3525 - accuracy: 0.4768\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3881 - accuracy: 0.4636\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3627 - accuracy: 0.4764\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3416 - accuracy: 0.4932\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3539 - accuracy: 0.4872\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.3649 - accuracy: 0.4724\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3647 - accuracy: 0.4808\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.3851 - accuracy: 0.4784\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3397 - accuracy: 0.4868\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.3686 - accuracy: 0.4792\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.3667 - accuracy: 0.4716\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.3344 - accuracy: 0.4880\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.3508 - accuracy: 0.4732\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.3578 - accuracy: 0.4720\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.3746 - accuracy: 0.4840\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3624 - accuracy: 0.4712\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.3613 - accuracy: 0.4936\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 0s 194us/step - loss: 1.3424 - accuracy: 0.4764\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3596 - accuracy: 0.4856\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.3136 - accuracy: 0.4984\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.3374 - accuracy: 0.4872\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.3355 - accuracy: 0.4892\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3428 - accuracy: 0.4788\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.3442 - accuracy: 0.4832\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3636 - accuracy: 0.4728\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3202 - accuracy: 0.5072\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.3407 - accuracy: 0.4836\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.3147 - accuracy: 0.4968\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.3248 - accuracy: 0.4984\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.3340 - accuracy: 0.4868\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.3344 - accuracy: 0.4844\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.3272 - accuracy: 0.4952\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.3206 - accuracy: 0.4896\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.3785 - accuracy: 0.4748\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.3290 - accuracy: 0.4788\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.3061 - accuracy: 0.5008\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3307 - accuracy: 0.5024\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.3109 - accuracy: 0.5032\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.3354 - accuracy: 0.5020\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3253 - accuracy: 0.5048\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.3166 - accuracy: 0.4940\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.3167 - accuracy: 0.50360s - loss: 1.3396 - accuracy: 0.\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.3265 - accuracy: 0.4992\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.3180 - accuracy: 0.5092\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2933 - accuracy: 0.5064\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.3007 - accuracy: 0.5148\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 194us/step - loss: 1.3093 - accuracy: 0.4944\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.2928 - accuracy: 0.5012\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2993 - accuracy: 0.5044\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.3068 - accuracy: 0.5196\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3043 - accuracy: 0.5000\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.2743 - accuracy: 0.5212\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.2702 - accuracy: 0.51160s - loss: 1.2580 - accuracy: 0.\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.3305 - accuracy: 0.4956\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.3134 - accuracy: 0.5048\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2638 - accuracy: 0.5168\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2967 - accuracy: 0.5024\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.3061 - accuracy: 0.5104\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.2702 - accuracy: 0.5188\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2889 - accuracy: 0.4912\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2863 - accuracy: 0.5112\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.3113 - accuracy: 0.4840\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2726 - accuracy: 0.5236\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.2951 - accuracy: 0.5196\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2884 - accuracy: 0.5268\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.2664 - accuracy: 0.5124\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.3072 - accuracy: 0.4904\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.2973 - accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2613 - accuracy: 0.5156\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.2791 - accuracy: 0.5184\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.2833 - accuracy: 0.5136\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.2673 - accuracy: 0.5168\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.2528 - accuracy: 0.5180\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.2653 - accuracy: 0.5196\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.2917 - accuracy: 0.5048\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.2542 - accuracy: 0.5172\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.2581 - accuracy: 0.5076\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.2552 - accuracy: 0.5160\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.2446 - accuracy: 0.5280\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.2670 - accuracy: 0.5164\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2642 - accuracy: 0.5160\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.2620 - accuracy: 0.5260\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2789 - accuracy: 0.5216\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.2706 - accuracy: 0.5136\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.2837 - accuracy: 0.5196\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2740 - accuracy: 0.5160\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2331 - accuracy: 0.5292\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2753 - accuracy: 0.5200\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2311 - accuracy: 0.5196\n",
      "lr=0.001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 546us/step - loss: 1.2758 - accuracy: 0.5224\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2789 - accuracy: 0.5112\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.2684 - accuracy: 0.5320\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.2636 - accuracy: 0.5196\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2682 - accuracy: 0.5228\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2515 - accuracy: 0.5180\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.2742 - accuracy: 0.5196\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2680 - accuracy: 0.5208\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.2704 - accuracy: 0.5172\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2558 - accuracy: 0.5284\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2383 - accuracy: 0.5380\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.2524 - accuracy: 0.5168\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.2515 - accuracy: 0.5316\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2643 - accuracy: 0.5128\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2337 - accuracy: 0.5420\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2378 - accuracy: 0.5372\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2499 - accuracy: 0.5296\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2382 - accuracy: 0.5284\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2122 - accuracy: 0.5344\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.2447 - accuracy: 0.5408\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2730 - accuracy: 0.5240\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2643 - accuracy: 0.5176\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.2210 - accuracy: 0.5164\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2216 - accuracy: 0.5336\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.2553 - accuracy: 0.5328\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2431 - accuracy: 0.5228\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2852 - accuracy: 0.5212\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2451 - accuracy: 0.5392\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2583 - accuracy: 0.5268\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2343 - accuracy: 0.5340\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2620 - accuracy: 0.5272\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.2305 - accuracy: 0.5348\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2544 - accuracy: 0.5232\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2300 - accuracy: 0.5284\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2383 - accuracy: 0.5336\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 1s 224us/step - loss: 1.2934 - accuracy: 0.5212\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2563 - accuracy: 0.5264\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2615 - accuracy: 0.5240\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.2331 - accuracy: 0.5348\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2212 - accuracy: 0.5340\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2802 - accuracy: 0.5288\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.2380 - accuracy: 0.5268\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2262 - accuracy: 0.5308\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 1s 218us/step - loss: 1.2297 - accuracy: 0.5356\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2339 - accuracy: 0.5300\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.2647 - accuracy: 0.5236\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.2059 - accuracy: 0.5512\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.2250 - accuracy: 0.5312\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2528 - accuracy: 0.5364\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2382 - accuracy: 0.5240\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2537 - accuracy: 0.5324\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2399 - accuracy: 0.5308\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2478 - accuracy: 0.5244\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2471 - accuracy: 0.5356\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.2320 - accuracy: 0.5228\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.2295 - accuracy: 0.5396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.2083 - accuracy: 0.5424\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.2469 - accuracy: 0.5124\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.2315 - accuracy: 0.5332\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.2305 - accuracy: 0.5320\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.2572 - accuracy: 0.5196\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.2099 - accuracy: 0.5316\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.2087 - accuracy: 0.5480\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2268 - accuracy: 0.5280\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.2321 - accuracy: 0.5296\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2441 - accuracy: 0.5236\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.2307 - accuracy: 0.5356\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.2411 - accuracy: 0.5204\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2274 - accuracy: 0.5456\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.2363 - accuracy: 0.5432\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.2491 - accuracy: 0.5432\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2397 - accuracy: 0.5292\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.1970 - accuracy: 0.5564\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 1s 235us/step - loss: 1.2500 - accuracy: 0.5436\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 1s 242us/step - loss: 1.2154 - accuracy: 0.5400\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2554 - accuracy: 0.5368\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.2448 - accuracy: 0.5332\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.2452 - accuracy: 0.5436\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.2231 - accuracy: 0.5340\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.2527 - accuracy: 0.5268\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.2316 - accuracy: 0.5324\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2430 - accuracy: 0.5320\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.2279 - accuracy: 0.5512\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 1s 228us/step - loss: 1.2349 - accuracy: 0.5316\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 1s 242us/step - loss: 1.2295 - accuracy: 0.5420\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 1s 270us/step - loss: 1.2140 - accuracy: 0.5376\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 1s 230us/step - loss: 1.2382 - accuracy: 0.5252\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 1s 228us/step - loss: 1.2432 - accuracy: 0.5288\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.2280 - accuracy: 0.5492\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 1s 228us/step - loss: 1.2196 - accuracy: 0.5436\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2603 - accuracy: 0.5132\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 1s 239us/step - loss: 1.2526 - accuracy: 0.52520s - loss: 1.2443 - accuracy: 0.\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 1s 234us/step - loss: 1.2335 - accuracy: 0.5348\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 1s 232us/step - loss: 1.2462 - accuracy: 0.5296\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 1s 231us/step - loss: 1.2429 - accuracy: 0.5304\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.2126 - accuracy: 0.5512\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 1s 215us/step - loss: 1.2086 - accuracy: 0.5340\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2251 - accuracy: 0.5284\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2534 - accuracy: 0.5144\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2284 - accuracy: 0.5300\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.1824 - accuracy: 0.5448\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2280 - accuracy: 0.5280\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.2293 - accuracy: 0.5336\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2059 - accuracy: 0.5304\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2350 - accuracy: 0.5356\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2386 - accuracy: 0.5312\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2532 - accuracy: 0.5280\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.2296 - accuracy: 0.5304\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2223 - accuracy: 0.5464\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2726 - accuracy: 0.5236\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2652 - accuracy: 0.5188\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2322 - accuracy: 0.5352\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2465 - accuracy: 0.5296\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2257 - accuracy: 0.5264\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2289 - accuracy: 0.5372\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2182 - accuracy: 0.5384\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2477 - accuracy: 0.5192\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2759 - accuracy: 0.5044\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2315 - accuracy: 0.5448\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2094 - accuracy: 0.5360\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2098 - accuracy: 0.5344\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2156 - accuracy: 0.5376\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.1964 - accuracy: 0.5316\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2388 - accuracy: 0.5372\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.2632 - accuracy: 0.5196\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.1881 - accuracy: 0.5592\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2274 - accuracy: 0.5360\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2269 - accuracy: 0.5456\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2083 - accuracy: 0.5364\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2165 - accuracy: 0.5456\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2593 - accuracy: 0.5172\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2084 - accuracy: 0.5516\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2173 - accuracy: 0.5260\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.2535 - accuracy: 0.5332\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2040 - accuracy: 0.5472\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2282 - accuracy: 0.5368\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 1s 214us/step - loss: 1.2468 - accuracy: 0.5336\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2235 - accuracy: 0.5348\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2098 - accuracy: 0.5400\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2287 - accuracy: 0.5500\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2365 - accuracy: 0.5404\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2114 - accuracy: 0.5368\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2191 - accuracy: 0.5284\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2578 - accuracy: 0.5156\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2366 - accuracy: 0.5360\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2248 - accuracy: 0.5288\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2092 - accuracy: 0.5320\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2274 - accuracy: 0.5236\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2336 - accuracy: 0.5392\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.2364 - accuracy: 0.5388\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2646 - accuracy: 0.5228\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2036 - accuracy: 0.5284\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2213 - accuracy: 0.5424\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 1s 214us/step - loss: 1.2248 - accuracy: 0.5392\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2350 - accuracy: 0.5528\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.2507 - accuracy: 0.5248\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2450 - accuracy: 0.5280\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.2542 - accuracy: 0.5156\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2191 - accuracy: 0.5424\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.1886 - accuracy: 0.5560\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2196 - accuracy: 0.5372\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2165 - accuracy: 0.5336\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2175 - accuracy: 0.5436\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.2307 - accuracy: 0.54640s - loss: 1.2373 - accura\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2165 - accuracy: 0.5464\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2289 - accuracy: 0.5168\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2126 - accuracy: 0.5436\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.2544 - accuracy: 0.5272\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.2439 - accuracy: 0.5292\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2278 - accuracy: 0.5360\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2689 - accuracy: 0.5060\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2308 - accuracy: 0.5444\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2231 - accuracy: 0.5356\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2424 - accuracy: 0.5380\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2293 - accuracy: 0.5512\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2555 - accuracy: 0.5208\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 1s 240us/step - loss: 1.1957 - accuracy: 0.5400\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 1s 245us/step - loss: 1.2025 - accuracy: 0.5364\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 1s 259us/step - loss: 1.2185 - accuracy: 0.5376\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 1s 272us/step - loss: 1.2273 - accuracy: 0.5392\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 1s 235us/step - loss: 1.2596 - accuracy: 0.5332\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 1s 226us/step - loss: 1.2378 - accuracy: 0.5224\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2138 - accuracy: 0.5372\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2191 - accuracy: 0.5420\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 1s 227us/step - loss: 1.1953 - accuracy: 0.5524\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 1s 245us/step - loss: 1.2257 - accuracy: 0.5392\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 1s 248us/step - loss: 1.2123 - accuracy: 0.5356\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 1s 214us/step - loss: 1.2260 - accuracy: 0.5356\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2053 - accuracy: 0.5444\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2497 - accuracy: 0.5212\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2260 - accuracy: 0.5340\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2398 - accuracy: 0.5412\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2327 - accuracy: 0.5416\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2332 - accuracy: 0.5324\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2486 - accuracy: 0.5244\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.2185 - accuracy: 0.5404\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.2176 - accuracy: 0.5432\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1994 - accuracy: 0.5452\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1740 - accuracy: 0.5544\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2159 - accuracy: 0.5384\n",
      "lr=0.0001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 599us/step - loss: 1.2198 - accuracy: 0.5476\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.2399 - accuracy: 0.5344\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.1921 - accuracy: 0.5384\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2048 - accuracy: 0.5444\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2178 - accuracy: 0.5400\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2123 - accuracy: 0.5436\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2208 - accuracy: 0.5420\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2230 - accuracy: 0.5388\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2195 - accuracy: 0.5376\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2531 - accuracy: 0.5188\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2128 - accuracy: 0.5300\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2100 - accuracy: 0.5484\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.2567 - accuracy: 0.5440\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2133 - accuracy: 0.5392\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.2345 - accuracy: 0.5404\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2181 - accuracy: 0.5464\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 1s 227us/step - loss: 1.2234 - accuracy: 0.5396\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.2121 - accuracy: 0.5436\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 1s 236us/step - loss: 1.2319 - accuracy: 0.5252\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.2302 - accuracy: 0.54240s - loss: 1.2195 - accuracy: 0.\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.2445 - accuracy: 0.5276\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2269 - accuracy: 0.5452\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2346 - accuracy: 0.5360\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2204 - accuracy: 0.5404\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2604 - accuracy: 0.5212\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2317 - accuracy: 0.5240\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2276 - accuracy: 0.5316\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2090 - accuracy: 0.5488\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2052 - accuracy: 0.5436\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2374 - accuracy: 0.5304\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2314 - accuracy: 0.5360\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2062 - accuracy: 0.55200s - loss: 1.1956 - accuracy: \n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2370 - accuracy: 0.5344\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2208 - accuracy: 0.5336\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2378 - accuracy: 0.5204\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2377 - accuracy: 0.5284\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.2232 - accuracy: 0.5296\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2089 - accuracy: 0.5448\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2229 - accuracy: 0.5380\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2225 - accuracy: 0.5448\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2093 - accuracy: 0.5532\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2236 - accuracy: 0.5320\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2481 - accuracy: 0.5452\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 1s 227us/step - loss: 1.2082 - accuracy: 0.5492\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 1s 227us/step - loss: 1.2072 - accuracy: 0.5280\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.2287 - accuracy: 0.53040s - loss: 1.1916 - accuracy: \n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2254 - accuracy: 0.5412\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2228 - accuracy: 0.5380\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2313 - accuracy: 0.5332\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2091 - accuracy: 0.5376\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.1975 - accuracy: 0.5460\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 1s 233us/step - loss: 1.2280 - accuracy: 0.5320\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 1s 242us/step - loss: 1.2426 - accuracy: 0.5344\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2018 - accuracy: 0.5436\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.1777 - accuracy: 0.5468\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 1s 236us/step - loss: 1.2026 - accuracy: 0.5348\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 1s 227us/step - loss: 1.2258 - accuracy: 0.5360\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 1s 269us/step - loss: 1.2478 - accuracy: 0.5236\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 1s 267us/step - loss: 1.2386 - accuracy: 0.5320\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 1s 238us/step - loss: 1.2139 - accuracy: 0.5452\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 1s 214us/step - loss: 1.2239 - accuracy: 0.5392\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2315 - accuracy: 0.5288\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1767 - accuracy: 0.5528\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2265 - accuracy: 0.5424\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1996 - accuracy: 0.5440\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.2007 - accuracy: 0.5504\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2389 - accuracy: 0.5384\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 1s 262us/step - loss: 1.2307 - accuracy: 0.5308\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2235 - accuracy: 0.5476\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2222 - accuracy: 0.5268\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2332 - accuracy: 0.5400\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2328 - accuracy: 0.5308\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2171 - accuracy: 0.5456\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.2277 - accuracy: 0.5380\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 1s 233us/step - loss: 1.1914 - accuracy: 0.5460\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2156 - accuracy: 0.5416\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2211 - accuracy: 0.5424\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.2359 - accuracy: 0.5352\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.2050 - accuracy: 0.5340\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.2302 - accuracy: 0.5268\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.1999 - accuracy: 0.5316\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2190 - accuracy: 0.5496\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.2490 - accuracy: 0.5252\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.2279 - accuracy: 0.5352\n",
      "Epoch 85/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.1909 - accuracy: 0.5504\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2030 - accuracy: 0.5416\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.1915 - accuracy: 0.5452\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.1971 - accuracy: 0.54640s - loss: 1.1906 - accuracy: \n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 1s 253us/step - loss: 1.2105 - accuracy: 0.5368\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.1777 - accuracy: 0.5548\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.2301 - accuracy: 0.5428\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 1s 218us/step - loss: 1.2234 - accuracy: 0.5348\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.2207 - accuracy: 0.5336\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.2000 - accuracy: 0.5416\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2077 - accuracy: 0.5508\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.2267 - accuracy: 0.5324\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.2379 - accuracy: 0.5404\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 1s 236us/step - loss: 1.1528 - accuracy: 0.5516\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 1s 234us/step - loss: 1.2228 - accuracy: 0.5372\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.2462 - accuracy: 0.5272\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 1s 233us/step - loss: 1.2197 - accuracy: 0.5404\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 1s 237us/step - loss: 1.2071 - accuracy: 0.5284\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.2044 - accuracy: 0.5476\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.1679 - accuracy: 0.5568\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.2162 - accuracy: 0.5376\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.2044 - accuracy: 0.5540\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2187 - accuracy: 0.5464\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.1889 - accuracy: 0.5496\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 1s 222us/step - loss: 1.2553 - accuracy: 0.5140\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2389 - accuracy: 0.5316\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2035 - accuracy: 0.5396\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.2141 - accuracy: 0.5408\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2198 - accuracy: 0.5212\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2154 - accuracy: 0.5452\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2015 - accuracy: 0.5500\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.1955 - accuracy: 0.5340\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2154 - accuracy: 0.5508\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.2048 - accuracy: 0.5292\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2033 - accuracy: 0.5448\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2300 - accuracy: 0.5276\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2094 - accuracy: 0.5416\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2312 - accuracy: 0.5312\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2379 - accuracy: 0.5300\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2323 - accuracy: 0.5288\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2273 - accuracy: 0.5236\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2107 - accuracy: 0.5336\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.2281 - accuracy: 0.5372\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2336 - accuracy: 0.5448\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.2026 - accuracy: 0.5400\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1976 - accuracy: 0.5616\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2393 - accuracy: 0.5356\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2039 - accuracy: 0.5540\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.2258 - accuracy: 0.5492\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 1s 261us/step - loss: 1.1940 - accuracy: 0.5404\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.2165 - accuracy: 0.5320\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2072 - accuracy: 0.5448\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.2264 - accuracy: 0.5332\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2137 - accuracy: 0.5436\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.1995 - accuracy: 0.5564\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2104 - accuracy: 0.5248\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.1737 - accuracy: 0.5536\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2308 - accuracy: 0.5300\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2433 - accuracy: 0.5240\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.2218 - accuracy: 0.5464\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 1s 215us/step - loss: 1.2280 - accuracy: 0.5212\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2099 - accuracy: 0.5460\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 1s 251us/step - loss: 1.2059 - accuracy: 0.5316\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.2635 - accuracy: 0.5172\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.2171 - accuracy: 0.5328\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2283 - accuracy: 0.5340\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2113 - accuracy: 0.5520\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1930 - accuracy: 0.5452\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2100 - accuracy: 0.5512\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2228 - accuracy: 0.5304\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2663 - accuracy: 0.5220\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2205 - accuracy: 0.5280\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2079 - accuracy: 0.5360\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2225 - accuracy: 0.5296\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2054 - accuracy: 0.5416\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2079 - accuracy: 0.5404\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.1841 - accuracy: 0.5512\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.2225 - accuracy: 0.5348\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2246 - accuracy: 0.5344\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2229 - accuracy: 0.5424\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2093 - accuracy: 0.5492\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.1977 - accuracy: 0.5364\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2176 - accuracy: 0.5512\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.2155 - accuracy: 0.5420\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2363 - accuracy: 0.5416\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.2041 - accuracy: 0.5388\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.2076 - accuracy: 0.5372\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2132 - accuracy: 0.5332\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2112 - accuracy: 0.5436\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1964 - accuracy: 0.5404\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2256 - accuracy: 0.5448\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2256 - accuracy: 0.5400\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2218 - accuracy: 0.5324\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2002 - accuracy: 0.5460\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.2216 - accuracy: 0.5456\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2293 - accuracy: 0.5348\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2047 - accuracy: 0.5564\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2290 - accuracy: 0.5396\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.2222 - accuracy: 0.5316\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2035 - accuracy: 0.5428\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.2064 - accuracy: 0.5464\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2172 - accuracy: 0.5416\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.1932 - accuracy: 0.5616\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.2176 - accuracy: 0.5364\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2002 - accuracy: 0.5464\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.2233 - accuracy: 0.5268\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2083 - accuracy: 0.5436\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1952 - accuracy: 0.5500\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.1939 - accuracy: 0.5388\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.2063 - accuracy: 0.5504\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.2144 - accuracy: 0.5392\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 1s 247us/step - loss: 1.2084 - accuracy: 0.5368\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 1s 226us/step - loss: 1.2243 - accuracy: 0.5384\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 1s 237us/step - loss: 1.2242 - accuracy: 0.5416\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.2087 - accuracy: 0.5512\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.2271 - accuracy: 0.5404\n",
      "lr=0.0001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 538us/step - loss: 1.2417 - accuracy: 0.5472\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.2093 - accuracy: 0.5344\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2334 - accuracy: 0.5392\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.2318 - accuracy: 0.5408\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2184 - accuracy: 0.5444\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2443 - accuracy: 0.5368\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1980 - accuracy: 0.5476\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2438 - accuracy: 0.5468\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.2673 - accuracy: 0.5132\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2068 - accuracy: 0.5360\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.1956 - accuracy: 0.5464\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2251 - accuracy: 0.5492\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.2335 - accuracy: 0.5348\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.1926 - accuracy: 0.52960s - loss: 1.1564 - accuracy: 0.\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1902 - accuracy: 0.5588\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1948 - accuracy: 0.5452\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2140 - accuracy: 0.5376\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1973 - accuracy: 0.5424\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2486 - accuracy: 0.5356\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.2523 - accuracy: 0.5316\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1961 - accuracy: 0.5528\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2258 - accuracy: 0.5364\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 194us/step - loss: 1.2264 - accuracy: 0.5452\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.2438 - accuracy: 0.5320\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2033 - accuracy: 0.5548\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2369 - accuracy: 0.5240\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1935 - accuracy: 0.5436\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.1996 - accuracy: 0.5444\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.1975 - accuracy: 0.5592\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2205 - accuracy: 0.5500\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1849 - accuracy: 0.5536\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2309 - accuracy: 0.5220\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.1680 - accuracy: 0.5444\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2475 - accuracy: 0.5244\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2319 - accuracy: 0.5476\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2323 - accuracy: 0.5352\n",
      "Epoch 37/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1870 - accuracy: 0.5488\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.2095 - accuracy: 0.5444\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1681 - accuracy: 0.5440\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.1502 - accuracy: 0.5696\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 1s 255us/step - loss: 1.1967 - accuracy: 0.5416\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.1596 - accuracy: 0.5780\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2021 - accuracy: 0.5420\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1828 - accuracy: 0.5620\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1915 - accuracy: 0.5460\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.1831 - accuracy: 0.5592\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1921 - accuracy: 0.5660\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.2127 - accuracy: 0.5456\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.2122 - accuracy: 0.5320\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1866 - accuracy: 0.5480\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 1s 232us/step - loss: 1.2210 - accuracy: 0.5372\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.2045 - accuracy: 0.5660\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 1s 231us/step - loss: 1.2069 - accuracy: 0.5548\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.1979 - accuracy: 0.5420\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.2163 - accuracy: 0.5516\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1756 - accuracy: 0.5596\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.1773 - accuracy: 0.5584\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2002 - accuracy: 0.5516\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2067 - accuracy: 0.5544\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1843 - accuracy: 0.5648\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1591 - accuracy: 0.5612\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 1s 222us/step - loss: 1.1563 - accuracy: 0.5708\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.1453 - accuracy: 0.5728\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 1s 222us/step - loss: 1.2075 - accuracy: 0.5364\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.1887 - accuracy: 0.55400s - loss: 1.2475 - accu\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2229 - accuracy: 0.5536\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.1808 - accuracy: 0.5516\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.1601 - accuracy: 0.5684\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.2114 - accuracy: 0.5464\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2022 - accuracy: 0.5484\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2044 - accuracy: 0.5500\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.1708 - accuracy: 0.5584\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1807 - accuracy: 0.5548\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1302 - accuracy: 0.5780\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1888 - accuracy: 0.5552\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1805 - accuracy: 0.5596\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1639 - accuracy: 0.5612\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.1832 - accuracy: 0.5444\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1477 - accuracy: 0.5644\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.1908 - accuracy: 0.5600\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 1s 256us/step - loss: 1.1586 - accuracy: 0.5772\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 1s 270us/step - loss: 1.1580 - accuracy: 0.5584\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.1976 - accuracy: 0.5556\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1609 - accuracy: 0.5540\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1907 - accuracy: 0.5616\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.1260 - accuracy: 0.5768\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1517 - accuracy: 0.5744\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1850 - accuracy: 0.5628\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1730 - accuracy: 0.5640\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1376 - accuracy: 0.5692\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.1628 - accuracy: 0.5648\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.1669 - accuracy: 0.5616\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 1s 222us/step - loss: 1.1600 - accuracy: 0.5660\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.1536 - accuracy: 0.5784\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1289 - accuracy: 0.5692\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1513 - accuracy: 0.5652\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1610 - accuracy: 0.5716\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1497 - accuracy: 0.5616\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1433 - accuracy: 0.5700\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1453 - accuracy: 0.5700\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1704 - accuracy: 0.5608\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1406 - accuracy: 0.5764\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.1628 - accuracy: 0.54680s - loss: 1.1407 - accuracy: \n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1213 - accuracy: 0.5664\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1455 - accuracy: 0.5652\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1356 - accuracy: 0.5756\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1558 - accuracy: 0.5780\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1628 - accuracy: 0.5656\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.1697 - accuracy: 0.5576\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.1431 - accuracy: 0.5660\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 1s 231us/step - loss: 1.1522 - accuracy: 0.5836\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1491 - accuracy: 0.5672\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.1362 - accuracy: 0.5792\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1204 - accuracy: 0.5756\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.1496 - accuracy: 0.5708\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1312 - accuracy: 0.57440s - loss: 1.1102 - accuracy: \n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.1286 - accuracy: 0.5752\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.1427 - accuracy: 0.5716\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1490 - accuracy: 0.5648\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1233 - accuracy: 0.5700\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 1s 232us/step - loss: 1.1623 - accuracy: 0.5740\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 1s 214us/step - loss: 1.1746 - accuracy: 0.5636\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.1603 - accuracy: 0.5772\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.1137 - accuracy: 0.5744\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.1663 - accuracy: 0.5632\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1464 - accuracy: 0.5744\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1223 - accuracy: 0.5812\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.1539 - accuracy: 0.5696\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.1413 - accuracy: 0.5732\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1052 - accuracy: 0.5904\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1105 - accuracy: 0.5788\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1119 - accuracy: 0.5868\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.1218 - accuracy: 0.5868\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1399 - accuracy: 0.5688\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.1522 - accuracy: 0.5812\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1589 - accuracy: 0.5756\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1398 - accuracy: 0.5696\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.1802 - accuracy: 0.56160s - loss: 1.1413 - accuracy\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1024 - accuracy: 0.5868\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1687 - accuracy: 0.5608\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.1515 - accuracy: 0.5640\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.1440 - accuracy: 0.5872\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.1325 - accuracy: 0.5724\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1433 - accuracy: 0.5788\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.0857 - accuracy: 0.5824\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.1630 - accuracy: 0.5676\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1167 - accuracy: 0.5864\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.1013 - accuracy: 0.5856\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 194us/step - loss: 1.1341 - accuracy: 0.5804\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1309 - accuracy: 0.5648\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1072 - accuracy: 0.5896\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1031 - accuracy: 0.5912\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1094 - accuracy: 0.5776\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1065 - accuracy: 0.5836\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.1161 - accuracy: 0.58120s - loss: 1.1357 - accuracy: \n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1219 - accuracy: 0.5764\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.1147 - accuracy: 0.5852\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.1105 - accuracy: 0.5848\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1144 - accuracy: 0.5952\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1243 - accuracy: 0.5660\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1135 - accuracy: 0.5932\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.0873 - accuracy: 0.5848\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1339 - accuracy: 0.5720\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.1467 - accuracy: 0.5844\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.0913 - accuracy: 0.5924\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.1279 - accuracy: 0.5892\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.0966 - accuracy: 0.5940\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1323 - accuracy: 0.5712\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.0953 - accuracy: 0.5844\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1082 - accuracy: 0.5936\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1244 - accuracy: 0.5808\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1156 - accuracy: 0.5784\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.0860 - accuracy: 0.6032\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1043 - accuracy: 0.5704\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1033 - accuracy: 0.5848\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.0856 - accuracy: 0.5948\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.1168 - accuracy: 0.5960\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1326 - accuracy: 0.5664\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.0976 - accuracy: 0.5816\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1244 - accuracy: 0.5924\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.1487 - accuracy: 0.5700\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 1s 237us/step - loss: 1.0984 - accuracy: 0.5920\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 1s 260us/step - loss: 1.1168 - accuracy: 0.5900\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 1s 254us/step - loss: 1.1050 - accuracy: 0.6052\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 1s 258us/step - loss: 1.0967 - accuracy: 0.5896\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 1s 261us/step - loss: 1.1323 - accuracy: 0.5848\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 1s 232us/step - loss: 1.0626 - accuracy: 0.6076\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0909 - accuracy: 0.5968\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.1167 - accuracy: 0.5880\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0851 - accuracy: 0.5872\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.1161 - accuracy: 0.5816\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 1s 222us/step - loss: 1.0805 - accuracy: 0.5952\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.1087 - accuracy: 0.5864\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.0925 - accuracy: 0.5908\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.1060 - accuracy: 0.5876\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.0839 - accuracy: 0.6092\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.1248 - accuracy: 0.5860\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.1050 - accuracy: 0.5808\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.1144 - accuracy: 0.5880\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.0965 - accuracy: 0.5828\n",
      "lr=0.001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 598us/step - loss: 1.1284 - accuracy: 0.5752\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.1298 - accuracy: 0.5840\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0847 - accuracy: 0.5912\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0759 - accuracy: 0.5996\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1103 - accuracy: 0.5876\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1468 - accuracy: 0.5800\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.1202 - accuracy: 0.5992\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1247 - accuracy: 0.5764\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1050 - accuracy: 0.5968\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1057 - accuracy: 0.5864\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0905 - accuracy: 0.5892\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0978 - accuracy: 0.5984\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0806 - accuracy: 0.5964\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0983 - accuracy: 0.6056\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0789 - accuracy: 0.5936\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0957 - accuracy: 0.5968\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0624 - accuracy: 0.5952\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 1s 227us/step - loss: 1.0788 - accuracy: 0.6036\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.0884 - accuracy: 0.5996\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.0976 - accuracy: 0.5928\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0711 - accuracy: 0.5992\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0973 - accuracy: 0.5928\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0950 - accuracy: 0.5960\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.0818 - accuracy: 0.5928\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.0641 - accuracy: 0.6132\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0741 - accuracy: 0.6032\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0819 - accuracy: 0.6000\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.1330 - accuracy: 0.5944\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.0563 - accuracy: 0.6112\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.0876 - accuracy: 0.6008\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.0727 - accuracy: 0.5972\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0692 - accuracy: 0.5936\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0868 - accuracy: 0.6000\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0880 - accuracy: 0.5964\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.0700 - accuracy: 0.5832\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.0628 - accuracy: 0.6084\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0545 - accuracy: 0.6100\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.1050 - accuracy: 0.5884\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.0704 - accuracy: 0.6020\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 1s 224us/step - loss: 1.1042 - accuracy: 0.5872\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.0604 - accuracy: 0.5944\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.0496 - accuracy: 0.6192\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.1183 - accuracy: 0.5916\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.0866 - accuracy: 0.6000\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0581 - accuracy: 0.6060\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.1736 - accuracy: 0.5848\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1173 - accuracy: 0.5796\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.1145 - accuracy: 0.5808\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0619 - accuracy: 0.6136\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.1116 - accuracy: 0.5928\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0883 - accuracy: 0.5840\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0598 - accuracy: 0.6076\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0776 - accuracy: 0.5952\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.0436 - accuracy: 0.6144\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.0808 - accuracy: 0.6100\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.1147 - accuracy: 0.5884\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 1s 218us/step - loss: 1.0624 - accuracy: 0.6080\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.0529 - accuracy: 0.6084\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.1274 - accuracy: 0.5896\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 1s 247us/step - loss: 1.1024 - accuracy: 0.5876\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 1s 226us/step - loss: 1.0576 - accuracy: 0.6072\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.0803 - accuracy: 0.5976\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.0436 - accuracy: 0.6092\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.0897 - accuracy: 0.5964\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 218us/step - loss: 1.0637 - accuracy: 0.6024\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 1s 218us/step - loss: 1.0653 - accuracy: 0.5880\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 1s 238us/step - loss: 1.1208 - accuracy: 0.5872\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.0924 - accuracy: 0.5900\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.0488 - accuracy: 0.6168\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.0862 - accuracy: 0.6064\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 1s 227us/step - loss: 1.0729 - accuracy: 0.5976\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 1s 233us/step - loss: 1.1037 - accuracy: 0.5956\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 1s 224us/step - loss: 1.0740 - accuracy: 0.6152\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 1s 239us/step - loss: 1.0672 - accuracy: 0.6044\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0700 - accuracy: 0.5960\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0917 - accuracy: 0.5892\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0795 - accuracy: 0.5908\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0479 - accuracy: 0.6224\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0815 - accuracy: 0.6036\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0966 - accuracy: 0.5956\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0648 - accuracy: 0.6080\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0551 - accuracy: 0.6144\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.0660 - accuracy: 0.6052\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0553 - accuracy: 0.5980\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0714 - accuracy: 0.5984\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0961 - accuracy: 0.5844\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0545 - accuracy: 0.6144\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.0421 - accuracy: 0.6064\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.0604 - accuracy: 0.5948\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.0573 - accuracy: 0.6056\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0626 - accuracy: 0.5992\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 1s 233us/step - loss: 1.1031 - accuracy: 0.5892\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.0943 - accuracy: 0.5960\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.0574 - accuracy: 0.5988\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0893 - accuracy: 0.6052\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0842 - accuracy: 0.6000\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.0925 - accuracy: 0.6064\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.0829 - accuracy: 0.5888\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.0536 - accuracy: 0.6104\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.0676 - accuracy: 0.5904\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.0742 - accuracy: 0.6148\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0385 - accuracy: 0.6048\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0795 - accuracy: 0.5868\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.1270 - accuracy: 0.5960\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0930 - accuracy: 0.5964\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0806 - accuracy: 0.6104\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0704 - accuracy: 0.5968\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0460 - accuracy: 0.6188\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0738 - accuracy: 0.6016\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.0581 - accuracy: 0.6008\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 1s 233us/step - loss: 1.1060 - accuracy: 0.5840\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 1s 242us/step - loss: 1.0336 - accuracy: 0.6168\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 1s 235us/step - loss: 1.0567 - accuracy: 0.6084\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0620 - accuracy: 0.6160\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0668 - accuracy: 0.5984\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.0937 - accuracy: 0.5924\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.0660 - accuracy: 0.5980\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.0468 - accuracy: 0.6252\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.1024 - accuracy: 0.5916\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.0520 - accuracy: 0.6116\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.0041 - accuracy: 0.6220\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0422 - accuracy: 0.6160\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0440 - accuracy: 0.6016\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0384 - accuracy: 0.6032\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0680 - accuracy: 0.5972\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0636 - accuracy: 0.5936\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0549 - accuracy: 0.6168\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.1253 - accuracy: 0.5884\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0523 - accuracy: 0.6104\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0543 - accuracy: 0.6128\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.1239 - accuracy: 0.5908\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0560 - accuracy: 0.5972\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0710 - accuracy: 0.6036\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0769 - accuracy: 0.5976\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0852 - accuracy: 0.5976\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0847 - accuracy: 0.5984\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0496 - accuracy: 0.6052\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0483 - accuracy: 0.6172\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0572 - accuracy: 0.6116\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0697 - accuracy: 0.6084\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0746 - accuracy: 0.5820\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0586 - accuracy: 0.6072\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0578 - accuracy: 0.5968\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0968 - accuracy: 0.5880\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0725 - accuracy: 0.5968\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0460 - accuracy: 0.6160\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0653 - accuracy: 0.6008\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0673 - accuracy: 0.5996\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 1s 221us/step - loss: 1.0743 - accuracy: 0.5948\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 1s 227us/step - loss: 1.0493 - accuracy: 0.6168\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0379 - accuracy: 0.6232\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0491 - accuracy: 0.6164\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0589 - accuracy: 0.6160\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0403 - accuracy: 0.6100\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0699 - accuracy: 0.6072\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0404 - accuracy: 0.6140\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.0648 - accuracy: 0.6044\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0533 - accuracy: 0.6108\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0597 - accuracy: 0.6152\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0706 - accuracy: 0.6084\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0460 - accuracy: 0.6048\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0467 - accuracy: 0.6076\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0755 - accuracy: 0.6112\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1013 - accuracy: 0.5848\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0586 - accuracy: 0.6128\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0500 - accuracy: 0.6132\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0731 - accuracy: 0.6088\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0903 - accuracy: 0.5976\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0664 - accuracy: 0.6012\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.1095 - accuracy: 0.5936\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0643 - accuracy: 0.6104\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0473 - accuracy: 0.6112\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.0538 - accuracy: 0.6152\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0453 - accuracy: 0.6116\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0843 - accuracy: 0.5924\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0920 - accuracy: 0.5864\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0721 - accuracy: 0.6044\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0609 - accuracy: 0.61040s - loss: 1.1471 - accura\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0488 - accuracy: 0.6112\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 1s 214us/step - loss: 1.0732 - accuracy: 0.6060\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.0447 - accuracy: 0.6120\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0339 - accuracy: 0.6060\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0820 - accuracy: 0.5968\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0476 - accuracy: 0.6152\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0683 - accuracy: 0.6172\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0533 - accuracy: 0.6088\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0524 - accuracy: 0.6072\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0546 - accuracy: 0.6192\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0597 - accuracy: 0.6016\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0725 - accuracy: 0.6092\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0812 - accuracy: 0.5936\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0142 - accuracy: 0.6132\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0467 - accuracy: 0.6056\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.0816 - accuracy: 0.5972\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.0549 - accuracy: 0.6036\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.0584 - accuracy: 0.6016\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0614 - accuracy: 0.6060\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0923 - accuracy: 0.5984\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0608 - accuracy: 0.6072\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.0597 - accuracy: 0.6052\n",
      "lr=0.0001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 594us/step - loss: 1.0767 - accuracy: 0.5960\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.0859 - accuracy: 0.5952\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 1s 261us/step - loss: 1.0693 - accuracy: 0.6076\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.0939 - accuracy: 0.5916\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0474 - accuracy: 0.6088\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 1s 218us/step - loss: 1.0842 - accuracy: 0.6052\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.1018 - accuracy: 0.5948\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.0680 - accuracy: 0.5996\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 1s 250us/step - loss: 1.0578 - accuracy: 0.6108\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 1s 243us/step - loss: 1.0274 - accuracy: 0.6156\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 1s 244us/step - loss: 1.0835 - accuracy: 0.5964\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 1s 258us/step - loss: 1.0688 - accuracy: 0.6004\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 1s 240us/step - loss: 1.0731 - accuracy: 0.6040\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 1s 216us/step - loss: 1.0776 - accuracy: 0.6132\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0554 - accuracy: 0.6040\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0240 - accuracy: 0.6256\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0718 - accuracy: 0.6084\n",
      "Epoch 18/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.0659 - accuracy: 0.6008\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0728 - accuracy: 0.6040\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.0159 - accuracy: 0.6136\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0959 - accuracy: 0.5908\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0582 - accuracy: 0.6008\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0674 - accuracy: 0.6020\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0700 - accuracy: 0.5996\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0531 - accuracy: 0.5908\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0746 - accuracy: 0.5968\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0536 - accuracy: 0.5988\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.0133 - accuracy: 0.6204\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.1052 - accuracy: 0.5896\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 1s 226us/step - loss: 1.0282 - accuracy: 0.6224\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0542 - accuracy: 0.5984\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0538 - accuracy: 0.6192\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.1222 - accuracy: 0.6004\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0523 - accuracy: 0.6008\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0564 - accuracy: 0.6076\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.0512 - accuracy: 0.6176\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.0715 - accuracy: 0.6092\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 1s 228us/step - loss: 1.0420 - accuracy: 0.6156\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 1s 229us/step - loss: 1.0275 - accuracy: 0.6256\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.0495 - accuracy: 0.6120\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0516 - accuracy: 0.6000\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0477 - accuracy: 0.6036\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0532 - accuracy: 0.6080\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0398 - accuracy: 0.6088\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0220 - accuracy: 0.6212\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0340 - accuracy: 0.6292\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0658 - accuracy: 0.6176\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0389 - accuracy: 0.6096\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0701 - accuracy: 0.6004\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0536 - accuracy: 0.6080\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0522 - accuracy: 0.6100\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0223 - accuracy: 0.6228\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0629 - accuracy: 0.6172\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0722 - accuracy: 0.6016\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0692 - accuracy: 0.6132\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0456 - accuracy: 0.6000\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0480 - accuracy: 0.6064\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 1s 218us/step - loss: 1.0337 - accuracy: 0.6036\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.0763 - accuracy: 0.6068\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0436 - accuracy: 0.6080\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0278 - accuracy: 0.6148\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0679 - accuracy: 0.6140\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0459 - accuracy: 0.6068\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0888 - accuracy: 0.5896\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0720 - accuracy: 0.6088\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0494 - accuracy: 0.6168\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0704 - accuracy: 0.6032\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0544 - accuracy: 0.6192\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0810 - accuracy: 0.6072\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0459 - accuracy: 0.6256\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0442 - accuracy: 0.6076\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.1044 - accuracy: 0.6008\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0801 - accuracy: 0.5960\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0853 - accuracy: 0.6104\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0760 - accuracy: 0.6000\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0535 - accuracy: 0.6164\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.1246 - accuracy: 0.5828\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0432 - accuracy: 0.6236\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0635 - accuracy: 0.6080\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0685 - accuracy: 0.5996\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0719 - accuracy: 0.6036\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.1364 - accuracy: 0.5876\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.1188 - accuracy: 0.5868\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.0707 - accuracy: 0.6072\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0532 - accuracy: 0.6104\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0515 - accuracy: 0.5996\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0523 - accuracy: 0.6128\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0108 - accuracy: 0.6228\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.0373 - accuracy: 0.6160\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.0520 - accuracy: 0.6120\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 1s 209us/step - loss: 1.0824 - accuracy: 0.6024\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0891 - accuracy: 0.5932\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.0550 - accuracy: 0.6068\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0757 - accuracy: 0.6000\n",
      "Epoch 95/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0808 - accuracy: 0.5952\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0611 - accuracy: 0.6008\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0709 - accuracy: 0.6056\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0364 - accuracy: 0.6160\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0222 - accuracy: 0.6144\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0616 - accuracy: 0.6156\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0746 - accuracy: 0.6140\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.1050 - accuracy: 0.5944\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0769 - accuracy: 0.6064\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0636 - accuracy: 0.5992\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0675 - accuracy: 0.6096\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.0799 - accuracy: 0.5996\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0371 - accuracy: 0.6068\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0812 - accuracy: 0.6068\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0889 - accuracy: 0.5928\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0931 - accuracy: 0.5936\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0782 - accuracy: 0.6140\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0646 - accuracy: 0.6068\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0480 - accuracy: 0.6168\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0571 - accuracy: 0.6120\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0433 - accuracy: 0.6188\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0831 - accuracy: 0.5944\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 1s 200us/step - loss: 1.0700 - accuracy: 0.6020\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0756 - accuracy: 0.5964\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0478 - accuracy: 0.6160\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 1s 219us/step - loss: 1.0573 - accuracy: 0.6080\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.0723 - accuracy: 0.6060\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0994 - accuracy: 0.6072\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0552 - accuracy: 0.6028\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0920 - accuracy: 0.5996\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0580 - accuracy: 0.6096\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0834 - accuracy: 0.5988\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0125 - accuracy: 0.6228\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0745 - accuracy: 0.6120\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 1s 239us/step - loss: 1.0814 - accuracy: 0.5932\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 1s 223us/step - loss: 1.0713 - accuracy: 0.6020\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 1s 245us/step - loss: 1.0567 - accuracy: 0.6120\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 1s 257us/step - loss: 1.0547 - accuracy: 0.6088\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 1s 238us/step - loss: 1.0955 - accuracy: 0.5952\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0689 - accuracy: 0.6156\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0477 - accuracy: 0.6124\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0648 - accuracy: 0.6060\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0657 - accuracy: 0.5916\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0419 - accuracy: 0.6204\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0161 - accuracy: 0.6300\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0366 - accuracy: 0.6040\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0557 - accuracy: 0.6072\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0736 - accuracy: 0.6096\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0384 - accuracy: 0.6248\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.0594 - accuracy: 0.6024\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0640 - accuracy: 0.6236\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0572 - accuracy: 0.6124\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0515 - accuracy: 0.6016\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0805 - accuracy: 0.6004\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.1151 - accuracy: 0.5856\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.0430 - accuracy: 0.6140\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.0438 - accuracy: 0.6072\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0599 - accuracy: 0.6032\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.1194 - accuracy: 0.5888\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0828 - accuracy: 0.6016\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0683 - accuracy: 0.6008\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0389 - accuracy: 0.6148\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0720 - accuracy: 0.6056\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0462 - accuracy: 0.6016\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0712 - accuracy: 0.5984\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0591 - accuracy: 0.6116\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0511 - accuracy: 0.6164\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0280 - accuracy: 0.6224\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0835 - accuracy: 0.5980\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0781 - accuracy: 0.5984\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0891 - accuracy: 0.5916\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 1s 211us/step - loss: 1.0667 - accuracy: 0.6000\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0353 - accuracy: 0.6108\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0617 - accuracy: 0.6120\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0817 - accuracy: 0.5904\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.0986 - accuracy: 0.5964\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0526 - accuracy: 0.6064\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0237 - accuracy: 0.6240\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.0712 - accuracy: 0.6080\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0439 - accuracy: 0.6252\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0459 - accuracy: 0.6072\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 194us/step - loss: 1.0669 - accuracy: 0.6136\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.0443 - accuracy: 0.6152\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.0377 - accuracy: 0.6104\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.0427 - accuracy: 0.6128\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.0776 - accuracy: 0.5932\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 1s 206us/step - loss: 1.0624 - accuracy: 0.5972\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.0727 - accuracy: 0.6012\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.0824 - accuracy: 0.5960\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.0672 - accuracy: 0.5952\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.0679 - accuracy: 0.5924\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.0647 - accuracy: 0.6048\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.0833 - accuracy: 0.5992\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.0594 - accuracy: 0.6144\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.0294 - accuracy: 0.6148\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.1148 - accuracy: 0.5888\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.0547 - accuracy: 0.6036\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.0408 - accuracy: 0.6172\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 0s 194us/step - loss: 1.0618 - accuracy: 0.6020\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.0549 - accuracy: 0.6100\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.0585 - accuracy: 0.6180\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.0630 - accuracy: 0.6096\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0792 - accuracy: 0.6140\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 1s 215us/step - loss: 1.1030 - accuracy: 0.5916\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 1s 217us/step - loss: 1.0635 - accuracy: 0.5912\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 1s 213us/step - loss: 1.0796 - accuracy: 0.6080\n",
      "lr=0.0001, train complete\n",
      "--- 677.694993019104 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "start_time = time.time()\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.01),metrics=['accuracy'])\n",
    "model.fit(points_data, Y,epochs=50, batch_size=300)\n",
    "print('lr=0.01, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation=[X_test,y_test],epochs=200, batch_size=250)\n",
    "print('lr=0.001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation=[X_test,y_test],epochs=200, batch_size=200)\n",
    "print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.00001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation=[X_test,y_test],epochs=200, batch_size=200)\n",
    "print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation=[X_test,y_test],epochs=200, batch_size=250)\n",
    "print('lr=0.001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation=[X_test,y_test],epochs=200, batch_size=200)\n",
    "print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.00001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,validation=[X_test,y_test],epochs=50, batch_size=200)\n",
    "print('lr=0.0001, train complete')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nn.m']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model,'../output/nn.m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
