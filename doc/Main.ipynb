{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Flatten, Input,Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class load():\n",
    "    def load_data(filename):\n",
    "        raw_data = pd.read_csv(filename)\n",
    "        raw_data['filename'] = [str(i).zfill(4)+'.jpg' for i in raw_data['Index'].tolist()]\n",
    "        raw_data['pointsname'] = [str(i).zfill(4)+'.mat' for i in raw_data['Index'].tolist()]\n",
    "        return raw_data\n",
    "\n",
    "    #read points data from mat data \n",
    "    def load_points(points_path,data):\n",
    "        n = data.shape[0] \n",
    "        points_data = np.zeros([n,3003,2])\n",
    "        start_time = time.time()\n",
    "        for i in range(n):\n",
    "            result = loadmat(points_path+data['pointsname'][i])\n",
    "            key = sorted(result.keys())[-1] \n",
    "            points = result[key]\n",
    "            distance_h = []\n",
    "            distance_v = []\n",
    "            for d in range(points.shape[0]-1):\n",
    "                for j in range(d+1,points.shape[0]):\n",
    "                    distance_h.append(abs(points[d,0]-points[j,0]))\n",
    "                    distance_v.append(abs(points[d,1]-points[j,1]))\n",
    "\n",
    "            points_data[i,:,0]=distance_h\n",
    "            points_data[i,:,1]=distance_v\n",
    "        print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "        return points_data.reshape([2500,6006])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.97139000892639 seconds ---\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/luyue_chen/Documents/Fall2019-proj3-sec1--proj3-sec1-grp7-master/data/train_set/'\n",
    "data = load.load_data(path+'label.csv')\n",
    "points_path = '/Users/luyue_chen/Documents/Fall2019-proj3-sec1--proj3-sec1-grp7-master/data/train_set/points/'\n",
    "X = load.load_points(points_path,data)\n",
    "y = data['emotion_idx']\n",
    "train_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1308.2316908836365 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gbmtree_model = GradientBoostingClassifier(max_depth = 1).fit(train_x,train_y) \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.60%\n"
     ]
    }
   ],
   "source": [
    "gbm_predictions = gbmtree_model.predict(test_x)\n",
    "gbm_predictions = [round(value) for value in gbm_predictions]\n",
    "gbm_accuracy = np.mean(test_y==gbm_predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (gbm_accuracy *  100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x149838cc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_predictions = gbmtree_model.predict(test_x) \n",
    "cn = confusion_matrix(test_y,gbm_predictions)\n",
    "sns.heatmap(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.67      0.60        18\n",
      "           2       0.57      0.68      0.62        19\n",
      "           3       0.24      0.32      0.27        25\n",
      "           4       0.35      0.52      0.42        21\n",
      "           5       0.50      0.56      0.53        18\n",
      "           6       0.32      0.27      0.29        26\n",
      "           7       0.37      0.50      0.43        20\n",
      "           8       0.65      0.69      0.67        16\n",
      "           9       0.71      0.48      0.57        25\n",
      "          10       0.35      0.40      0.37        20\n",
      "          11       0.48      0.50      0.49        24\n",
      "          12       0.38      0.28      0.32        32\n",
      "          13       0.12      0.12      0.12        24\n",
      "          14       0.45      0.61      0.52        23\n",
      "          15       0.44      0.32      0.37        22\n",
      "          16       0.62      0.59      0.60        22\n",
      "          17       0.40      0.46      0.43        26\n",
      "          18       0.47      0.32      0.38        22\n",
      "          19       0.32      0.43      0.37        23\n",
      "          20       0.06      0.05      0.05        20\n",
      "          21       0.32      0.18      0.23        34\n",
      "          22       0.20      0.10      0.13        20\n",
      "\n",
      "    accuracy                           0.40       500\n",
      "   macro avg       0.40      0.41      0.40       500\n",
      "weighted avg       0.40      0.40      0.39       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,gbm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbmtree_model_final = GradientBoostingClassifier(max_depth = 1).fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(gbmtree_model_final,'../output/gbm_base.m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)\n",
    "Y = Y[:,1:]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [6006] \n",
    "input_layer = Input(input_shape)\n",
    "x = BatchNormalization()(input_layer) \n",
    "x = Dense(96,activation='relu',kernel_initializer=initializers.glorot_normal(seed=None))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dense(16,activation='relu',kernel_initializer=initializers.glorot_normal(seed=None))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(22,activation='softmax',kernel_initializer=initializers.glorot_normal(seed=None))(x) \n",
    "model = Model(input_layer,output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 1s 537us/step - loss: 3.3434 - accuracy: 0.0652\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 3.0465 - accuracy: 0.0860\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 2.9648 - accuracy: 0.0948\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 2.8679 - accuracy: 0.1156\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 2.7386 - accuracy: 0.1608\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 2.6434 - accuracy: 0.1648\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 2.5620 - accuracy: 0.1672\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 2.4620 - accuracy: 0.2000\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 2.3908 - accuracy: 0.2048\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 2.3021 - accuracy: 0.2248\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 2.2858 - accuracy: 0.2204\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 2.2169 - accuracy: 0.2428\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 2.1737 - accuracy: 0.2516\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 2.1557 - accuracy: 0.2484\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 2.1139 - accuracy: 0.2744\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 2.1047 - accuracy: 0.2640\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 2.0929 - accuracy: 0.2536\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 2.0398 - accuracy: 0.2764\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 2.0289 - accuracy: 0.2928\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 2.0100 - accuracy: 0.2872\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 2.0198 - accuracy: 0.2856\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.9914 - accuracy: 0.2980\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 2.0141 - accuracy: 0.2784\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.9651 - accuracy: 0.2992\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.9209 - accuracy: 0.3176\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.9258 - accuracy: 0.2924\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.9008 - accuracy: 0.3036\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.8935 - accuracy: 0.3208\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.9101 - accuracy: 0.3228\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.8323 - accuracy: 0.3316\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.8262 - accuracy: 0.3276\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.8282 - accuracy: 0.3308\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.8539 - accuracy: 0.3276\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.8472 - accuracy: 0.3348\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.8376 - accuracy: 0.3276\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.7931 - accuracy: 0.3536\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.7973 - accuracy: 0.3392\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.7638 - accuracy: 0.3484\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.7901 - accuracy: 0.3516\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.7525 - accuracy: 0.3560\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.7772 - accuracy: 0.3560\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.7504 - accuracy: 0.3600\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.7712 - accuracy: 0.3536\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.7532 - accuracy: 0.3644\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.7508 - accuracy: 0.3648\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.7027 - accuracy: 0.3664\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.6840 - accuracy: 0.3900\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.7050 - accuracy: 0.3772\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.6753 - accuracy: 0.3876\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.6752 - accuracy: 0.3760\n",
      "lr=0.01, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 409us/step - loss: 1.6522 - accuracy: 0.3936\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.6210 - accuracy: 0.3940\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.5864 - accuracy: 0.4180\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.6254 - accuracy: 0.3972\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.5789 - accuracy: 0.4208\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.5797 - accuracy: 0.4080\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.5780 - accuracy: 0.4184\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.5656 - accuracy: 0.4252\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.5508 - accuracy: 0.4280\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.5319 - accuracy: 0.4384\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.5656 - accuracy: 0.4144\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.5753 - accuracy: 0.4256\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.5391 - accuracy: 0.4252\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.5431 - accuracy: 0.4304\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.5605 - accuracy: 0.4328\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.5469 - accuracy: 0.4256\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.5555 - accuracy: 0.4292\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.4941 - accuracy: 0.4616\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.5044 - accuracy: 0.4456\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.5044 - accuracy: 0.4388\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.5023 - accuracy: 0.4296\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.5191 - accuracy: 0.4344\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.4772 - accuracy: 0.4488\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.5229 - accuracy: 0.4392\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.5160 - accuracy: 0.4348\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.4657 - accuracy: 0.4500\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.4716 - accuracy: 0.4584\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.4799 - accuracy: 0.4620\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.4693 - accuracy: 0.4460\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.4967 - accuracy: 0.4404\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.4819 - accuracy: 0.4448\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.4925 - accuracy: 0.4456\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.4642 - accuracy: 0.4564\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.5014 - accuracy: 0.4332\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.4580 - accuracy: 0.4504\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.4657 - accuracy: 0.4532\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.4525 - accuracy: 0.4576\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.4638 - accuracy: 0.4540\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.4845 - accuracy: 0.4440\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.4586 - accuracy: 0.4516\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.4558 - accuracy: 0.4512\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.4753 - accuracy: 0.4496\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.4430 - accuracy: 0.4580\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.4168 - accuracy: 0.4704\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.4432 - accuracy: 0.4644\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.4372 - accuracy: 0.4748\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.4571 - accuracy: 0.4528\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.4572 - accuracy: 0.4424\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.4253 - accuracy: 0.4508\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.4254 - accuracy: 0.4640\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.4373 - accuracy: 0.4464\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.4596 - accuracy: 0.4560\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.4440 - accuracy: 0.4464\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.4276 - accuracy: 0.4636\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.4516 - accuracy: 0.4552\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.4106 - accuracy: 0.4716\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.4169 - accuracy: 0.4672\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 0s 146us/step - loss: 1.3978 - accuracy: 0.4640\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.4220 - accuracy: 0.4716\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.4064 - accuracy: 0.4708\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.4543 - accuracy: 0.4604\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.3817 - accuracy: 0.4736\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.4333 - accuracy: 0.4616\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.4000 - accuracy: 0.4868\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.4056 - accuracy: 0.4712\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 146us/step - loss: 1.4193 - accuracy: 0.4668\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.4178 - accuracy: 0.4684\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.3773 - accuracy: 0.4832\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.4069 - accuracy: 0.4616\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.4053 - accuracy: 0.4748\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.4172 - accuracy: 0.4732\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.3844 - accuracy: 0.4864\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.3974 - accuracy: 0.4732\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.3983 - accuracy: 0.4656\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.4264 - accuracy: 0.4592\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.4302 - accuracy: 0.4620\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.3889 - accuracy: 0.4832\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.3655 - accuracy: 0.4876\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.3653 - accuracy: 0.4716\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.3798 - accuracy: 0.4760\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.3978 - accuracy: 0.4688\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.3655 - accuracy: 0.4760\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - ETA: 0s - loss: 1.3624 - accuracy: 0.47 - 0s 157us/step - loss: 1.3671 - accuracy: 0.4788\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.3827 - accuracy: 0.4844\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.4036 - accuracy: 0.4728\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.3752 - accuracy: 0.4864\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.3785 - accuracy: 0.4948\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.3742 - accuracy: 0.4840\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.3692 - accuracy: 0.4920\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.3819 - accuracy: 0.4848\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.3631 - accuracy: 0.4840\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.3493 - accuracy: 0.4860\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.3722 - accuracy: 0.4832\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.3486 - accuracy: 0.4896\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.3809 - accuracy: 0.4876\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.3529 - accuracy: 0.4796\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.3650 - accuracy: 0.4768\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.3440 - accuracy: 0.4984\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.3318 - accuracy: 0.5040\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.3428 - accuracy: 0.4784\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.3232 - accuracy: 0.4920\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.3736 - accuracy: 0.4904\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.3475 - accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.3307 - accuracy: 0.4932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.3308 - accuracy: 0.4960\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.3627 - accuracy: 0.4908\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.3264 - accuracy: 0.4900\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.3456 - accuracy: 0.4896\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.2935 - accuracy: 0.5136\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.3125 - accuracy: 0.4908\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.3350 - accuracy: 0.4956\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.3473 - accuracy: 0.4776\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.3094 - accuracy: 0.5068\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.3085 - accuracy: 0.5100\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.3358 - accuracy: 0.4944\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.3273 - accuracy: 0.4976\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.3039 - accuracy: 0.5100\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.3172 - accuracy: 0.5048\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.3119 - accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.3104 - accuracy: 0.5056\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.2841 - accuracy: 0.5040\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.3221 - accuracy: 0.5040\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.3380 - accuracy: 0.5012\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.3025 - accuracy: 0.4972\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.3121 - accuracy: 0.4968\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.3115 - accuracy: 0.5112\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.3150 - accuracy: 0.4964\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.3276 - accuracy: 0.4920\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.2986 - accuracy: 0.5024\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.3372 - accuracy: 0.4952\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2942 - accuracy: 0.5024\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2869 - accuracy: 0.5084\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.3063 - accuracy: 0.5072\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.2742 - accuracy: 0.5252\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.3049 - accuracy: 0.5032\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.2926 - accuracy: 0.5128\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.3201 - accuracy: 0.4992\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2628 - accuracy: 0.5088\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.2823 - accuracy: 0.5016\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.2839 - accuracy: 0.5044\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.3014 - accuracy: 0.5064\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.3033 - accuracy: 0.5136\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.2799 - accuracy: 0.5252\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.2897 - accuracy: 0.5004\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.2566 - accuracy: 0.5144\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.3129 - accuracy: 0.4996\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.2780 - accuracy: 0.5032\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 191us/step - loss: 1.2815 - accuracy: 0.5184\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.2815 - accuracy: 0.5100\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2493 - accuracy: 0.5248\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.2749 - accuracy: 0.5100\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2967 - accuracy: 0.5012\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2688 - accuracy: 0.5088\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.2571 - accuracy: 0.5208\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2842 - accuracy: 0.5028\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.2789 - accuracy: 0.5180\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.2714 - accuracy: 0.5104\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.2638 - accuracy: 0.5248\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2522 - accuracy: 0.5364\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.2669 - accuracy: 0.5272\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2570 - accuracy: 0.5216\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2675 - accuracy: 0.5152\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.2755 - accuracy: 0.5080\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2699 - accuracy: 0.5100\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.2976 - accuracy: 0.5040\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2466 - accuracy: 0.5192\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.2254 - accuracy: 0.5396\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.2662 - accuracy: 0.5252\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2587 - accuracy: 0.5120\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.2942 - accuracy: 0.5160\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2654 - accuracy: 0.5156\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2496 - accuracy: 0.5228\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2678 - accuracy: 0.5120\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2469 - accuracy: 0.5220\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2612 - accuracy: 0.5180\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.2402 - accuracy: 0.5344\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.2199 - accuracy: 0.5356\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2362 - accuracy: 0.5360\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2543 - accuracy: 0.5224\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2331 - accuracy: 0.5200\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.2395 - accuracy: 0.5356\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2188 - accuracy: 0.5428\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.2170 - accuracy: 0.5360\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2277 - accuracy: 0.5284\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.2534 - accuracy: 0.5324\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.2030 - accuracy: 0.5332\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2245 - accuracy: 0.5376\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2125 - accuracy: 0.5480\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.2434 - accuracy: 0.5260\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.2094 - accuracy: 0.5364\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.2343 - accuracy: 0.5304\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.2346 - accuracy: 0.5236\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2460 - accuracy: 0.5268\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.2230 - accuracy: 0.5440\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.2249 - accuracy: 0.5304\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2336 - accuracy: 0.5348\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.2316 - accuracy: 0.5304\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.2105 - accuracy: 0.5488\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.2363 - accuracy: 0.5376\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2104 - accuracy: 0.5416\n",
      "lr=0.001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 395us/step - loss: 1.2751 - accuracy: 0.5228\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.2205 - accuracy: 0.5172\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.2198 - accuracy: 0.5324\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.2021 - accuracy: 0.5476\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.2392 - accuracy: 0.5344\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.2321 - accuracy: 0.5268\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2126 - accuracy: 0.5468\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.2417 - accuracy: 0.5392\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.2073 - accuracy: 0.5452\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2345 - accuracy: 0.5164\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1938 - accuracy: 0.5348\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2148 - accuracy: 0.5388\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.2205 - accuracy: 0.5308\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.2221 - accuracy: 0.5480\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.2440 - accuracy: 0.5380\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.2088 - accuracy: 0.5388\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2138 - accuracy: 0.5564\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.2174 - accuracy: 0.5320\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2116 - accuracy: 0.5396\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2202 - accuracy: 0.5456\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2168 - accuracy: 0.5232\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.2385 - accuracy: 0.5280\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.2106 - accuracy: 0.5428\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2268 - accuracy: 0.5420\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.2069 - accuracy: 0.5384\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1877 - accuracy: 0.5504\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.1755 - accuracy: 0.5452\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1917 - accuracy: 0.5392\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.1889 - accuracy: 0.5420\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1968 - accuracy: 0.5560\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2046 - accuracy: 0.5300\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2171 - accuracy: 0.5392\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1959 - accuracy: 0.5392\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.2239 - accuracy: 0.5372\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1992 - accuracy: 0.5536\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.2076 - accuracy: 0.5408\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1890 - accuracy: 0.5360\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.2128 - accuracy: 0.5404\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2620 - accuracy: 0.5332\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2368 - accuracy: 0.5364\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2096 - accuracy: 0.5476\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2252 - accuracy: 0.5388\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.2214 - accuracy: 0.5404\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.2065 - accuracy: 0.5392\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.2154 - accuracy: 0.5404\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.1925 - accuracy: 0.5264\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2001 - accuracy: 0.5424\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.1996 - accuracy: 0.5456\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2211 - accuracy: 0.5440\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.2392 - accuracy: 0.5404\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.2200 - accuracy: 0.5312\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.2256 - accuracy: 0.5176\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2351 - accuracy: 0.5216\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1961 - accuracy: 0.5416\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.2075 - accuracy: 0.5464\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.2063 - accuracy: 0.5432\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1978 - accuracy: 0.5388\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.2403 - accuracy: 0.5156\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.1994 - accuracy: 0.5444\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1782 - accuracy: 0.5524\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1915 - accuracy: 0.5428\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1912 - accuracy: 0.5552\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.2058 - accuracy: 0.5464\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.2153 - accuracy: 0.5312\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.1800 - accuracy: 0.5512\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.2420 - accuracy: 0.5364\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.2526 - accuracy: 0.5320\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.2170 - accuracy: 0.5356\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.2231 - accuracy: 0.5484\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.2291 - accuracy: 0.5376\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2266 - accuracy: 0.5376\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1883 - accuracy: 0.5512\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1726 - accuracy: 0.5528\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.2343 - accuracy: 0.5244\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.2136 - accuracy: 0.5456\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1950 - accuracy: 0.5384\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.2076 - accuracy: 0.5508\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1961 - accuracy: 0.5568\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.2111 - accuracy: 0.5432\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1915 - accuracy: 0.5396\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1884 - accuracy: 0.5412\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 1s 208us/step - loss: 1.1617 - accuracy: 0.5424\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1877 - accuracy: 0.5492\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1947 - accuracy: 0.5420\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.1855 - accuracy: 0.5480\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1835 - accuracy: 0.5448\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1937 - accuracy: 0.5332\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2184 - accuracy: 0.5344\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1893 - accuracy: 0.5516\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.2187 - accuracy: 0.5420\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.2183 - accuracy: 0.5388\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1623 - accuracy: 0.5492\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1929 - accuracy: 0.5376\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.2074 - accuracy: 0.5344\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1677 - accuracy: 0.5484\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1871 - accuracy: 0.5564\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.2107 - accuracy: 0.5412\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1825 - accuracy: 0.5508\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1750 - accuracy: 0.5632\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1923 - accuracy: 0.5468\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.2062 - accuracy: 0.5328\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.2194 - accuracy: 0.5384\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2003 - accuracy: 0.5360\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1905 - accuracy: 0.5520\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1890 - accuracy: 0.5456\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1931 - accuracy: 0.5528\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.2217 - accuracy: 0.5348\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.2030 - accuracy: 0.5564\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.2282 - accuracy: 0.5420\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1488 - accuracy: 0.5636\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1879 - accuracy: 0.5456\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1954 - accuracy: 0.5276\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.2372 - accuracy: 0.5476\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1875 - accuracy: 0.5552\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1920 - accuracy: 0.5520\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.2424 - accuracy: 0.5308\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1791 - accuracy: 0.5388\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1791 - accuracy: 0.5564\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1731 - accuracy: 0.5500\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.1940 - accuracy: 0.5376\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1728 - accuracy: 0.5524\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1992 - accuracy: 0.5300\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1860 - accuracy: 0.5324\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1857 - accuracy: 0.5416\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1678 - accuracy: 0.5504\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1807 - accuracy: 0.5508\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.2037 - accuracy: 0.5480\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.2155 - accuracy: 0.5408\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.1934 - accuracy: 0.5420\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1735 - accuracy: 0.5652\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.2092 - accuracy: 0.5448\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1964 - accuracy: 0.5460\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1622 - accuracy: 0.5512\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1881 - accuracy: 0.5444\n",
      "Epoch 135/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1667 - accuracy: 0.5488\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.2071 - accuracy: 0.5472\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.2008 - accuracy: 0.5544\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1746 - accuracy: 0.5620\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1829 - accuracy: 0.5456\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1966 - accuracy: 0.5360\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1763 - accuracy: 0.5524\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1966 - accuracy: 0.5392\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1693 - accuracy: 0.5488\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1708 - accuracy: 0.5452\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1916 - accuracy: 0.5452\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1731 - accuracy: 0.5508\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1828 - accuracy: 0.5512\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.2106 - accuracy: 0.5428\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1741 - accuracy: 0.5604\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2070 - accuracy: 0.5428\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1754 - accuracy: 0.5520\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.1694 - accuracy: 0.5492\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1764 - accuracy: 0.5536\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1866 - accuracy: 0.5504\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2030 - accuracy: 0.5476\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.2014 - accuracy: 0.5432\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1818 - accuracy: 0.5572\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.2118 - accuracy: 0.5392\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1582 - accuracy: 0.5504\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1922 - accuracy: 0.5488\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.2179 - accuracy: 0.5428\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1982 - accuracy: 0.5432\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.2237 - accuracy: 0.5324\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1796 - accuracy: 0.5520\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1822 - accuracy: 0.5380\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.2215 - accuracy: 0.5160\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1737 - accuracy: 0.5584\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1823 - accuracy: 0.5460\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.2105 - accuracy: 0.5308\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1941 - accuracy: 0.5440\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1796 - accuracy: 0.5516\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1887 - accuracy: 0.5440\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.2120 - accuracy: 0.5384\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1790 - accuracy: 0.5464\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.1638 - accuracy: 0.5544\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1977 - accuracy: 0.5396\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1822 - accuracy: 0.5540\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1726 - accuracy: 0.5444\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.1666 - accuracy: 0.5404\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2009 - accuracy: 0.5448\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.2019 - accuracy: 0.5296\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.1978 - accuracy: 0.5372\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1555 - accuracy: 0.5624\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1907 - accuracy: 0.5428\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.2031 - accuracy: 0.5532\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.2122 - accuracy: 0.5340\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1875 - accuracy: 0.5524\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1518 - accuracy: 0.5588\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1595 - accuracy: 0.5684\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1841 - accuracy: 0.5500\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1672 - accuracy: 0.5504\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1740 - accuracy: 0.5548\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.1880 - accuracy: 0.5380\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.1944 - accuracy: 0.5492\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.2170 - accuracy: 0.5240\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2080 - accuracy: 0.5404\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1721 - accuracy: 0.5528\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1879 - accuracy: 0.5440\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1619 - accuracy: 0.5608\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2004 - accuracy: 0.5444\n",
      "lr=0.0001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 419us/step - loss: 1.2034 - accuracy: 0.5440\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.1821 - accuracy: 0.5556\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1679 - accuracy: 0.5472\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1984 - accuracy: 0.5388\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1851 - accuracy: 0.5500\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.1750 - accuracy: 0.5588\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1638 - accuracy: 0.5488\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.1592 - accuracy: 0.5584\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1698 - accuracy: 0.5508\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1994 - accuracy: 0.5360\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1573 - accuracy: 0.5548\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.1755 - accuracy: 0.5400\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1782 - accuracy: 0.5452\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.1709 - accuracy: 0.5504\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.2176 - accuracy: 0.5392\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1770 - accuracy: 0.5484\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1587 - accuracy: 0.5616\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1574 - accuracy: 0.5528\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.2055 - accuracy: 0.5420\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1786 - accuracy: 0.5576\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.1945 - accuracy: 0.5424\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.1729 - accuracy: 0.5728\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.2040 - accuracy: 0.5412\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1930 - accuracy: 0.5540\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.1890 - accuracy: 0.5624\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 1s 220us/step - loss: 1.1670 - accuracy: 0.5464\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.1645 - accuracy: 0.5596\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.1595 - accuracy: 0.5536\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1686 - accuracy: 0.5472\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1951 - accuracy: 0.5700\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.1739 - accuracy: 0.5604\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.2100 - accuracy: 0.5528\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1896 - accuracy: 0.5456\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1517 - accuracy: 0.5596\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1637 - accuracy: 0.5568\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1823 - accuracy: 0.5532\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1468 - accuracy: 0.5460\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.1720 - accuracy: 0.5376\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 149us/step - loss: 1.1976 - accuracy: 0.5420\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1835 - accuracy: 0.5568\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1901 - accuracy: 0.5376\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1841 - accuracy: 0.5524\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.1817 - accuracy: 0.5472\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1759 - accuracy: 0.5540\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1881 - accuracy: 0.5428\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1908 - accuracy: 0.5492\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1894 - accuracy: 0.5576\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 143us/step - loss: 1.1861 - accuracy: 0.5412\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1980 - accuracy: 0.5400\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1609 - accuracy: 0.5536\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2050 - accuracy: 0.5344\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1771 - accuracy: 0.5716\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1676 - accuracy: 0.5456\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1823 - accuracy: 0.5372\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1953 - accuracy: 0.5456\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1807 - accuracy: 0.5492\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1873 - accuracy: 0.5408\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1748 - accuracy: 0.5584\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1906 - accuracy: 0.5476\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 146us/step - loss: 1.1919 - accuracy: 0.5500\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1823 - accuracy: 0.5576\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1733 - accuracy: 0.5420\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1950 - accuracy: 0.5404\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.1998 - accuracy: 0.5456\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1673 - accuracy: 0.5512\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1753 - accuracy: 0.5580\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1634 - accuracy: 0.5668\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.1862 - accuracy: 0.5456\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.2029 - accuracy: 0.5320\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.2235 - accuracy: 0.5388\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1721 - accuracy: 0.5432\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1904 - accuracy: 0.5408\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1793 - accuracy: 0.5528\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1650 - accuracy: 0.5504\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1848 - accuracy: 0.5436\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.1578 - accuracy: 0.5596\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.1544 - accuracy: 0.5596\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1802 - accuracy: 0.5364\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1893 - accuracy: 0.5460\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1914 - accuracy: 0.5536\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1542 - accuracy: 0.5460\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.1547 - accuracy: 0.5576\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1634 - accuracy: 0.5608\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 149us/step - loss: 1.1923 - accuracy: 0.5564\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1936 - accuracy: 0.5508\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1748 - accuracy: 0.5448\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1699 - accuracy: 0.5540\n",
      "Epoch 88/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1753 - accuracy: 0.5536\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1994 - accuracy: 0.5272\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1752 - accuracy: 0.5492\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.2019 - accuracy: 0.5400\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1685 - accuracy: 0.5516\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1921 - accuracy: 0.5484\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1946 - accuracy: 0.5480\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.2146 - accuracy: 0.5408\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1650 - accuracy: 0.5572\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.1451 - accuracy: 0.5548\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1748 - accuracy: 0.5392\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.2002 - accuracy: 0.5412\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1716 - accuracy: 0.5680\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1639 - accuracy: 0.5392\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1697 - accuracy: 0.5524\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1929 - accuracy: 0.5452\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1700 - accuracy: 0.5708\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1765 - accuracy: 0.5520\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1805 - accuracy: 0.5484\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1646 - accuracy: 0.5380\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1660 - accuracy: 0.5572\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1619 - accuracy: 0.5568\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1828 - accuracy: 0.5532\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.2004 - accuracy: 0.5444\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1702 - accuracy: 0.5524\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1933 - accuracy: 0.5416\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1947 - accuracy: 0.5552\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 147us/step - loss: 1.1596 - accuracy: 0.5544\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1821 - accuracy: 0.55400s - loss: 1.1861 - accuracy\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1877 - accuracy: 0.5520\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1533 - accuracy: 0.5568\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1391 - accuracy: 0.5668\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1807 - accuracy: 0.5564\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1551 - accuracy: 0.5616\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1411 - accuracy: 0.5588\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1720 - accuracy: 0.5612\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1899 - accuracy: 0.5472\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1824 - accuracy: 0.5428\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1684 - accuracy: 0.5524\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1940 - accuracy: 0.5576\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1984 - accuracy: 0.5520\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1719 - accuracy: 0.5436\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1775 - accuracy: 0.5544\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.1782 - accuracy: 0.5456\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1977 - accuracy: 0.5380\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1454 - accuracy: 0.5548\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1762 - accuracy: 0.5460\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1986 - accuracy: 0.5520\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.1939 - accuracy: 0.5508\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 192us/step - loss: 1.2057 - accuracy: 0.5568\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.1592 - accuracy: 0.5604\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1921 - accuracy: 0.5504\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1599 - accuracy: 0.5632\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 198us/step - loss: 1.2227 - accuracy: 0.5388\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.2045 - accuracy: 0.5416\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.1770 - accuracy: 0.5472\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1984 - accuracy: 0.5448\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1977 - accuracy: 0.5528\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1900 - accuracy: 0.5476\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1493 - accuracy: 0.5584\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.1803 - accuracy: 0.5396\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1745 - accuracy: 0.55520s - loss: 1.1969 - accuracy\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 196us/step - loss: 1.2340 - accuracy: 0.5152\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.1780 - accuracy: 0.5480\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.1713 - accuracy: 0.5460\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1879 - accuracy: 0.5448\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1413 - accuracy: 0.5616\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.2011 - accuracy: 0.55080s - loss: 1.1852 - accura\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1984 - accuracy: 0.5408\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.1936 - accuracy: 0.5368\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1652 - accuracy: 0.5556\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1775 - accuracy: 0.5548\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1648 - accuracy: 0.5712\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.1599 - accuracy: 0.5576\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1578 - accuracy: 0.5696\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1512 - accuracy: 0.5684\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1957 - accuracy: 0.5400\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1954 - accuracy: 0.5496\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1857 - accuracy: 0.5460\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.1802 - accuracy: 0.5436\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1762 - accuracy: 0.5560\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.1942 - accuracy: 0.5412\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.2093 - accuracy: 0.5328\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.2069 - accuracy: 0.5400\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1563 - accuracy: 0.5608\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1602 - accuracy: 0.5536\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1801 - accuracy: 0.5520\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1596 - accuracy: 0.5644\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1852 - accuracy: 0.5520\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 199us/step - loss: 1.1720 - accuracy: 0.5508\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.1824 - accuracy: 0.5480\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.1871 - accuracy: 0.5376\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1969 - accuracy: 0.5580\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1951 - accuracy: 0.5600\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1839 - accuracy: 0.5452\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.1736 - accuracy: 0.5540\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1472 - accuracy: 0.5728\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1556 - accuracy: 0.5764\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.1683 - accuracy: 0.5560\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.2002 - accuracy: 0.5484\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1767 - accuracy: 0.5544\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.1784 - accuracy: 0.5516\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1909 - accuracy: 0.5472\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1754 - accuracy: 0.5576\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1631 - accuracy: 0.5516\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1989 - accuracy: 0.5388\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.1722 - accuracy: 0.5556\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1785 - accuracy: 0.5460\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1836 - accuracy: 0.5524\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1873 - accuracy: 0.5564\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1730 - accuracy: 0.5600\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1833 - accuracy: 0.5376\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1876 - accuracy: 0.5436\n",
      "lr=0.0001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 411us/step - loss: 1.1615 - accuracy: 0.5532\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.2051 - accuracy: 0.5276\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1756 - accuracy: 0.5616\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2005 - accuracy: 0.5408\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1612 - accuracy: 0.5504\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1456 - accuracy: 0.5616\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1785 - accuracy: 0.5500\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1771 - accuracy: 0.5520\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1668 - accuracy: 0.5432\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1728 - accuracy: 0.5468\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1734 - accuracy: 0.5444\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1853 - accuracy: 0.5484\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 147us/step - loss: 1.1980 - accuracy: 0.5404\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.1725 - accuracy: 0.5604\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2032 - accuracy: 0.5480\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.2191 - accuracy: 0.5520\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1686 - accuracy: 0.5520\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1634 - accuracy: 0.5556\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1429 - accuracy: 0.5664\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1353 - accuracy: 0.5688\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 145us/step - loss: 1.1731 - accuracy: 0.5456\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1753 - accuracy: 0.5592\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.1815 - accuracy: 0.5508\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1703 - accuracy: 0.5548\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1648 - accuracy: 0.5496\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1570 - accuracy: 0.5612\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1818 - accuracy: 0.5552\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1480 - accuracy: 0.5584\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.2059 - accuracy: 0.5416\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.2208 - accuracy: 0.5304\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.2029 - accuracy: 0.5336\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.1914 - accuracy: 0.5548\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1481 - accuracy: 0.5652\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1828 - accuracy: 0.5516\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1960 - accuracy: 0.5372\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1672 - accuracy: 0.5532\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1859 - accuracy: 0.5540\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1916 - accuracy: 0.55200s - loss: 1.1743 - accuracy: \n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1961 - accuracy: 0.5388\n",
      "Epoch 40/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1666 - accuracy: 0.5556\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.1763 - accuracy: 0.5524\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1709 - accuracy: 0.5512\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1490 - accuracy: 0.5452\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1829 - accuracy: 0.5548\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1577 - accuracy: 0.5584\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1436 - accuracy: 0.5648\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1798 - accuracy: 0.5400\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.1670 - accuracy: 0.5516\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1616 - accuracy: 0.5760\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.1569 - accuracy: 0.5452\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 0s 181us/step - loss: 1.1868 - accuracy: 0.5532\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 194us/step - loss: 1.1710 - accuracy: 0.5544\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.1524 - accuracy: 0.5644\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.1680 - accuracy: 0.5796\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1473 - accuracy: 0.5568\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1492 - accuracy: 0.5624\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.1321 - accuracy: 0.5760\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.1369 - accuracy: 0.5680\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1421 - accuracy: 0.5584\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1597 - accuracy: 0.5584\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.1669 - accuracy: 0.5604\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1426 - accuracy: 0.5720\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1857 - accuracy: 0.5520\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.1558 - accuracy: 0.5684\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1303 - accuracy: 0.5676\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1851 - accuracy: 0.5472\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.1566 - accuracy: 0.5624\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1822 - accuracy: 0.5468\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1331 - accuracy: 0.5696\n",
      "Epoch 70/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1175 - accuracy: 0.5716\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1417 - accuracy: 0.5672\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1223 - accuracy: 0.5736\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1424 - accuracy: 0.5736\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.1599 - accuracy: 0.5648\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1731 - accuracy: 0.5552\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1240 - accuracy: 0.5820\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1315 - accuracy: 0.5712\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1446 - accuracy: 0.5616\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1642 - accuracy: 0.5536\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1719 - accuracy: 0.5664\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.1667 - accuracy: 0.5468\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1264 - accuracy: 0.5788\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1053 - accuracy: 0.5788\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1550 - accuracy: 0.5580\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1283 - accuracy: 0.5664\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1408 - accuracy: 0.5708\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1130 - accuracy: 0.5648\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.1280 - accuracy: 0.5716\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.1247 - accuracy: 0.5876\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1467 - accuracy: 0.5688\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.1602 - accuracy: 0.5564\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1545 - accuracy: 0.5592\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1739 - accuracy: 0.5580\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.1663 - accuracy: 0.5644\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1313 - accuracy: 0.5820\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1190 - accuracy: 0.5700\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1455 - accuracy: 0.5604\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1019 - accuracy: 0.5848\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0920 - accuracy: 0.5740\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.1368 - accuracy: 0.5664\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1471 - accuracy: 0.5732\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.1242 - accuracy: 0.5676\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1275 - accuracy: 0.5728\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1209 - accuracy: 0.5736\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.1444 - accuracy: 0.5696\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1291 - accuracy: 0.5744\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0960 - accuracy: 0.5856\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.1065 - accuracy: 0.5840\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1212 - accuracy: 0.5676\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.1089 - accuracy: 0.5772\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1270 - accuracy: 0.5744\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.1309 - accuracy: 0.5644\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.0869 - accuracy: 0.5836\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.0986 - accuracy: 0.5720\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1005 - accuracy: 0.5764\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.1308 - accuracy: 0.5732\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1175 - accuracy: 0.5676\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1391 - accuracy: 0.5744\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1086 - accuracy: 0.5888\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.0744 - accuracy: 0.5884\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.0945 - accuracy: 0.5888\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.1617 - accuracy: 0.5552\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 1s 222us/step - loss: 1.1053 - accuracy: 0.5688\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.1344 - accuracy: 0.5684\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.1207 - accuracy: 0.5712\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.0985 - accuracy: 0.5836\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.1276 - accuracy: 0.5684\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1192 - accuracy: 0.5888\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1416 - accuracy: 0.5756\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.0993 - accuracy: 0.5720\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.0907 - accuracy: 0.5828\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1215 - accuracy: 0.5868\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.1328 - accuracy: 0.5836\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.1023 - accuracy: 0.5816\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1267 - accuracy: 0.5572\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.1140 - accuracy: 0.5896\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1232 - accuracy: 0.5788\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.1299 - accuracy: 0.5704\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.0712 - accuracy: 0.5892\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.1189 - accuracy: 0.5660\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.0796 - accuracy: 0.5888\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.0933 - accuracy: 0.5868\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1098 - accuracy: 0.5896\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0686 - accuracy: 0.6032\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1255 - accuracy: 0.5768\n",
      "Epoch 146/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.1386 - accuracy: 0.5636\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0715 - accuracy: 0.5908\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.1032 - accuracy: 0.5876\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0594 - accuracy: 0.5940\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1127 - accuracy: 0.5776\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 146us/step - loss: 1.1414 - accuracy: 0.5720\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.1353 - accuracy: 0.5780\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0972 - accuracy: 0.5780\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0768 - accuracy: 0.5956\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0938 - accuracy: 0.5920\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0769 - accuracy: 0.5868\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.1167 - accuracy: 0.5824\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1065 - accuracy: 0.5852\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0973 - accuracy: 0.5836\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0848 - accuracy: 0.5856\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0784 - accuracy: 0.5996\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0724 - accuracy: 0.5836\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.1004 - accuracy: 0.5828\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.1085 - accuracy: 0.5776\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1124 - accuracy: 0.5724\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1086 - accuracy: 0.5804\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0715 - accuracy: 0.5960\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0772 - accuracy: 0.5944\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.1075 - accuracy: 0.5696\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1105 - accuracy: 0.5860\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.0959 - accuracy: 0.5856\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0933 - accuracy: 0.5940\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.0638 - accuracy: 0.5832\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.0955 - accuracy: 0.5924\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0915 - accuracy: 0.5916\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0565 - accuracy: 0.6044\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.1095 - accuracy: 0.5844\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.0622 - accuracy: 0.5952\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.0992 - accuracy: 0.5948\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.0906 - accuracy: 0.5832\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.0839 - accuracy: 0.5944\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.1176 - accuracy: 0.5776\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.1019 - accuracy: 0.5880\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.1191 - accuracy: 0.5744\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.0967 - accuracy: 0.5856\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.0835 - accuracy: 0.5956\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.1008 - accuracy: 0.5856\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.0619 - accuracy: 0.6012\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.1061 - accuracy: 0.5972\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.0585 - accuracy: 0.5976\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0301 - accuracy: 0.6032\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.1015 - accuracy: 0.5804\n",
      "Epoch 193/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 173us/step - loss: 1.0669 - accuracy: 0.6008\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.0961 - accuracy: 0.5832\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0725 - accuracy: 0.6040\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.0800 - accuracy: 0.5924\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.0679 - accuracy: 0.5868\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 1s 239us/step - loss: 1.1025 - accuracy: 0.5944\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0829 - accuracy: 0.5900\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.0464 - accuracy: 0.6208\n",
      "lr=0.001, train complete\n",
      "Epoch 1/200\n",
      "2500/2500 [==============================] - 1s 399us/step - loss: 1.0636 - accuracy: 0.6024\n",
      "Epoch 2/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.0283 - accuracy: 0.5964\n",
      "Epoch 3/200\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.0738 - accuracy: 0.5972\n",
      "Epoch 4/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.1132 - accuracy: 0.5952\n",
      "Epoch 5/200\n",
      "2500/2500 [==============================] - 0s 145us/step - loss: 1.0905 - accuracy: 0.6008\n",
      "Epoch 6/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0784 - accuracy: 0.5852\n",
      "Epoch 7/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.0565 - accuracy: 0.6032\n",
      "Epoch 8/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0786 - accuracy: 0.5800\n",
      "Epoch 9/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0497 - accuracy: 0.5724\n",
      "Epoch 10/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0337 - accuracy: 0.6036\n",
      "Epoch 11/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0651 - accuracy: 0.5948\n",
      "Epoch 12/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.0504 - accuracy: 0.6064\n",
      "Epoch 13/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.0667 - accuracy: 0.6020\n",
      "Epoch 14/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0778 - accuracy: 0.5876\n",
      "Epoch 15/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.0607 - accuracy: 0.6036\n",
      "Epoch 16/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.0816 - accuracy: 0.5928\n",
      "Epoch 17/200\n",
      "2500/2500 [==============================] - 0s 200us/step - loss: 1.0294 - accuracy: 0.6048\n",
      "Epoch 18/200\n",
      "2500/2500 [==============================] - 0s 193us/step - loss: 1.0716 - accuracy: 0.6068\n",
      "Epoch 19/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.0922 - accuracy: 0.5856\n",
      "Epoch 20/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.0203 - accuracy: 0.6184\n",
      "Epoch 21/200\n",
      "2500/2500 [==============================] - 0s 147us/step - loss: 1.0764 - accuracy: 0.6004\n",
      "Epoch 22/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.0636 - accuracy: 0.5964\n",
      "Epoch 23/200\n",
      "2500/2500 [==============================] - 0s 184us/step - loss: 1.0717 - accuracy: 0.5956\n",
      "Epoch 24/200\n",
      "2500/2500 [==============================] - 0s 187us/step - loss: 1.0674 - accuracy: 0.5996\n",
      "Epoch 25/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.0405 - accuracy: 0.6192\n",
      "Epoch 26/200\n",
      "2500/2500 [==============================] - 0s 177us/step - loss: 1.0595 - accuracy: 0.6104\n",
      "Epoch 27/200\n",
      "2500/2500 [==============================] - 0s 182us/step - loss: 1.0144 - accuracy: 0.6088\n",
      "Epoch 28/200\n",
      "2500/2500 [==============================] - 0s 189us/step - loss: 1.0720 - accuracy: 0.6120\n",
      "Epoch 29/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.0398 - accuracy: 0.6032\n",
      "Epoch 30/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0598 - accuracy: 0.6036\n",
      "Epoch 31/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0350 - accuracy: 0.6152\n",
      "Epoch 32/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.0430 - accuracy: 0.6000\n",
      "Epoch 33/200\n",
      "2500/2500 [==============================] - 1s 201us/step - loss: 1.1010 - accuracy: 0.5804\n",
      "Epoch 34/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0442 - accuracy: 0.5944\n",
      "Epoch 35/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0393 - accuracy: 0.6100\n",
      "Epoch 36/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0977 - accuracy: 0.5884\n",
      "Epoch 37/200\n",
      "2500/2500 [==============================] - 1s 245us/step - loss: 1.0932 - accuracy: 0.5980\n",
      "Epoch 38/200\n",
      "2500/2500 [==============================] - 1s 212us/step - loss: 1.0529 - accuracy: 0.6004\n",
      "Epoch 39/200\n",
      "2500/2500 [==============================] - 1s 204us/step - loss: 1.0575 - accuracy: 0.5936\n",
      "Epoch 40/200\n",
      "2500/2500 [==============================] - 1s 210us/step - loss: 1.0788 - accuracy: 0.5984\n",
      "Epoch 41/200\n",
      "2500/2500 [==============================] - 1s 225us/step - loss: 1.1157 - accuracy: 0.5864\n",
      "Epoch 42/200\n",
      "2500/2500 [==============================] - 0s 195us/step - loss: 1.0579 - accuracy: 0.6008\n",
      "Epoch 43/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0642 - accuracy: 0.6024\n",
      "Epoch 44/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.0404 - accuracy: 0.6136\n",
      "Epoch 45/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0711 - accuracy: 0.5936\n",
      "Epoch 46/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.0739 - accuracy: 0.5908\n",
      "Epoch 47/200\n",
      "2500/2500 [==============================] - 0s 180us/step - loss: 1.0390 - accuracy: 0.6044\n",
      "Epoch 48/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0427 - accuracy: 0.6052\n",
      "Epoch 49/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.0292 - accuracy: 0.6080\n",
      "Epoch 50/200\n",
      "2500/2500 [==============================] - 1s 203us/step - loss: 1.0565 - accuracy: 0.5964\n",
      "Epoch 51/200\n",
      "2500/2500 [==============================] - 1s 207us/step - loss: 1.0988 - accuracy: 0.5936\n",
      "Epoch 52/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.0707 - accuracy: 0.6064\n",
      "Epoch 53/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.0432 - accuracy: 0.6064\n",
      "Epoch 54/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.0529 - accuracy: 0.6076\n",
      "Epoch 55/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0769 - accuracy: 0.5876\n",
      "Epoch 56/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0432 - accuracy: 0.6064\n",
      "Epoch 57/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.0535 - accuracy: 0.6052\n",
      "Epoch 58/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.0353 - accuracy: 0.6148\n",
      "Epoch 59/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0820 - accuracy: 0.5980\n",
      "Epoch 60/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0406 - accuracy: 0.6144\n",
      "Epoch 61/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0667 - accuracy: 0.5908\n",
      "Epoch 62/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.0354 - accuracy: 0.6024\n",
      "Epoch 63/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.0436 - accuracy: 0.6048\n",
      "Epoch 64/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0673 - accuracy: 0.6020\n",
      "Epoch 65/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.0215 - accuracy: 0.6116\n",
      "Epoch 66/200\n",
      "2500/2500 [==============================] - 1s 231us/step - loss: 1.0595 - accuracy: 0.6004\n",
      "Epoch 67/200\n",
      "2500/2500 [==============================] - 0s 179us/step - loss: 1.0966 - accuracy: 0.6044\n",
      "Epoch 68/200\n",
      "2500/2500 [==============================] - 0s 185us/step - loss: 1.0626 - accuracy: 0.6032\n",
      "Epoch 69/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.0736 - accuracy: 0.5928\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.0822 - accuracy: 0.5876\n",
      "Epoch 71/200\n",
      "2500/2500 [==============================] - 0s 197us/step - loss: 1.0563 - accuracy: 0.6060\n",
      "Epoch 72/200\n",
      "2500/2500 [==============================] - 1s 202us/step - loss: 1.0183 - accuracy: 0.6132\n",
      "Epoch 73/200\n",
      "2500/2500 [==============================] - 0s 186us/step - loss: 1.0822 - accuracy: 0.5916\n",
      "Epoch 74/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0578 - accuracy: 0.5952\n",
      "Epoch 75/200\n",
      "2500/2500 [==============================] - 0s 188us/step - loss: 1.0798 - accuracy: 0.5916\n",
      "Epoch 76/200\n",
      "2500/2500 [==============================] - 1s 215us/step - loss: 1.0604 - accuracy: 0.5964\n",
      "Epoch 77/200\n",
      "2500/2500 [==============================] - 0s 190us/step - loss: 1.0791 - accuracy: 0.5860\n",
      "Epoch 78/200\n",
      "2500/2500 [==============================] - 0s 176us/step - loss: 1.0870 - accuracy: 0.6024\n",
      "Epoch 79/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0410 - accuracy: 0.6228\n",
      "Epoch 80/200\n",
      "2500/2500 [==============================] - 0s 149us/step - loss: 1.0850 - accuracy: 0.5992\n",
      "Epoch 81/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.0629 - accuracy: 0.6008\n",
      "Epoch 82/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.0366 - accuracy: 0.6088\n",
      "Epoch 83/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.0341 - accuracy: 0.6104\n",
      "Epoch 84/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.0694 - accuracy: 0.5900\n",
      "Epoch 85/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0437 - accuracy: 0.6116\n",
      "Epoch 86/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0352 - accuracy: 0.6084\n",
      "Epoch 87/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0184 - accuracy: 0.6172\n",
      "Epoch 88/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.0807 - accuracy: 0.5808\n",
      "Epoch 89/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.0269 - accuracy: 0.6124\n",
      "Epoch 90/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0763 - accuracy: 0.6012\n",
      "Epoch 91/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.1130 - accuracy: 0.5928\n",
      "Epoch 92/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0344 - accuracy: 0.6012\n",
      "Epoch 93/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0640 - accuracy: 0.5960\n",
      "Epoch 94/200\n",
      "2500/2500 [==============================] - 0s 169us/step - loss: 1.0230 - accuracy: 0.6176\n",
      "Epoch 95/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0185 - accuracy: 0.6292\n",
      "Epoch 96/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0628 - accuracy: 0.5944\n",
      "Epoch 97/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0483 - accuracy: 0.6072\n",
      "Epoch 98/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0375 - accuracy: 0.6068\n",
      "Epoch 99/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0622 - accuracy: 0.5944\n",
      "Epoch 100/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0753 - accuracy: 0.5844\n",
      "Epoch 101/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0081 - accuracy: 0.6188\n",
      "Epoch 102/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0312 - accuracy: 0.6056\n",
      "Epoch 103/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0717 - accuracy: 0.5888\n",
      "Epoch 104/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0774 - accuracy: 0.5972\n",
      "Epoch 105/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0330 - accuracy: 0.6228\n",
      "Epoch 106/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0229 - accuracy: 0.6124\n",
      "Epoch 107/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.0607 - accuracy: 0.6096\n",
      "Epoch 108/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.0862 - accuracy: 0.5908\n",
      "Epoch 109/200\n",
      "2500/2500 [==============================] - 1s 205us/step - loss: 1.0445 - accuracy: 0.5992\n",
      "Epoch 110/200\n",
      "2500/2500 [==============================] - 0s 175us/step - loss: 1.0182 - accuracy: 0.6168\n",
      "Epoch 111/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.0720 - accuracy: 0.6016\n",
      "Epoch 112/200\n",
      "2500/2500 [==============================] - 0s 171us/step - loss: 1.0467 - accuracy: 0.6092\n",
      "Epoch 113/200\n",
      "2500/2500 [==============================] - 0s 172us/step - loss: 1.0189 - accuracy: 0.6160\n",
      "Epoch 114/200\n",
      "2500/2500 [==============================] - 0s 170us/step - loss: 1.0632 - accuracy: 0.6032\n",
      "Epoch 115/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.0572 - accuracy: 0.6040\n",
      "Epoch 116/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.0464 - accuracy: 0.6112\n",
      "Epoch 117/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0283 - accuracy: 0.6088\n",
      "Epoch 118/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.0194 - accuracy: 0.6232\n",
      "Epoch 119/200\n",
      "2500/2500 [==============================] - 0s 178us/step - loss: 1.0373 - accuracy: 0.6120\n",
      "Epoch 120/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.0439 - accuracy: 0.6152\n",
      "Epoch 121/200\n",
      "2500/2500 [==============================] - 0s 174us/step - loss: 1.0564 - accuracy: 0.6096\n",
      "Epoch 122/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.0615 - accuracy: 0.59800s - loss: 1.0357 - accuracy: 0.60\n",
      "Epoch 123/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0120 - accuracy: 0.6212\n",
      "Epoch 124/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0434 - accuracy: 0.5960\n",
      "Epoch 125/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0300 - accuracy: 0.6024\n",
      "Epoch 126/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.0200 - accuracy: 0.6112\n",
      "Epoch 127/200\n",
      "2500/2500 [==============================] - 0s 183us/step - loss: 1.0464 - accuracy: 0.6052\n",
      "Epoch 128/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0290 - accuracy: 0.6072\n",
      "Epoch 129/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.0250 - accuracy: 0.6104\n",
      "Epoch 130/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0440 - accuracy: 0.5988\n",
      "Epoch 131/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0530 - accuracy: 0.6060\n",
      "Epoch 132/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0650 - accuracy: 0.5960\n",
      "Epoch 133/200\n",
      "2500/2500 [==============================] - 0s 145us/step - loss: 1.0404 - accuracy: 0.6104\n",
      "Epoch 134/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0840 - accuracy: 0.6016\n",
      "Epoch 135/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0433 - accuracy: 0.6124\n",
      "Epoch 136/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0455 - accuracy: 0.6052\n",
      "Epoch 137/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0515 - accuracy: 0.6132\n",
      "Epoch 138/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0458 - accuracy: 0.6056\n",
      "Epoch 139/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0391 - accuracy: 0.6092\n",
      "Epoch 140/200\n",
      "2500/2500 [==============================] - 0s 168us/step - loss: 1.0923 - accuracy: 0.5972\n",
      "Epoch 141/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0447 - accuracy: 0.6016\n",
      "Epoch 142/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0473 - accuracy: 0.5980\n",
      "Epoch 143/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0711 - accuracy: 0.5984\n",
      "Epoch 144/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0594 - accuracy: 0.6088\n",
      "Epoch 145/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0477 - accuracy: 0.6140\n",
      "Epoch 146/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0425 - accuracy: 0.6084\n",
      "Epoch 147/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0300 - accuracy: 0.6172\n",
      "Epoch 148/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0596 - accuracy: 0.5984\n",
      "Epoch 149/200\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.0412 - accuracy: 0.6080\n",
      "Epoch 150/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0472 - accuracy: 0.6020\n",
      "Epoch 151/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.0484 - accuracy: 0.6020\n",
      "Epoch 152/200\n",
      "2500/2500 [==============================] - 0s 146us/step - loss: 1.0484 - accuracy: 0.6064\n",
      "Epoch 153/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0479 - accuracy: 0.6088\n",
      "Epoch 154/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0379 - accuracy: 0.6088\n",
      "Epoch 155/200\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0662 - accuracy: 0.5940\n",
      "Epoch 156/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0572 - accuracy: 0.5928\n",
      "Epoch 157/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0184 - accuracy: 0.6060\n",
      "Epoch 158/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0744 - accuracy: 0.5872\n",
      "Epoch 159/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0363 - accuracy: 0.6212\n",
      "Epoch 160/200\n",
      "2500/2500 [==============================] - 0s 146us/step - loss: 1.0175 - accuracy: 0.6116\n",
      "Epoch 161/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0517 - accuracy: 0.6036\n",
      "Epoch 162/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0504 - accuracy: 0.6064\n",
      "Epoch 163/200\n",
      "2500/2500 [==============================] - 0s 143us/step - loss: 1.0812 - accuracy: 0.5972\n",
      "Epoch 164/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0625 - accuracy: 0.5924\n",
      "Epoch 165/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0446 - accuracy: 0.6092\n",
      "Epoch 166/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0613 - accuracy: 0.5992\n",
      "Epoch 167/200\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0334 - accuracy: 0.6092\n",
      "Epoch 168/200\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.0388 - accuracy: 0.6092\n",
      "Epoch 169/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0522 - accuracy: 0.6068\n",
      "Epoch 170/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0576 - accuracy: 0.6020\n",
      "Epoch 171/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.0087 - accuracy: 0.6196\n",
      "Epoch 172/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0254 - accuracy: 0.6068\n",
      "Epoch 173/200\n",
      "2500/2500 [==============================] - 0s 167us/step - loss: 1.0403 - accuracy: 0.6092\n",
      "Epoch 174/200\n",
      "2500/2500 [==============================] - 0s 166us/step - loss: 1.0535 - accuracy: 0.5884\n",
      "Epoch 175/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0439 - accuracy: 0.5952\n",
      "Epoch 176/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0777 - accuracy: 0.6016\n",
      "Epoch 177/200\n",
      "2500/2500 [==============================] - 0s 149us/step - loss: 1.0179 - accuracy: 0.6096\n",
      "Epoch 178/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.0314 - accuracy: 0.6136\n",
      "Epoch 179/200\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0783 - accuracy: 0.5956\n",
      "Epoch 180/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0256 - accuracy: 0.6140\n",
      "Epoch 181/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0730 - accuracy: 0.6104\n",
      "Epoch 182/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.0675 - accuracy: 0.6116\n",
      "Epoch 183/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0321 - accuracy: 0.6100\n",
      "Epoch 184/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0387 - accuracy: 0.6132\n",
      "Epoch 185/200\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0267 - accuracy: 0.6176\n",
      "Epoch 186/200\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0498 - accuracy: 0.5968\n",
      "Epoch 187/200\n",
      "2500/2500 [==============================] - 0s 164us/step - loss: 1.0515 - accuracy: 0.5964\n",
      "Epoch 188/200\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0298 - accuracy: 0.5904\n",
      "Epoch 189/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0769 - accuracy: 0.5752\n",
      "Epoch 190/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0034 - accuracy: 0.6264\n",
      "Epoch 191/200\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0493 - accuracy: 0.6108\n",
      "Epoch 192/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0193 - accuracy: 0.6164\n",
      "Epoch 193/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0567 - accuracy: 0.6020\n",
      "Epoch 194/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0199 - accuracy: 0.6120\n",
      "Epoch 195/200\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0456 - accuracy: 0.6072\n",
      "Epoch 196/200\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0133 - accuracy: 0.6276\n",
      "Epoch 197/200\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0595 - accuracy: 0.5996\n",
      "Epoch 198/200\n",
      "2500/2500 [==============================] - 0s 150us/step - loss: 1.0381 - accuracy: 0.6048\n",
      "Epoch 199/200\n",
      "2500/2500 [==============================] - 0s 148us/step - loss: 1.0410 - accuracy: 0.6076\n",
      "Epoch 200/200\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0233 - accuracy: 0.6120\n",
      "lr=0.0001, train complete\n",
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 1s 405us/step - loss: 1.0381 - accuracy: 0.6076\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 1.0351 - accuracy: 0.6060\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 0s 165us/step - loss: 1.0277 - accuracy: 0.6176\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0264 - accuracy: 0.6244\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0761 - accuracy: 0.5996\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0346 - accuracy: 0.6196\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0252 - accuracy: 0.6096\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0859 - accuracy: 0.5936\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0462 - accuracy: 0.6064\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0242 - accuracy: 0.6200\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0534 - accuracy: 0.6108\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0461 - accuracy: 0.6156\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0230 - accuracy: 0.6076\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0426 - accuracy: 0.6152\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0515 - accuracy: 0.6000\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 0.9914 - accuracy: 0.6316\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0496 - accuracy: 0.6072\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 0s 159us/step - loss: 1.0413 - accuracy: 0.6120\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0209 - accuracy: 0.6152\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0434 - accuracy: 0.6128\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0839 - accuracy: 0.5948\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 0s 149us/step - loss: 1.0401 - accuracy: 0.6160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0507 - accuracy: 0.5968\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0543 - accuracy: 0.6084\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0516 - accuracy: 0.5936\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0285 - accuracy: 0.6044\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0124 - accuracy: 0.6128\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0514 - accuracy: 0.5960\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0396 - accuracy: 0.6176\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 0s 157us/step - loss: 1.0308 - accuracy: 0.6232\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0632 - accuracy: 0.5952\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0272 - accuracy: 0.6140\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0442 - accuracy: 0.6092\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0381 - accuracy: 0.6020\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0795 - accuracy: 0.6016\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 0s 155us/step - loss: 1.0197 - accuracy: 0.6236\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 0s 156us/step - loss: 1.0060 - accuracy: 0.6252\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 0s 149us/step - loss: 1.0237 - accuracy: 0.6148\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 0s 163us/step - loss: 1.0398 - accuracy: 0.6156\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0679 - accuracy: 0.6008\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0276 - accuracy: 0.6096\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 0s 162us/step - loss: 1.0443 - accuracy: 0.6144\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 0s 151us/step - loss: 1.0494 - accuracy: 0.6008\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 0s 160us/step - loss: 0.9877 - accuracy: 0.6220\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 0s 161us/step - loss: 1.0087 - accuracy: 0.6324\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0428 - accuracy: 0.6172\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 0s 152us/step - loss: 1.0679 - accuracy: 0.6068\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 0s 158us/step - loss: 1.0428 - accuracy: 0.6036\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 0s 153us/step - loss: 1.0119 - accuracy: 0.6120\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 0s 154us/step - loss: 1.0356 - accuracy: 0.6088\n",
      "lr=0.0001, train complete\n",
      "--- 478.1248540878296 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.01),metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=50, batch_size=300)\n",
    "print('lr=0.01, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=200, batch_size=250)\n",
    "print('lr=0.001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=200, batch_size=200)\n",
    "print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.00001),metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=200, batch_size=200)\n",
    "print('lr=0.00001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=200, batch_size=250)\n",
    "print('lr=0.001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=200, batch_size=200)\n",
    "print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.00001),metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=50, batch_size=200)\n",
    "print('lr=0.00001, train complete')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1503237f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD/CAYAAADPJgxuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAcyUlEQVR4nO3de7wcZZ3n8c83CSAYknCRCEGJKMguKihZdL2sXLyAsoAjKLAjFy8ZFQUdXwIOzjq6owZvvFhHWINcRe7IRQUUQWB05CZgAgYRESQhBCVAgqJwTv/2j6rjNE33qao+Xae66nzfeT2vU/3U00893enz9HOeei6KCMzMbPJNq7oAZmZTlStgM7OKuAI2M6uIK2Azs4q4AjYzq4grYDOzirgCNjOryIysBJK2A/YB5qVRK4DLImJZmQUzM2u6cVvAko4GzgUE3JQGAedIOqb84pmZNZfGmwkn6W5g+4h4uiN+XeDOiNim5PKZmTVWVhdEC9gCuL8jfvP0XFeSFgILATR99k7Tpj13ImU0syli5KkVmmgeT//x3tzrK6yz6dYTvt5EZFXAHwOulvQb4IE07oXAS4CP9HpSRCwGFgPMWHeeF5sws8nTGq26BLmNWwFHxJWStgV25pk34W6OiPq8SjObOqLnH+dDJ3MURES0gBsmoSxmZhPXalAFPFFrz/qH3Gk3/PtvllgSM5sKYnSk6iLkVnoFbGY2qZrUBWFmVitNuQlnZlY7bgGbmVXEN+HMzKrhm3BmZlVxF4SZWUVqdBPO6wGbWbNEK3/IIOlUSQ9LuqMt7suS7pK0RNLFkuak8fMlPSnp9jT8v6z8XQGbWbO0WvlDttOBPTrirgJeFhGvAO4GPtV27rcRsWMaPpiVeeldEEVmt6294Mhiee9/QtHimFnTDbAPOCKulzS/I+5HbQ9vAPbrN3/3AZtZo8To09mJBue9wHltj18k6TZgDfDpiPj38Z7sCtjMmqVAC7h97fLU4nQ53TzPPRYYAb6TRq0EXhgRj0jaCbhE0vYRsaZXHnn3hJsH3BgRT7TF7xERV+YpqJnZpCkwEaN97fIiJB0K7AXsHum2QhHxV+Cv6fEvJP0W2Ba4pVc+WXvCHQFcCnwUuEPSPm2nv1C00GZmpRvgKIhuJO0BHAXsHRF/bot/nqTp6fHWwDbAvePlldUC/gCwU0Q8kXZEXyhpfkScQLI5Z68Ctm9JhLckMrNJM8BxwJLOAXYBNpW0HPgMyaiH9YCrJAHckI54+B/A5yQ9TbJl2wcjYvV4+WdVwNPGuh0i4j5Ju5BUwlsxTgXsLYnMrDIDnIocEQd2iT6lR9qLgIuK5J81DniVpB3bLvAESb/HpsDLi1zIzGxSlNwFMUhZLeCDSe7y/U1EjAAHS/L2FWY2fJqyGlpELB/n3M8GXxwzswlqSgU82YrObHvywXHHOD/L+lu8oVB6M6ufOm3YPlQVsJnZhLkFbGZWES/IbmZWkSEY3ZCXK2AzaxZ3QZiZVcQtYDOzirgFbGZWEVfAZmYV8SgIM7OKuA94chSd2bbmy/8zd9pZn/xeobx7Lg3XwzAtEVek7GWW+4WzNiuU/vdrHi6pJFZr7oIwM6uIW8BmZhWpUQs4az3gZ5F0ZhkFMTMbiNHR/KFi47aAJV3WGQXsKmkOQETsXVbBzMz6UqMWcFYXxJbAr4Bvkdx/EbAA+Op4T/KecGZWmRpVwFldEAuAXwDHAo9HxLXAkxFxXURc1+tJEbE4IhZExAJXvmY2qZqyJVFEtIDjJV2Q/lyV9Rwzs0rVqAWcqzJNtybaX9LbgTXlFsnMbAJimEbZj69QazYifgD8oKSymJlN3IinIg+lIrPb1p50YKG8N/zQOYXSD8vss8nIPy/PbLOBGIK+3bymVAVsZs0XrWFpUmRzBWxmzdK0m3BmZrXhLggzs4q4C8LMrCIeBWFmVpGmjgM2Mxt6vglnZlYR9wHXX9GJFasP2b5Q+o3PuLNQ+roqus3QAwUmY9Tn18wm1QBHQUg6FdgLeDgiXpbGbQycB8wH7gPeFRGPShJwAvA24M/AoRFx63j5F16Q3awsRSpfs15iZDR3yOF0YI+OuGOAqyNiG+Dq9DHAnsA2aVgInJSVuStgM2uWVuQPGSLiemB1R/Q+wBnp8RnAvm3xZ0biBmCOpM3Hy98VsJk1S4H1gCUtlHRLW1iY4wpzI2JlevwQMDc9ngc80JZueRrXU9aWRK8GlkXEGknrkzS1X0WyS8YXIuLxHIU1M5s8BW7CRcRiYHG/l4qIkNT37YisFvCpJJ3JkHQuzwaOS+NO6/eiZmalabXyh/6sGutaSH+O3bxYAbygLd2WaVxPWRXwtIgYm1ayICI+FhE/jYjPAlv3elJ7s77V+lPGJczMBmiAfcA9XAYckh4fAlzaFn+wEq8h2cZtZbcMxmRVwHdIOiw9/qWkBQCStgWe7vUk7wlnZpUZ4Lb0ks4Bfg68VNJySe8DFgFvlvQb4E3pY4DLgXuBe4CTgQ9n5Z81Dvj9wAmSPg38Efi5pAdIOprfn1l6M7NJFgOcCRcRvXZm2L1L2gAOL5J/1qacjwOHSpoFvChNvzwiVhW5iJnZpGnaTLiIWAP8suSy1FrRmW1rz83/RbnhAd8oWpyh4W2GuhumLakap2kVsJlZbXhBdjOzirgFbGZWjRhxC9jMrBpeD9jMrCLugjAzq4grYDOzaoT3hDMzq4hvwpmZVSPcBWFZisxuW/vjzxfL+03HFi2OTbL6VBE15ArYzKwi9emBcAVsZs3iLggzs6o0pQKWtC5wAPBgRPxY0kHAa4FlwOKI6Lkou5lZFWKkIRUwyb5vM4ANJB0CzAS+S7IY8c7857YcZmbDoUF9wC+PiFdImkGyudwWETEq6SzGWR843dp5IYCmz8bbEpnZZKlTH3DmppxpN8SGwAYkuyIDrAes0+tJ3hPOzCrTKhAqltUCPgW4C5gOHAtcIOle4DXAuSWXzcyssBqtx565J9zxks5Ljx+UdCbJLqAnR8RNk1FAM7MiYqTqEuSXOQwtIh5sO34MuLCswqwzvdiouKdHa/ROT0DRmW1r/u9+hdLPOqK0/1KzydeUFrCZWd00pgvCzKxuXAGbmVXEFbCZWVVCVZcgN1fAZtYorRFXwGZmlXAXhJlZRcJdEGZm1XAL2MysItFyC7gvZc9s22j9mbnTPvrkEyWWpFxFZ7Y99vFX50475/gbixYnt+fMWLdQ+r+MPFVSSazOBrUrvaSXAue1RW0N/G9gDvAB4A9p/D9FxOX9XGOoKmAzs4lqjWQt8phPRPwa2BFA0nSSJXkvBg4Djo+Ir0z0Gq6AzaxRBtUC7rA78NuIuF8aXBfHYL4qzMyGRLSUO0haKOmWtrCwR7YHAOe0Pf6IpCWSTpW0Ub9ldQVsZo0SoQLhPzePSMPizvzSTSn2Bi5Io04CXkzSPbES+Gq/ZS2lC8JbEplZVUoYhrYncGtErAIY+wkg6WTg+/1mPG4LWNJsSYsk3SVptaRHJC1L4+b0ep63JDKzqoy2puUOOR1IW/eDpM3bzr0DuKPfsmaV4HzgUWCXiNg4IjYBdk3jzu/3omZmZSnSB5xF0nOBN5PsBj/mS5KWSlpCUh9+vN+yZnVBzI+I49ojIuIh4DhJ7+33omZmZRnkKIiI+BOwSUfcewaVf1YL+H5JR0maOxYhaa6ko4EHBlUIM7NBGWQLuGxZLeB3A8cA10naLI1bBVwG7F9mwcrw5NOeOdVNkdltK167TaG8/9dv18uddvlfVxfK+57HHsxOZFNOqymL8UTEo8DRaXgGSYcBp5VULjOzvtRpNbSJjAP+7MBKYWY2IKMt5Q5VG7cFnN7l63oKmNvjnJlZZerUAs7qA54LvJVk2Fk7Af9RSonMzCagpLUgSpFVAX8fmBkRt3eekHRtKSUyM5uAJt2Ee9845w4afHHMzCamSV0QZma10pgWsJlZ3Yy6AjYzq4a7IIaU9xCbuB1uX5WdqM1vDtgqf94XlrsnoE0NNdoUeWpVwGbWfIFbwGZmlWg1aBywmVmtjNZopzVXwGbWKFO+D9h7wplZVerUB5y1J9wsSV+U9G1JB3WcO7HX87wnnJlVpVUgVC2rs+Q0koV3LgIOkHSRpLEVtl9TasnMzPpQpwo4qwvixRHxzvT4EknHAtdI2rvkcpmZ9aVOXRBZFfB6kqZFRAsgIj4vaQVwPTCz9NKZmRU0ouZUwN8DdgN+PBYREadLegj4epkFK8NG6+f/znj0ySdKLMlwKfJxfeKpvxTK+7+cvzx32iVv2CQ7UZvNrni4UHqbGmo0DDhzOcqjesRfKekL5RTJzKx/w9C3m5f3hDOzRmlJuUPVvCecmTVKY7og8J5wZlYzdeqC8J5wZtYojRkF4T3hzKxumtQFYWZWK636NIBdAZtZszSpD9jMrFbcBTGkptLstiKKfGCL7qv30BP50292Redgm/GtvfyfC6V/3t7H5U7r/QPra2SAXRCS7gPWAqPASEQskLQxcB4wH7gPeFdEFPvwpuqzdLyZWQ4lrIa2a0TsGBEL0sfHAFdHxDbA1enjvrgCNrNGCeUPfdoHOCM9PgPYt9+MXAGbWaMMuAUcwI8k/SLd6QdgbkSsTI8fYgKzggv3AUvaLCK8DJWZDaUioyDat09LLY6IxW2PXx8RKyRtBlwl6a7250dESOr7vl/WWhAbd0YBN0l6JaCIWN3jed4TzswqUaQ2TCvbxeOcX5H+fFjSxcDOwCpJm0fESkmbA303SLNawH8E7u+ImwfcSvI6t+5R6L+9qBnrzqvTqBAzq7lBjYKQ9FxgWkSsTY/fAnwOuAw4BFiU/ry032tkVcCfBN4MfDIilqaF+l1EvKjfC5qZlWmAEzHmAhcrWVtiBnB2uhb6zcD5kt5H0kB9V78XyFoL4quSzgOOl/QA8BnqNc7ZzKaYQVVQEXEvsEOX+EeA3QdxjcybcBGxHNg/3YjzKmCDQVzYbKL+8f3XFEr/nVn/PXfad66+rmhxbEjUaS2I3MPQIuIyYFfgTQCSDiurUGZm/arTtvSFxgFHxJMRcUf60FsSmdnQiQKhat6SyMwaZWQoqtZ8vCWRmTVKfapfb0lkZg0zDH27eXlLIjNrlDqNgphS6wGbWfO1atQJ4QrYzBpltOoCFOAK2MwaxS1gs0lw8oM/K5a+QNq15x5eKO8ND/hGofRWnvpUv66AzaxhGjMKwsysbtwFYWZWkfpUv66AzaxhRmtUBRfelFPSJmUUxMxsEBqzGpqkRZI2TY8XSLoXuFHS/ZLeOM7zFkq6RdItrdafBlxkM7PeWkTuULWsFvDbI+KP6fGXgXdHxEtItin6aq8nRcTiiFgQEQu8IaeZTabGLEcJzJA0IyJGgPUj4maAiLhb0nrlF8/MrJhhaNnmlVUBnwhcLmkRcKWkE4DvArsBz1ohzcysanW6CZe1GtrXJS0FPgRsm6bfBrgE+D/lF6+5iizYVJ+PU3MUndn2xPVfK5R+092OyZ32LyNPFcp7qhuGm2t55dmU81rg2s74dE+40wZfJDOz/kWNmiyFh6G18Z5wZjZ06jQMzXvCmVmjtKI+LWDvCWdmjVKf6td7wplZw4wORedCPt4TzswapT7VrxfjMbOGadJEDDOzWqnTMDRXwGbWKO6CaIDp04oNkR5t1em/3QbtUwdcXCj95bMW5E6722oPOCoiajQMbSITMczMhs4IkTuMR9ILJP1E0q8k3SnpyDT+XyStkHR7Gt7Wb1ndAjazRhlgH/AI8ImIuFXShsAvJF2Vnjs+Ir4y0Qu4AjazRhnUKIiIWAmsTI/XSloGzBtI5il3QZhZo0RE7pCXpPnAK4Eb06iPSFoi6VRJG/VbVlfAZtYoRRbjad8+LQ0LO/OTNBO4CPhYRKwBTgJeDOxI0kLuuTtQlqw94RakndBnpR3SV0l6XNLNkl45zvO8J5yZVWKUVu7Qvn1aGha35yVpHZLK9zsR8V2AiFgVEaMR0QJOBnbut6xZLeATgS8BPyBZfOebETEbOCY915X3hDOzqgyqC0KSgFOAZRHxtbb4zduSvQO4o9+yZt2EWycirkgvelxEXAgQEVdLmvAdQDOzQRvgVOTXAe8BlkoaW5Dsn4ADJe1IsvDafcA/9HuBrAr4L5LeAswGQtK+EXFJuiX9aL8XNTMry6CGoUXET+m+e9jlA7kA2RXwB0m6IFok6wJ/SNLpwArgA4MqxDAqe2ZbfebqDK91phcbRfn06EhJJYGvP/jvxdIXSLtmUbFx/rOOKVY/PGfGurnT/rXg/nRVfM7rtCD7uH3AEfHLiHhrROwZEXdFxJERMScitgdeOkllNDPLLQqEqnlPODNrlBFauUPVvCecmTVKnRbj8Z5wZtYoTVqQ3XvCmVmtNGZBdu8JZ2Z106QuCDOzWmlSF4SZWa2MRvWjG/JyBWxmjdKYPmCzYVbmzLZhMrvgzLa1ZxVbmmDW33+zUPphV6eZcK6AzaxR3AI2M6uIW8BmZhWp0024rB0xZktaJOkuSaslPSJpWRo3Z7IKaWaWVxT4V7WsxXjOJ5mGvEtEbBwRmwC7pnHn93qStyQys6q0InKHqmVVwPMj4riIeGgsIiIeiojjgK16PclbEplZVZrUAr5f0lGS/rbymaS5ko4GHii3aGZmxUW0coeqZVXA7wY2Aa6T9Kik1cC1wMbAu0oum5lZYS0id6ha1mI8j0o6DbgKuCEinhg7J2kP4MqSy2dmVkidRkFovJWDJB0BHA4sA3YEjoyIS9Nzt0bEq7IuMGPdedV/zZjVWLddIQdpzbmH504756CTCuVddG/FkadWTPjlztto+9x1zopH7yz77R1X1jjgDwA7RcQTkuYDF0qaHxEnUP7nwsyssGEY3ZBXVgU8bazbISLuk7QLSSW8Fa6AzWwIDcPohryybsKtkrTj2IO0Mt4L2BR4eZkFMzPrR0TkDlXLagEfDDxjyamIGAEOltSsJZTMrBGGYXRDXlmjIJaPc+5ngy+OmdnEFL3xVyUvxmNmjTIMXQt5uQI2s0ZpTBeEmVnduAVsZlaROo0DHncm3CB4JpxZc6w99dBC6Td87+mF0g9iJtz662+Vu8558sn7h3omnJlZrdSpCyJrIoaZWa0Mcj1gSXtI+rWkeyQdM+iyugVsZo0yqBawpOnAN4A3A8uBmyVdFhG/GsgFyN4TbpakL0r6tqSDOs6dOKhCmJkNygCnIu8M3BMR90bEU8C5wD6TVljgImARsC9wWfp4vfTcreM8byFwSxoW9kpT8I3Knb7MvF2Wqf06XZZqylJW6KirnlFfAfsB32p7/B7g3wZ6/YzC3d7x+FjgZyS7ZPSsgHO+8FvKSl9m3i7L1H6dLks1ZakiTEYFnNUHvJ6kaZFunhQRn5e0ArgemJnxXDOzOlsBvKDt8ZZp3MBkjYL4HrBbe0REnA58AnhqkAUxMxsyNwPbSHqRpHWBA0i6Ygdm3Ao4Io4ClkvaXdLMtvgrgSMmeO3FJaYvM++i6adKWabK6yya3mUZTN6TLpKldz8C/JBkW7bzI+LOQV4ja0+4j6YF6HtPODMz6y6rD3gh3hPOzKwU3hPOzKwi3hPOzKwiWX3AWwIjEfFQl3OviwLbEknajmQWybw0agVwWUQsK1bknnnPA24ca7Gn8XukNww70+8MRETcLOm/AnsAd0XE5TmudWZEHJyzXK8nmU1zR0T8qMv5VwPLImKNpPWBY4BXAb8CvhARj7elPQK4OCIeyHntsbu2D0bEj9OZjK8l6c9fHBFPd6TfGvg7kmE3o8DdwNkRsSbP9cysuNKXowSQdDRwIMlUvrF95rYkqSDOjYhFBfI6LCJOa3t8BHA4OW8USvoMsCdJ98tVwKuBn5DM9/5hRHy+LW3nkBMBuwLXAETE3h153xQRO6fHH0jLdTHwFuB7na9T0p3ADhExImkx8GfgQmD3NP7v2tI+DvwJ+C1wDnBBRPxhnPfpO+lr3AB4jGTc9nfTvBURh3S8h3uRjO9+G3Bb+px3AB+OiGt7XacJJG0WEQ+XlPcmEfFIGXkPkqTZwKdIZr1uBgTwMHApsCgiHsuZzxURsWdH3Kw07y2BKyLi7LZzJ0bEhwfzKmpokmaU3A2s0yV+XeA3BfP6fcfjpcDM9Hg+yXTCI9PHt3V5/lJgOknFtAaYlcavDyzpSHsrcBawC/DG9OfK9PiNXfK+re34ZuB56fFzgaVd0i9rv1bHuc5ZiLeRdBm9BTgF+ANwJXAIsGGXvJekP2cAq4Dp6WN1eZ1L285vAFybHr+w23uYnptNMk39LmA18AjJl+AiYE6B/88rusTNAr4IfBs4qOPciV3SPx84iWThlE2Af0lf0/nA5h1pN+4ImwD3ARsBG3fJe4+O13wKsAQ4G5jbkXYRsGl6vAC4F7gHuL/H5+VW4NPAi3O+VwtIGgtnkfylchXwePpZe2VH2pnA54A70zR/AG4ADu2R9w+Bo4Hnd7yvRwM/6kj7qh5hJ2Bll7z7WtJgKoTJuUjyS7pVl/itgF93iV/SIywF/tqR9s4uH7wrga/RUYml52/rdpw+7qz0pgEfTz/oO6Zx947zOn+Z/iJvQsdUy85rpXEXAIelx6cBC9LjbYGbO9J2VtDrAHuTtIb/0CXvO0i+4DYC1o5VLsBzaKv407ilbb8QG7WXnaT7pNtrHZpf2PT/+6MkXThL0jK8II27tCNtC/hdR3g6/fms/9v26wHfAv41/dx+HLik831sO/4J8N/a/j+fNfU2veZXgN8DN6V5bjHO5+smkr/eDgQeAPZL43cHft6R9lLgUJJW5z8C/wxsA5xB0r3Vmfezfg97nSPporomfY2d4ckuzy9tSYO6h8m5SNLHeg9wBckA7MXpL809tLUw2tKvIulO2KojzCfp02xPew1p5dgWNwM4ExjtkveNwAbp8bS2+Nm9Pgzph/gC4N/oaIF3pLuPpNXzu/Tn5mn8zM4PYds1TyfpVrgxrQjuBa4j6YJoT9u1JZqe26BL3MfTvO4nmTRzNXAySWX7mY60R5JUXCeTfFmOfSk8D7i+xzWH5heWZ36pdv6F1JnXJ9LP3svb4n43zmu5dZy8Oh8vA2akxzd0nOv2F1B73m8ATgQeSt+XZy1Wk/E6OxsTv+x4fPPYZ57kfkdn3j8CjqKtVQ/MJfky+3FH2juAbXq8Xw90iVtG2+9aGncoSev8/l7v/VQIk3eh5D/+NcA70/Aa0j97u6Q9BXh9j3NndzzekrZWWMe513WJW69H2k3bfyl7pHk7XVoPOV77BsCLxjk/C9iBpEU4t0eabfu47hakLSpgDsniIjv3SLt9en67nHkPzS9se2UD/GvHuW4V39gX6teADRn/r5rlJC3IT5B8oantXGdXzkfT92U3km6QE0i6qz4LfLtL3t2+TKaTNFhO63Lu5yRdUPuTfLHum8a/kWf/xfUfY79DJH8p/bDtXLe/OjcCjiP5An6UpFtpWRq3cUfa/YCX9ni/9u0S9yXgTV3i96BgF2TTQuUFcKhn6PiFXd3xC7tRR9pSf2FJ+jpndol/CXDhOK9hb5J+0YfGSfOZjjDWr/984Mwu6XcBziPps18KXE4yoWlGl7TnFnzPdyDp+rkC2C6t4B8j+WJ6bUfaV5B0WTwK/JT0C5zkr5ojeuS/HfCmzveS7n+lbkfS9ZGZNiP9nlV/lqsMlRfAoXmBtAtj0GnLSE9y8/VlZZel6teZlZakm+rXwCUkXWn7tJ3rvP+QO20a99Ei6adSqLwADs0LjNNPPpG0Zaeva96DKAsFRhMVSdtP+qkUvCec9UXSkl6nSPqC+0pbdvq65l12WSi27EDRJQq8pEEProCtX3OBt5L0MbYTyQ2gftOWnb6ueZddllWSdoyI2yFZdkDSXsCpPHvZgSJp+0k/ZbgCtn59n+TPyts7T0i6dgJpy05f17zLLsvBwEh7RCTr4R4s6ZsTSNtP+iljUqYim5nZs2WthmZmZiVxBWxmVhFXwGZmFXEFbGZWEVfAZmYV+f9gvZkMrSlfBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(X)\n",
    "pred = pred.argmax(axis=1)\n",
    "cm = confusion_matrix(y,pred)\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(model,'../output/nn.m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
