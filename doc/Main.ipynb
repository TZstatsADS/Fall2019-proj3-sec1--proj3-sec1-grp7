{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rui\\Anaconda3\\envs\\data\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\rui\\Anaconda3\\envs\\data\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rui\\Anaconda3\\envs\\data\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rui\\Anaconda3\\envs\\data\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rui\\Anaconda3\\envs\\data\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rui\\Anaconda3\\envs\\data\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rui\\Anaconda3\\envs\\data\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Flatten, Input,Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "%run ../lib/load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 23.873502731323242 seconds ---\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/rui/Desktop/train_set/'\n",
    "data = load.load_data(path+'label.csv')\n",
    "points_path = 'C:/Users/rui/Desktop/train_set/points/'\n",
    "X = load.load_points(points_path,data)\n",
    "y = data['emotion_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=train_test_split(X,y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1308.2316908836365 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "gbmtree_model = GradientBoostingClassifier(max_depth = 1).fit(train_x,train_y) \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 39.60%\n"
     ]
    }
   ],
   "source": [
    "gbm_predictions = gbmtree_model.predict(test_x)\n",
    "gbm_predictions = [round(value) for value in gbm_predictions]\n",
    "gbm_accuracy = np.mean(test_y==gbm_predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (gbm_accuracy *  100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x149838cc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_predictions = gbmtree_model.predict(test_x) \n",
    "cn = confusion_matrix(test_y,gbm_predictions)\n",
    "sns.heatmap(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.67      0.60        18\n",
      "           2       0.57      0.68      0.62        19\n",
      "           3       0.24      0.32      0.27        25\n",
      "           4       0.35      0.52      0.42        21\n",
      "           5       0.50      0.56      0.53        18\n",
      "           6       0.32      0.27      0.29        26\n",
      "           7       0.37      0.50      0.43        20\n",
      "           8       0.65      0.69      0.67        16\n",
      "           9       0.71      0.48      0.57        25\n",
      "          10       0.35      0.40      0.37        20\n",
      "          11       0.48      0.50      0.49        24\n",
      "          12       0.38      0.28      0.32        32\n",
      "          13       0.12      0.12      0.12        24\n",
      "          14       0.45      0.61      0.52        23\n",
      "          15       0.44      0.32      0.37        22\n",
      "          16       0.62      0.59      0.60        22\n",
      "          17       0.40      0.46      0.43        26\n",
      "          18       0.47      0.32      0.38        22\n",
      "          19       0.32      0.43      0.37        23\n",
      "          20       0.06      0.05      0.05        20\n",
      "          21       0.32      0.18      0.23        34\n",
      "          22       0.20      0.10      0.13        20\n",
      "\n",
      "    accuracy                           0.40       500\n",
      "   macro avg       0.40      0.41      0.40       500\n",
      "weighted avg       0.40      0.40      0.39       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y,gbm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbmtree_model_final = GradientBoostingClassifier(max_depth = 1).fit(X,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(gbmtree_model_final,'../output/gbm_base.m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(y)\n",
    "Y = Y[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rui\\Anaconda3\\envs\\data\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_shape = [6006] \n",
    "input_layer = Input(input_shape)\n",
    "x = BatchNormalization()(input_layer) \n",
    "x = Dense(96,activation='relu',kernel_initializer=initializers.glorot_normal(seed=None))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x) \n",
    "x = Dense(16,activation='relu',kernel_initializer=initializers.glorot_normal(seed=None))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(22,activation='softmax',kernel_initializer=initializers.glorot_normal(seed=None))(x) \n",
    "model = Model(input_layer,output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Accuracy Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 2s 759us/step - loss: 1.7561 - accuracy: 0.3625 - val_loss: 1.5734 - val_accuracy: 0.4220\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.7893 - accuracy: 0.3565 - val_loss: 1.5512 - val_accuracy: 0.4340\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 1s 278us/step - loss: 1.7743 - accuracy: 0.3790 - val_loss: 1.5497 - val_accuracy: 0.4560\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.7520 - accuracy: 0.3765 - val_loss: 1.5566 - val_accuracy: 0.4540\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.7050 - accuracy: 0.3865 - val_loss: 1.5210 - val_accuracy: 0.4440\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 1.7124 - accuracy: 0.3780 - val_loss: 1.5080 - val_accuracy: 0.4620\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.7357 - accuracy: 0.3755 - val_loss: 1.5034 - val_accuracy: 0.4720\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 1s 282us/step - loss: 1.6554 - accuracy: 0.3860 - val_loss: 1.5138 - val_accuracy: 0.4620\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.6292 - accuracy: 0.4025 - val_loss: 1.5157 - val_accuracy: 0.4760\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.6395 - accuracy: 0.4045 - val_loss: 1.5418 - val_accuracy: 0.4740\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.6514 - accuracy: 0.4155 - val_loss: 1.4933 - val_accuracy: 0.4560\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.5818 - accuracy: 0.4300 - val_loss: 1.4784 - val_accuracy: 0.4600\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.6646 - accuracy: 0.3945 - val_loss: 1.5173 - val_accuracy: 0.4360\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.6231 - accuracy: 0.4210 - val_loss: 1.5263 - val_accuracy: 0.4320\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.6114 - accuracy: 0.4215 - val_loss: 1.5327 - val_accuracy: 0.4380\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 1s 286us/step - loss: 1.6172 - accuracy: 0.4180 - val_loss: 1.4722 - val_accuracy: 0.4760\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.5628 - accuracy: 0.4170 - val_loss: 1.4903 - val_accuracy: 0.4640\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.6288 - accuracy: 0.4070 - val_loss: 1.4523 - val_accuracy: 0.4620\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.5810 - accuracy: 0.4290 - val_loss: 1.4756 - val_accuracy: 0.4660\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.5548 - accuracy: 0.4205 - val_loss: 1.4920 - val_accuracy: 0.4580\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.6055 - accuracy: 0.4260 - val_loss: 1.4893 - val_accuracy: 0.4500\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 1s 287us/step - loss: 1.5573 - accuracy: 0.4390 - val_loss: 1.4805 - val_accuracy: 0.4860\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.5774 - accuracy: 0.4285 - val_loss: 1.4656 - val_accuracy: 0.4780\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.5658 - accuracy: 0.4330 - val_loss: 1.4901 - val_accuracy: 0.4740\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.5182 - accuracy: 0.4410 - val_loss: 1.4764 - val_accuracy: 0.4540\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.5120 - accuracy: 0.4525 - val_loss: 1.5119 - val_accuracy: 0.4540\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.5298 - accuracy: 0.4400 - val_loss: 1.4302 - val_accuracy: 0.5000\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.5527 - accuracy: 0.4365 - val_loss: 1.4556 - val_accuracy: 0.5040\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.4991 - accuracy: 0.4505 - val_loss: 1.4855 - val_accuracy: 0.4800\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.5058 - accuracy: 0.4520 - val_loss: 1.4841 - val_accuracy: 0.4800\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.5101 - accuracy: 0.4455 - val_loss: 1.4506 - val_accuracy: 0.4960\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.4852 - accuracy: 0.4430 - val_loss: 1.3927 - val_accuracy: 0.5080\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.5024 - accuracy: 0.4370 - val_loss: 1.4328 - val_accuracy: 0.5080\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 1s 267us/step - loss: 1.5069 - accuracy: 0.4615 - val_loss: 1.5136 - val_accuracy: 0.5100\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.4898 - accuracy: 0.4485 - val_loss: 1.4810 - val_accuracy: 0.4880\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 1s 274us/step - loss: 1.4590 - accuracy: 0.4565 - val_loss: 1.4865 - val_accuracy: 0.4880\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 1s 262us/step - loss: 1.4799 - accuracy: 0.4530 - val_loss: 1.4819 - val_accuracy: 0.4880\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.4605 - accuracy: 0.4655 - val_loss: 1.4438 - val_accuracy: 0.5140\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.4478 - accuracy: 0.4530 - val_loss: 1.5026 - val_accuracy: 0.4800\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 1.4648 - accuracy: 0.4695 - val_loss: 1.5083 - val_accuracy: 0.4920\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.4402 - accuracy: 0.4785 - val_loss: 1.5074 - val_accuracy: 0.4800\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.4486 - accuracy: 0.4730 - val_loss: 1.5540 - val_accuracy: 0.4820\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.4498 - accuracy: 0.4735 - val_loss: 1.5551 - val_accuracy: 0.4740\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.4252 - accuracy: 0.4810 - val_loss: 1.4893 - val_accuracy: 0.5160\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.4847 - accuracy: 0.4700 - val_loss: 1.4763 - val_accuracy: 0.5060\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.4279 - accuracy: 0.4820 - val_loss: 1.4482 - val_accuracy: 0.5080\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.4365 - accuracy: 0.4720 - val_loss: 1.4556 - val_accuracy: 0.5000\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.4271 - accuracy: 0.4735 - val_loss: 1.4513 - val_accuracy: 0.5000\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.4033 - accuracy: 0.4755 - val_loss: 1.4556 - val_accuracy: 0.5160\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.4342 - accuracy: 0.4825 - val_loss: 1.4309 - val_accuracy: 0.5120\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 2s 877us/step - loss: 1.3786 - accuracy: 0.4930 - val_loss: 1.4409 - val_accuracy: 0.5020\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.3975 - accuracy: 0.4845 - val_loss: 1.4441 - val_accuracy: 0.5120\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.3706 - accuracy: 0.4975 - val_loss: 1.4495 - val_accuracy: 0.5260\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.3460 - accuracy: 0.5030 - val_loss: 1.4543 - val_accuracy: 0.5200\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.3552 - accuracy: 0.5160 - val_loss: 1.4578 - val_accuracy: 0.5220\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.3305 - accuracy: 0.5000 - val_loss: 1.4536 - val_accuracy: 0.5220\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.3222 - accuracy: 0.4980 - val_loss: 1.4504 - val_accuracy: 0.5320\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.2939 - accuracy: 0.5170 - val_loss: 1.4518 - val_accuracy: 0.5380\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.3366 - accuracy: 0.4915 - val_loss: 1.4551 - val_accuracy: 0.5380\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.3033 - accuracy: 0.5080 - val_loss: 1.4540 - val_accuracy: 0.5380\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.2833 - accuracy: 0.5235 - val_loss: 1.4589 - val_accuracy: 0.5340\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.2804 - accuracy: 0.5240 - val_loss: 1.4619 - val_accuracy: 0.5260\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.2860 - accuracy: 0.5265 - val_loss: 1.4699 - val_accuracy: 0.5360\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.3020 - accuracy: 0.5165 - val_loss: 1.4748 - val_accuracy: 0.5360\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.2700 - accuracy: 0.5375 - val_loss: 1.4734 - val_accuracy: 0.5360\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.3099 - accuracy: 0.5205 - val_loss: 1.4725 - val_accuracy: 0.5340\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.2805 - accuracy: 0.5195 - val_loss: 1.4724 - val_accuracy: 0.5300\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.2826 - accuracy: 0.5175 - val_loss: 1.4675 - val_accuracy: 0.5240\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.2687 - accuracy: 0.5310 - val_loss: 1.4618 - val_accuracy: 0.5280\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.2966 - accuracy: 0.5280 - val_loss: 1.4556 - val_accuracy: 0.5220\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.2702 - accuracy: 0.5225 - val_loss: 1.4612 - val_accuracy: 0.5220\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.2685 - accuracy: 0.5420 - val_loss: 1.4746 - val_accuracy: 0.5180\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.2581 - accuracy: 0.5275 - val_loss: 1.4786 - val_accuracy: 0.5240\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.2527 - accuracy: 0.5250 - val_loss: 1.4771 - val_accuracy: 0.5220\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.2793 - accuracy: 0.5290 - val_loss: 1.4689 - val_accuracy: 0.5320\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.2549 - accuracy: 0.5370 - val_loss: 1.4741 - val_accuracy: 0.5420\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.2920 - accuracy: 0.5240 - val_loss: 1.4847 - val_accuracy: 0.5380\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.2968 - accuracy: 0.5230 - val_loss: 1.4900 - val_accuracy: 0.5160\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.2672 - accuracy: 0.5240 - val_loss: 1.4900 - val_accuracy: 0.5140\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.2396 - accuracy: 0.5400 - val_loss: 1.4910 - val_accuracy: 0.5180\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.2564 - accuracy: 0.5315 - val_loss: 1.4897 - val_accuracy: 0.5220\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.2784 - accuracy: 0.5305 - val_loss: 1.4866 - val_accuracy: 0.5240\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.2655 - accuracy: 0.5330 - val_loss: 1.4842 - val_accuracy: 0.5180\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.2472 - accuracy: 0.5505 - val_loss: 1.4932 - val_accuracy: 0.5100\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.2464 - accuracy: 0.5445 - val_loss: 1.4996 - val_accuracy: 0.5080\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.2196 - accuracy: 0.5385 - val_loss: 1.5029 - val_accuracy: 0.5100\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.2578 - accuracy: 0.5345 - val_loss: 1.5006 - val_accuracy: 0.5140\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.2507 - accuracy: 0.5335 - val_loss: 1.5062 - val_accuracy: 0.5100\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.2294 - accuracy: 0.5385 - val_loss: 1.5053 - val_accuracy: 0.5180\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.2592 - accuracy: 0.5295 - val_loss: 1.5102 - val_accuracy: 0.5120\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.2271 - accuracy: 0.5440 - val_loss: 1.5109 - val_accuracy: 0.5200\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.2212 - accuracy: 0.5505 - val_loss: 1.4764 - val_accuracy: 0.5240\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.2231 - accuracy: 0.5480 - val_loss: 1.4656 - val_accuracy: 0.5260\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.2312 - accuracy: 0.5435 - val_loss: 1.4706 - val_accuracy: 0.5260\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.2218 - accuracy: 0.5335 - val_loss: 1.4797 - val_accuracy: 0.5120\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.2546 - accuracy: 0.5300 - val_loss: 1.4806 - val_accuracy: 0.5180\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.1974 - accuracy: 0.5430 - val_loss: 1.4822 - val_accuracy: 0.5200\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 1.2183 - accuracy: 0.5565 - val_loss: 1.4834 - val_accuracy: 0.5180\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.2554 - accuracy: 0.5230 - val_loss: 1.4964 - val_accuracy: 0.5100\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.2312 - accuracy: 0.5405 - val_loss: 1.5016 - val_accuracy: 0.5180\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.2049 - accuracy: 0.5545 - val_loss: 1.4828 - val_accuracy: 0.5200\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.2526 - accuracy: 0.5285 - val_loss: 1.4642 - val_accuracy: 0.5280\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.1876 - accuracy: 0.5715 - val_loss: 1.4745 - val_accuracy: 0.5200\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.2356 - accuracy: 0.5405 - val_loss: 1.4812 - val_accuracy: 0.5200\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.2036 - accuracy: 0.5480 - val_loss: 1.4929 - val_accuracy: 0.5160\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.2471 - accuracy: 0.5415 - val_loss: 1.4977 - val_accuracy: 0.5180\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.2330 - accuracy: 0.5215 - val_loss: 1.5036 - val_accuracy: 0.5180\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 1.2423 - accuracy: 0.5325 - val_loss: 1.5077 - val_accuracy: 0.5260\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.2346 - accuracy: 0.5360 - val_loss: 1.5084 - val_accuracy: 0.5220\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.2479 - accuracy: 0.5260 - val_loss: 1.5114 - val_accuracy: 0.5180\n",
      "Epoch 61/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.2349 - accuracy: 0.5435 - val_loss: 1.5171 - val_accuracy: 0.5200\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1852 - accuracy: 0.5585 - val_loss: 1.5279 - val_accuracy: 0.5300\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.2180 - accuracy: 0.5360 - val_loss: 1.5428 - val_accuracy: 0.5240\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.2515 - accuracy: 0.5375 - val_loss: 1.5474 - val_accuracy: 0.5240\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 282us/step - loss: 1.2284 - accuracy: 0.5315 - val_loss: 1.5383 - val_accuracy: 0.5300\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.2160 - accuracy: 0.5470 - val_loss: 1.5379 - val_accuracy: 0.5160\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.2147 - accuracy: 0.5475 - val_loss: 1.5266 - val_accuracy: 0.5200\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.2144 - accuracy: 0.5505 - val_loss: 1.5310 - val_accuracy: 0.5300\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.2093 - accuracy: 0.5480 - val_loss: 1.5419 - val_accuracy: 0.5240\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.2402 - accuracy: 0.5445 - val_loss: 1.5473 - val_accuracy: 0.5220\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.2087 - accuracy: 0.5495 - val_loss: 1.5619 - val_accuracy: 0.5240\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.1881 - accuracy: 0.5520 - val_loss: 1.5663 - val_accuracy: 0.5200\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.2176 - accuracy: 0.5470 - val_loss: 1.5720 - val_accuracy: 0.5200\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.1657 - accuracy: 0.5625 - val_loss: 1.5704 - val_accuracy: 0.5180\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.2118 - accuracy: 0.5430 - val_loss: 1.5626 - val_accuracy: 0.5160\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.1881 - accuracy: 0.5630 - val_loss: 1.5495 - val_accuracy: 0.5300\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.1895 - accuracy: 0.5565 - val_loss: 1.5627 - val_accuracy: 0.5240\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.2429 - accuracy: 0.5300 - val_loss: 1.5688 - val_accuracy: 0.5300\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.2148 - accuracy: 0.5470 - val_loss: 1.5752 - val_accuracy: 0.5240\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.1597 - accuracy: 0.5545 - val_loss: 1.5815 - val_accuracy: 0.5220\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.1723 - accuracy: 0.5745 - val_loss: 1.5793 - val_accuracy: 0.5200\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.1900 - accuracy: 0.5505 - val_loss: 1.5699 - val_accuracy: 0.5080\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1671 - accuracy: 0.5505 - val_loss: 1.5720 - val_accuracy: 0.5080\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.1767 - accuracy: 0.5555 - val_loss: 1.5773 - val_accuracy: 0.5160\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.1615 - accuracy: 0.5680 - val_loss: 1.5789 - val_accuracy: 0.5160\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.1844 - accuracy: 0.5550 - val_loss: 1.5822 - val_accuracy: 0.5180\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.1728 - accuracy: 0.5465 - val_loss: 1.5867 - val_accuracy: 0.5200\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.1733 - accuracy: 0.5595 - val_loss: 1.5827 - val_accuracy: 0.5160\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.1662 - accuracy: 0.5660 - val_loss: 1.5717 - val_accuracy: 0.5180\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.1764 - accuracy: 0.5570 - val_loss: 1.5689 - val_accuracy: 0.5240\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 349us/step - loss: 1.2064 - accuracy: 0.5460 - val_loss: 1.5739 - val_accuracy: 0.5180\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1861 - accuracy: 0.5530 - val_loss: 1.5780 - val_accuracy: 0.5180\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.1700 - accuracy: 0.5670 - val_loss: 1.5785 - val_accuracy: 0.5180\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.1857 - accuracy: 0.5570 - val_loss: 1.5922 - val_accuracy: 0.5240\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.1479 - accuracy: 0.5805 - val_loss: 1.6038 - val_accuracy: 0.5140\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 1.1643 - accuracy: 0.5660 - val_loss: 1.6003 - val_accuracy: 0.5160\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.1814 - accuracy: 0.5645 - val_loss: 1.5729 - val_accuracy: 0.5160\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 1.1763 - accuracy: 0.5520 - val_loss: 1.5732 - val_accuracy: 0.5180\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.1516 - accuracy: 0.5810 - val_loss: 1.5652 - val_accuracy: 0.5180\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.1755 - accuracy: 0.5740 - val_loss: 1.5579 - val_accuracy: 0.5120\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.1855 - accuracy: 0.5570 - val_loss: 1.5594 - val_accuracy: 0.5160\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.1958 - accuracy: 0.5415 - val_loss: 1.5524 - val_accuracy: 0.5120\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.2056 - accuracy: 0.5485 - val_loss: 1.5589 - val_accuracy: 0.5140\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.1666 - accuracy: 0.5590 - val_loss: 1.5801 - val_accuracy: 0.5120\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1843 - accuracy: 0.5610 - val_loss: 1.5880 - val_accuracy: 0.5260\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 282us/step - loss: 1.1817 - accuracy: 0.5535 - val_loss: 1.5923 - val_accuracy: 0.5300\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.1550 - accuracy: 0.5585 - val_loss: 1.6031 - val_accuracy: 0.5360\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.1724 - accuracy: 0.5685 - val_loss: 1.6127 - val_accuracy: 0.5340\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.1884 - accuracy: 0.5545 - val_loss: 1.6080 - val_accuracy: 0.5280\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.1409 - accuracy: 0.5645 - val_loss: 1.6099 - val_accuracy: 0.5280\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 272us/step - loss: 1.2099 - accuracy: 0.5545 - val_loss: 1.6028 - val_accuracy: 0.5200\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 1.1572 - accuracy: 0.5595 - val_loss: 1.6007 - val_accuracy: 0.5200\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.1591 - accuracy: 0.5710 - val_loss: 1.6031 - val_accuracy: 0.5220\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 1.1721 - accuracy: 0.5630 - val_loss: 1.6139 - val_accuracy: 0.5080\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.2211 - accuracy: 0.5465 - val_loss: 1.6155 - val_accuracy: 0.5260\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.1308 - accuracy: 0.5900 - val_loss: 1.6087 - val_accuracy: 0.5220\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.1359 - accuracy: 0.5775 - val_loss: 1.6061 - val_accuracy: 0.5240\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 286us/step - loss: 1.1658 - accuracy: 0.5640 - val_loss: 1.5958 - val_accuracy: 0.5260\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1717 - accuracy: 0.5555 - val_loss: 1.6073 - val_accuracy: 0.5300\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.1380 - accuracy: 0.5790 - val_loss: 1.6058 - val_accuracy: 0.5280\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.1443 - accuracy: 0.5590 - val_loss: 1.6118 - val_accuracy: 0.5420\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1378 - accuracy: 0.5725 - val_loss: 1.6240 - val_accuracy: 0.5400\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.1046 - accuracy: 0.5770 - val_loss: 1.6330 - val_accuracy: 0.5360\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.1675 - accuracy: 0.5645 - val_loss: 1.6415 - val_accuracy: 0.5380\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.1497 - accuracy: 0.5625 - val_loss: 1.6466 - val_accuracy: 0.5340\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.1566 - accuracy: 0.5545 - val_loss: 1.6462 - val_accuracy: 0.5280\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1710 - accuracy: 0.5565 - val_loss: 1.6526 - val_accuracy: 0.5340\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.1632 - accuracy: 0.5655 - val_loss: 1.6478 - val_accuracy: 0.5220\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.1846 - accuracy: 0.5530 - val_loss: 1.6461 - val_accuracy: 0.5160\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.1402 - accuracy: 0.5695 - val_loss: 1.6497 - val_accuracy: 0.5160\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.1294 - accuracy: 0.5795 - val_loss: 1.6508 - val_accuracy: 0.5160\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.1259 - accuracy: 0.5700 - val_loss: 1.6664 - val_accuracy: 0.5240\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.1312 - accuracy: 0.5750 - val_loss: 1.6529 - val_accuracy: 0.5320\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.1316 - accuracy: 0.5750 - val_loss: 1.6472 - val_accuracy: 0.5300\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.1701 - accuracy: 0.5580 - val_loss: 1.6652 - val_accuracy: 0.5320\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.1784 - accuracy: 0.5535 - val_loss: 1.6482 - val_accuracy: 0.5280\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.1243 - accuracy: 0.5705 - val_loss: 1.6426 - val_accuracy: 0.5380\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.1214 - accuracy: 0.5825 - val_loss: 1.6475 - val_accuracy: 0.5320\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.1140 - accuracy: 0.5735 - val_loss: 1.6618 - val_accuracy: 0.5320\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.1287 - accuracy: 0.5855 - val_loss: 1.6601 - val_accuracy: 0.5360\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.1514 - accuracy: 0.5615 - val_loss: 1.6576 - val_accuracy: 0.5380\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.1113 - accuracy: 0.5885 - val_loss: 1.6574 - val_accuracy: 0.5320\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.1258 - accuracy: 0.5780 - val_loss: 1.6551 - val_accuracy: 0.5300\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.1364 - accuracy: 0.5725 - val_loss: 1.6638 - val_accuracy: 0.5340\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.1456 - accuracy: 0.5605 - val_loss: 1.6765 - val_accuracy: 0.5380\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.0907 - accuracy: 0.5870 - val_loss: 1.6769 - val_accuracy: 0.5220\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.1117 - accuracy: 0.5745 - val_loss: 1.6824 - val_accuracy: 0.5300\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.1387 - accuracy: 0.5805 - val_loss: 1.6912 - val_accuracy: 0.5320\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.1594 - accuracy: 0.5555 - val_loss: 1.6840 - val_accuracy: 0.5280\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.1186 - accuracy: 0.5950 - val_loss: 1.6816 - val_accuracy: 0.5380\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.1576 - accuracy: 0.5630 - val_loss: 1.6950 - val_accuracy: 0.5300\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 281us/step - loss: 1.1378 - accuracy: 0.5545 - val_loss: 1.6988 - val_accuracy: 0.5140\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.1219 - accuracy: 0.5705 - val_loss: 1.7040 - val_accuracy: 0.5180\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.1609 - accuracy: 0.5625 - val_loss: 1.7085 - val_accuracy: 0.5200\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.1576 - accuracy: 0.5540 - val_loss: 1.7086 - val_accuracy: 0.5160\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.1231 - accuracy: 0.5930 - val_loss: 1.6991 - val_accuracy: 0.5180\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.1093 - accuracy: 0.5700 - val_loss: 1.7058 - val_accuracy: 0.5260\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.1351 - accuracy: 0.5625 - val_loss: 1.7052 - val_accuracy: 0.5400\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.1401 - accuracy: 0.5625 - val_loss: 1.7228 - val_accuracy: 0.5380\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 1.1336 - accuracy: 0.5725 - val_loss: 1.7292 - val_accuracy: 0.5200\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 282us/step - loss: 1.1675 - accuracy: 0.5610 - val_loss: 1.7127 - val_accuracy: 0.5160\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.1018 - accuracy: 0.5840 - val_loss: 1.6912 - val_accuracy: 0.5160\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.1110 - accuracy: 0.5765 - val_loss: 1.6799 - val_accuracy: 0.5220\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.1592 - accuracy: 0.5585 - val_loss: 1.6704 - val_accuracy: 0.5340\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.1076 - accuracy: 0.5870 - val_loss: 1.6766 - val_accuracy: 0.5300\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.1122 - accuracy: 0.5760 - val_loss: 1.6845 - val_accuracy: 0.5380\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.1362 - accuracy: 0.5680 - val_loss: 1.7062 - val_accuracy: 0.5240\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.1284 - accuracy: 0.5665 - val_loss: 1.7283 - val_accuracy: 0.5240\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.1031 - accuracy: 0.5850 - val_loss: 1.7430 - val_accuracy: 0.5240\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.1319 - accuracy: 0.5685 - val_loss: 1.7564 - val_accuracy: 0.5160\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.1151 - accuracy: 0.5815 - val_loss: 1.7607 - val_accuracy: 0.5160\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.1323 - accuracy: 0.5725 - val_loss: 1.7682 - val_accuracy: 0.5100\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.1019 - accuracy: 0.5740 - val_loss: 1.7939 - val_accuracy: 0.5080\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.1175 - accuracy: 0.5705 - val_loss: 1.7847 - val_accuracy: 0.5200\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.1306 - accuracy: 0.5840 - val_loss: 1.7600 - val_accuracy: 0.5200\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0970 - accuracy: 0.5845 - val_loss: 1.7403 - val_accuracy: 0.5400\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 1.1396 - accuracy: 0.5815 - val_loss: 1.7448 - val_accuracy: 0.5300\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.1217 - accuracy: 0.5925 - val_loss: 1.7532 - val_accuracy: 0.5280\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.1313 - accuracy: 0.5965 - val_loss: 1.7616 - val_accuracy: 0.5280\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0908 - accuracy: 0.5940 - val_loss: 1.7436 - val_accuracy: 0.5320\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.1048 - accuracy: 0.5975 - val_loss: 1.7136 - val_accuracy: 0.5320\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.1360 - accuracy: 0.5765 - val_loss: 1.7095 - val_accuracy: 0.5240\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1130 - accuracy: 0.5795 - val_loss: 1.7012 - val_accuracy: 0.5320\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0872 - accuracy: 0.5855 - val_loss: 1.7144 - val_accuracy: 0.5260\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.1195 - accuracy: 0.5825 - val_loss: 1.7132 - val_accuracy: 0.5340\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.1457 - accuracy: 0.5680 - val_loss: 1.7149 - val_accuracy: 0.5320\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.1526 - accuracy: 0.5650 - val_loss: 1.7086 - val_accuracy: 0.5240\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.1128 - accuracy: 0.5750 - val_loss: 1.7047 - val_accuracy: 0.5280\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.1530 - accuracy: 0.5810 - val_loss: 1.7132 - val_accuracy: 0.5280\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0862 - accuracy: 0.5900 - val_loss: 1.7305 - val_accuracy: 0.5220\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0666 - accuracy: 0.6080 - val_loss: 1.7551 - val_accuracy: 0.5240\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0745 - accuracy: 0.5855 - val_loss: 1.7664 - val_accuracy: 0.5280\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.1222 - accuracy: 0.5760 - val_loss: 1.7818 - val_accuracy: 0.5340\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.1019 - accuracy: 0.5755 - val_loss: 1.7770 - val_accuracy: 0.5320\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.1231 - accuracy: 0.5895 - val_loss: 1.7809 - val_accuracy: 0.5320\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.1068 - accuracy: 0.5770 - val_loss: 1.7820 - val_accuracy: 0.5340\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0781 - accuracy: 0.5855 - val_loss: 1.7629 - val_accuracy: 0.5340\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.1218 - accuracy: 0.5800 - val_loss: 1.7730 - val_accuracy: 0.5380\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0685 - accuracy: 0.5925 - val_loss: 1.7879 - val_accuracy: 0.5280\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.0886 - accuracy: 0.6015 - val_loss: 1.8146 - val_accuracy: 0.5320\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 2s 857us/step - loss: 1.1284 - accuracy: 0.5680 - val_loss: 1.8152 - val_accuracy: 0.5280\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.1290 - accuracy: 0.5755 - val_loss: 1.8082 - val_accuracy: 0.5260\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.1370 - accuracy: 0.5715 - val_loss: 1.8069 - val_accuracy: 0.5220\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.1171 - accuracy: 0.5840 - val_loss: 1.8033 - val_accuracy: 0.5260\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.1379 - accuracy: 0.5730 - val_loss: 1.8006 - val_accuracy: 0.5260\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 352us/step - loss: 1.1105 - accuracy: 0.5785 - val_loss: 1.7983 - val_accuracy: 0.5280\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.0968 - accuracy: 0.5880 - val_loss: 1.7954 - val_accuracy: 0.5280\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.1121 - accuracy: 0.5735 - val_loss: 1.7952 - val_accuracy: 0.5240\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 342us/step - loss: 1.1115 - accuracy: 0.5760 - val_loss: 1.7930 - val_accuracy: 0.5220\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.0867 - accuracy: 0.5915 - val_loss: 1.7913 - val_accuracy: 0.5260\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 341us/step - loss: 1.1489 - accuracy: 0.5735 - val_loss: 1.7906 - val_accuracy: 0.5300\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.1090 - accuracy: 0.5875 - val_loss: 1.7906 - val_accuracy: 0.5320\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.1250 - accuracy: 0.5770 - val_loss: 1.7908 - val_accuracy: 0.5360\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.1009 - accuracy: 0.5935 - val_loss: 1.7896 - val_accuracy: 0.5360\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0988 - accuracy: 0.5905 - val_loss: 1.7906 - val_accuracy: 0.5340\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.0680 - accuracy: 0.6075 - val_loss: 1.7880 - val_accuracy: 0.5340\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0871 - accuracy: 0.5870 - val_loss: 1.7883 - val_accuracy: 0.5360\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.0846 - accuracy: 0.6015 - val_loss: 1.7888 - val_accuracy: 0.5360\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 347us/step - loss: 1.1208 - accuracy: 0.5930 - val_loss: 1.7890 - val_accuracy: 0.5360\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 352us/step - loss: 1.1077 - accuracy: 0.5835 - val_loss: 1.7883 - val_accuracy: 0.5320\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.1259 - accuracy: 0.5785 - val_loss: 1.7889 - val_accuracy: 0.5340\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 351us/step - loss: 1.1077 - accuracy: 0.5830 - val_loss: 1.7895 - val_accuracy: 0.5360\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.1464 - accuracy: 0.5690 - val_loss: 1.7921 - val_accuracy: 0.5360\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0630 - accuracy: 0.5900 - val_loss: 1.7922 - val_accuracy: 0.5360\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.1027 - accuracy: 0.5825 - val_loss: 1.7942 - val_accuracy: 0.5360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.0888 - accuracy: 0.5880 - val_loss: 1.7933 - val_accuracy: 0.5360\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 340us/step - loss: 1.1027 - accuracy: 0.5900 - val_loss: 1.7916 - val_accuracy: 0.5340\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 353us/step - loss: 1.1265 - accuracy: 0.5785 - val_loss: 1.7898 - val_accuracy: 0.5340\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.1022 - accuracy: 0.5825 - val_loss: 1.7883 - val_accuracy: 0.5340\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.1183 - accuracy: 0.5795 - val_loss: 1.7879 - val_accuracy: 0.5340\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0678 - accuracy: 0.5955 - val_loss: 1.7879 - val_accuracy: 0.5340\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.1354 - accuracy: 0.5775 - val_loss: 1.7872 - val_accuracy: 0.5340\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.0777 - accuracy: 0.5830 - val_loss: 1.7870 - val_accuracy: 0.5340\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.1279 - accuracy: 0.5690 - val_loss: 1.7871 - val_accuracy: 0.5360\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.1349 - accuracy: 0.5855 - val_loss: 1.7854 - val_accuracy: 0.5360\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0793 - accuracy: 0.6050 - val_loss: 1.7853 - val_accuracy: 0.5360\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.1227 - accuracy: 0.5670 - val_loss: 1.7836 - val_accuracy: 0.5360\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0826 - accuracy: 0.5900 - val_loss: 1.7836 - val_accuracy: 0.5320\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.0802 - accuracy: 0.5945 - val_loss: 1.7831 - val_accuracy: 0.5300\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.1081 - accuracy: 0.5995 - val_loss: 1.7831 - val_accuracy: 0.5340\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.1221 - accuracy: 0.5810 - val_loss: 1.7812 - val_accuracy: 0.5300\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.1042 - accuracy: 0.5830 - val_loss: 1.7789 - val_accuracy: 0.5300\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.1053 - accuracy: 0.6010 - val_loss: 1.7770 - val_accuracy: 0.5280\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0766 - accuracy: 0.5925 - val_loss: 1.7770 - val_accuracy: 0.5320\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.1025 - accuracy: 0.5805 - val_loss: 1.7792 - val_accuracy: 0.5340\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0332 - accuracy: 0.60 - 1s 321us/step - loss: 1.0559 - accuracy: 0.6030 - val_loss: 1.7808 - val_accuracy: 0.5360\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0862 - accuracy: 0.5890 - val_loss: 1.7829 - val_accuracy: 0.5340\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0691 - accuracy: 0.6055 - val_loss: 1.7881 - val_accuracy: 0.5320\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.1712 - accuracy: 0.5720 - val_loss: 1.7900 - val_accuracy: 0.5320\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0870 - accuracy: 0.5925 - val_loss: 1.7915 - val_accuracy: 0.5300\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.0874 - accuracy: 0.5900 - val_loss: 1.7928 - val_accuracy: 0.5300\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.0942 - accuracy: 0.5825 - val_loss: 1.7934 - val_accuracy: 0.5300\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.0631 - accuracy: 0.5930 - val_loss: 1.7964 - val_accuracy: 0.5320\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.0869 - accuracy: 0.6020 - val_loss: 1.7963 - val_accuracy: 0.5300\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.1233 - accuracy: 0.5800 - val_loss: 1.7953 - val_accuracy: 0.5300\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0771 - accuracy: 0.5970 - val_loss: 1.7938 - val_accuracy: 0.5260\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.1354 - accuracy: 0.5785 - val_loss: 1.7915 - val_accuracy: 0.5260\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.0877 - accuracy: 0.5890 - val_loss: 1.7921 - val_accuracy: 0.5260\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 344us/step - loss: 1.0695 - accuracy: 0.5925 - val_loss: 1.7923 - val_accuracy: 0.5280\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 346us/step - loss: 1.0717 - accuracy: 0.5990 - val_loss: 1.7928 - val_accuracy: 0.5280\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.1074 - accuracy: 0.5855 - val_loss: 1.7937 - val_accuracy: 0.5280\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0838 - accuracy: 0.5935 - val_loss: 1.7928 - val_accuracy: 0.5280\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.1248 - accuracy: 0.5725 - val_loss: 1.7917 - val_accuracy: 0.5260\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 339us/step - loss: 1.1120 - accuracy: 0.5780 - val_loss: 1.7900 - val_accuracy: 0.5260\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 354us/step - loss: 1.1222 - accuracy: 0.5885 - val_loss: 1.7882 - val_accuracy: 0.5280\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 356us/step - loss: 1.0995 - accuracy: 0.6015 - val_loss: 1.7873 - val_accuracy: 0.5300\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 349us/step - loss: 1.0943 - accuracy: 0.5995 - val_loss: 1.7855 - val_accuracy: 0.5300\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 351us/step - loss: 1.0617 - accuracy: 0.6005 - val_loss: 1.7838 - val_accuracy: 0.5260\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 346us/step - loss: 1.1092 - accuracy: 0.5885 - val_loss: 1.7829 - val_accuracy: 0.5340\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 337us/step - loss: 1.1174 - accuracy: 0.5890 - val_loss: 1.7844 - val_accuracy: 0.5280\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.1079 - accuracy: 0.5950 - val_loss: 1.7871 - val_accuracy: 0.5280\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.1184 - accuracy: 0.5770 - val_loss: 1.7894 - val_accuracy: 0.5260\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 351us/step - loss: 1.1105 - accuracy: 0.5845 - val_loss: 1.7892 - val_accuracy: 0.5260\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0551 - accuracy: 0.5990 - val_loss: 1.7886 - val_accuracy: 0.5280\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0969 - accuracy: 0.5825 - val_loss: 1.7894 - val_accuracy: 0.5300\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0969 - accuracy: 0.5925 - val_loss: 1.7917 - val_accuracy: 0.5300\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.0957 - accuracy: 0.5885 - val_loss: 1.7953 - val_accuracy: 0.5320\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 348us/step - loss: 1.0773 - accuracy: 0.5980 - val_loss: 1.7943 - val_accuracy: 0.5320\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0843 - accuracy: 0.5910 - val_loss: 1.7946 - val_accuracy: 0.5300\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.0906 - accuracy: 0.5840 - val_loss: 1.7955 - val_accuracy: 0.5260\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 288us/step - loss: 1.0913 - accuracy: 0.5955 - val_loss: 1.7962 - val_accuracy: 0.5260\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 261us/step - loss: 1.0862 - accuracy: 0.5855 - val_loss: 1.7966 - val_accuracy: 0.5240\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.0889 - accuracy: 0.5920 - val_loss: 1.7999 - val_accuracy: 0.5240\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0874 - accuracy: 0.5950 - val_loss: 1.8038 - val_accuracy: 0.5200\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.1171 - accuracy: 0.5955 - val_loss: 1.8057 - val_accuracy: 0.5200\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 272us/step - loss: 1.0550 - accuracy: 0.6065 - val_loss: 1.8031 - val_accuracy: 0.5240\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 265us/step - loss: 1.1032 - accuracy: 0.5800 - val_loss: 1.8032 - val_accuracy: 0.5240\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 272us/step - loss: 1.0763 - accuracy: 0.5790 - val_loss: 1.8048 - val_accuracy: 0.5240\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 282us/step - loss: 1.0980 - accuracy: 0.5940 - val_loss: 1.8041 - val_accuracy: 0.5240\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.1240 - accuracy: 0.5625 - val_loss: 1.8026 - val_accuracy: 0.5260\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0947 - accuracy: 0.5965 - val_loss: 1.8029 - val_accuracy: 0.5280\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.1268 - accuracy: 0.5805 - val_loss: 1.8050 - val_accuracy: 0.5280\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.1219 - accuracy: 0.5860 - val_loss: 1.8056 - val_accuracy: 0.5300\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.0722 - accuracy: 0.5995 - val_loss: 1.8080 - val_accuracy: 0.5320\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.0653 - accuracy: 0.6045 - val_loss: 1.8077 - val_accuracy: 0.5320\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.1043 - accuracy: 0.5845 - val_loss: 1.8075 - val_accuracy: 0.5360\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.1128 - accuracy: 0.5980 - val_loss: 1.8080 - val_accuracy: 0.5360\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.1350 - accuracy: 0.5785 - val_loss: 1.8061 - val_accuracy: 0.5360\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.1025 - accuracy: 0.5915 - val_loss: 1.8055 - val_accuracy: 0.5320\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.0756 - accuracy: 0.5955 - val_loss: 1.8045 - val_accuracy: 0.5320\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 359us/step - loss: 1.0868 - accuracy: 0.5905 - val_loss: 1.8045 - val_accuracy: 0.5300\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 345us/step - loss: 1.0462 - accuracy: 0.5990 - val_loss: 1.8048 - val_accuracy: 0.5360\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.1011 - accuracy: 0.5860 - val_loss: 1.8062 - val_accuracy: 0.5280\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 337us/step - loss: 1.0947 - accuracy: 0.5825 - val_loss: 1.8082 - val_accuracy: 0.5260\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0915 - accuracy: 0.5870 - val_loss: 1.8096 - val_accuracy: 0.5260\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.1379 - accuracy: 0.5780 - val_loss: 1.8107 - val_accuracy: 0.5240\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.1196 - accuracy: 0.5880 - val_loss: 1.8101 - val_accuracy: 0.5240\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0793 - accuracy: 0.5875 - val_loss: 1.8106 - val_accuracy: 0.5240\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.0889 - accuracy: 0.5910 - val_loss: 1.8092 - val_accuracy: 0.5260\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.0928 - accuracy: 0.5960 - val_loss: 1.8121 - val_accuracy: 0.5280\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 1.1171 - accuracy: 0.5860 - val_loss: 1.8107 - val_accuracy: 0.5280\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.1021 - accuracy: 0.5790 - val_loss: 1.8100 - val_accuracy: 0.5280\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 339us/step - loss: 1.0789 - accuracy: 0.5985 - val_loss: 1.8105 - val_accuracy: 0.5300\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0810 - accuracy: 0.6020 - val_loss: 1.8076 - val_accuracy: 0.5300\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.1345 - accuracy: 0.5630 - val_loss: 1.8087 - val_accuracy: 0.5300\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.1326 - accuracy: 0.5865 - val_loss: 1.8085 - val_accuracy: 0.5260\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.0886 - accuracy: 0.5910 - val_loss: 1.8082 - val_accuracy: 0.5260\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.0864 - accuracy: 0.5925 - val_loss: 1.8119 - val_accuracy: 0.5260\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0959 - accuracy: 0.5915 - val_loss: 1.8146 - val_accuracy: 0.5240\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.0435 - accuracy: 0.6100 - val_loss: 1.8169 - val_accuracy: 0.5260\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.0905 - accuracy: 0.5900 - val_loss: 1.8145 - val_accuracy: 0.5300\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.1126 - accuracy: 0.5700 - val_loss: 1.8118 - val_accuracy: 0.5280\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.0915 - accuracy: 0.5970 - val_loss: 1.8114 - val_accuracy: 0.5280\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.1354 - accuracy: 0.5840 - val_loss: 1.8117 - val_accuracy: 0.5240\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0814 - accuracy: 0.5920 - val_loss: 1.8109 - val_accuracy: 0.5280\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0877 - accuracy: 0.5935 - val_loss: 1.8130 - val_accuracy: 0.5280\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.0870 - accuracy: 0.5905 - val_loss: 1.8152 - val_accuracy: 0.5300\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0895 - accuracy: 0.5905 - val_loss: 1.8150 - val_accuracy: 0.5300\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.0645 - accuracy: 0.5885 - val_loss: 1.8156 - val_accuracy: 0.5300\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.0654 - accuracy: 0.5975 - val_loss: 1.8175 - val_accuracy: 0.5300\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.1070 - accuracy: 0.5710 - val_loss: 1.8169 - val_accuracy: 0.5280\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0774 - accuracy: 0.6010 - val_loss: 1.8163 - val_accuracy: 0.5280\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.1085 - accuracy: 0.5825 - val_loss: 1.8167 - val_accuracy: 0.5300\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0966 - accuracy: 0.5735 - val_loss: 1.8164 - val_accuracy: 0.5280\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.0899 - accuracy: 0.5935 - val_loss: 1.8173 - val_accuracy: 0.5280\n",
      "Epoch 136/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.1135 - accuracy: 0.5740 - val_loss: 1.8154 - val_accuracy: 0.5280\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.1080 - accuracy: 0.5880 - val_loss: 1.8138 - val_accuracy: 0.5300\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.0978 - accuracy: 0.5950 - val_loss: 1.8135 - val_accuracy: 0.5260\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.1340 - accuracy: 0.5745 - val_loss: 1.8135 - val_accuracy: 0.5300\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.0728 - accuracy: 0.5920 - val_loss: 1.8122 - val_accuracy: 0.5320\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.0478 - accuracy: 0.5985 - val_loss: 1.8110 - val_accuracy: 0.5300\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 346us/step - loss: 1.1007 - accuracy: 0.5850 - val_loss: 1.8130 - val_accuracy: 0.5260\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.0698 - accuracy: 0.5930 - val_loss: 1.8139 - val_accuracy: 0.5300\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.1032 - accuracy: 0.5965 - val_loss: 1.8129 - val_accuracy: 0.5340\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0617 - accuracy: 0.5980 - val_loss: 1.8101 - val_accuracy: 0.5300\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.0779 - accuracy: 0.5815 - val_loss: 1.8084 - val_accuracy: 0.5300\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0796 - accuracy: 0.6065 - val_loss: 1.8112 - val_accuracy: 0.5300\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.1075 - accuracy: 0.5925 - val_loss: 1.8099 - val_accuracy: 0.5300\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 337us/step - loss: 1.0938 - accuracy: 0.6040 - val_loss: 1.8049 - val_accuracy: 0.5320\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0803 - accuracy: 0.5905 - val_loss: 1.8043 - val_accuracy: 0.5260\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.0806 - accuracy: 0.5850 - val_loss: 1.8047 - val_accuracy: 0.5260\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.0733 - accuracy: 0.5945 - val_loss: 1.8049 - val_accuracy: 0.5240\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0908 - accuracy: 0.5925 - val_loss: 1.8028 - val_accuracy: 0.5240\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0933 - accuracy: 0.5965 - val_loss: 1.8011 - val_accuracy: 0.5240\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0581 - accuracy: 0.5805 - val_loss: 1.8044 - val_accuracy: 0.5240\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.0965 - accuracy: 0.5845 - val_loss: 1.8060 - val_accuracy: 0.5260\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.1260 - accuracy: 0.5725 - val_loss: 1.8057 - val_accuracy: 0.5260\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.1053 - accuracy: 0.5825 - val_loss: 1.8047 - val_accuracy: 0.5260\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.0896 - accuracy: 0.5975 - val_loss: 1.8061 - val_accuracy: 0.5260\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 347us/step - loss: 1.0882 - accuracy: 0.5890 - val_loss: 1.8084 - val_accuracy: 0.5240\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.1220 - accuracy: 0.5735 - val_loss: 1.8083 - val_accuracy: 0.5220\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.1039 - accuracy: 0.5840 - val_loss: 1.8081 - val_accuracy: 0.5260\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0788 - accuracy: 0.5980 - val_loss: 1.8065 - val_accuracy: 0.5260\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0619 - accuracy: 0.5995 - val_loss: 1.8047 - val_accuracy: 0.5260\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.0851 - accuracy: 0.6075 - val_loss: 1.8063 - val_accuracy: 0.5240\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.0746 - accuracy: 0.5985 - val_loss: 1.8081 - val_accuracy: 0.5240\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.1147 - accuracy: 0.5795 - val_loss: 1.8090 - val_accuracy: 0.5240\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.1117 - accuracy: 0.5975 - val_loss: 1.8098 - val_accuracy: 0.5240\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.1143 - accuracy: 0.5905 - val_loss: 1.8101 - val_accuracy: 0.5220\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 358us/step - loss: 1.0637 - accuracy: 0.5985 - val_loss: 1.8093 - val_accuracy: 0.5220\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0645 - accuracy: 0.6065 - val_loss: 1.8097 - val_accuracy: 0.5240\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0796 - accuracy: 0.5960 - val_loss: 1.8132 - val_accuracy: 0.5220\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.0513 - accuracy: 0.5995 - val_loss: 1.8148 - val_accuracy: 0.5220\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0873 - accuracy: 0.5980 - val_loss: 1.8146 - val_accuracy: 0.5220\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.0878 - accuracy: 0.5975 - val_loss: 1.8119 - val_accuracy: 0.5240\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0873 - accuracy: 0.5980 - val_loss: 1.8099 - val_accuracy: 0.5280\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.0982 - accuracy: 0.5855 - val_loss: 1.8077 - val_accuracy: 0.5260\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0767 - accuracy: 0.6070 - val_loss: 1.8083 - val_accuracy: 0.5260\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0706 - accuracy: 0.5855 - val_loss: 1.8086 - val_accuracy: 0.5260\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.0928 - accuracy: 0.5880 - val_loss: 1.8086 - val_accuracy: 0.5280\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 340us/step - loss: 1.0912 - accuracy: 0.5910 - val_loss: 1.8110 - val_accuracy: 0.5280\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0500 - accuracy: 0.6000 - val_loss: 1.8132 - val_accuracy: 0.5280\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.0992 - accuracy: 0.5805 - val_loss: 1.8145 - val_accuracy: 0.5300\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0934 - accuracy: 0.5940 - val_loss: 1.8139 - val_accuracy: 0.5300\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 1.0851 - accuracy: 0.6040 - val_loss: 1.8141 - val_accuracy: 0.5300\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 1.0635 - accuracy: 0.5935 - val_loss: 1.8146 - val_accuracy: 0.5260\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 1.0887 - accuracy: 0.6000 - val_loss: 1.8154 - val_accuracy: 0.5260\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 1.0698 - accuracy: 0.6025 - val_loss: 1.8140 - val_accuracy: 0.5260\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 395us/step - loss: 1.1069 - accuracy: 0.5850 - val_loss: 1.8144 - val_accuracy: 0.5260\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 399us/step - loss: 1.0834 - accuracy: 0.5985 - val_loss: 1.8141 - val_accuracy: 0.5260\n",
      "Epoch 191/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 404us/step - loss: 1.0809 - accuracy: 0.5920 - val_loss: 1.8117 - val_accuracy: 0.5240\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 1.0857 - accuracy: 0.5945 - val_loss: 1.8127 - val_accuracy: 0.5220\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 382us/step - loss: 1.0966 - accuracy: 0.5980 - val_loss: 1.8118 - val_accuracy: 0.5240\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 435us/step - loss: 1.0522 - accuracy: 0.5960 - val_loss: 1.8099 - val_accuracy: 0.5220\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 1.0936 - accuracy: 0.5820 - val_loss: 1.8104 - val_accuracy: 0.5220\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 1.0642 - accuracy: 0.5935 - val_loss: 1.8090 - val_accuracy: 0.5220\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 435us/step - loss: 1.1061 - accuracy: 0.5875 - val_loss: 1.8082 - val_accuracy: 0.5240\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 1.1057 - accuracy: 0.5895 - val_loss: 1.8082 - val_accuracy: 0.5240\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 1.0846 - accuracy: 0.5940 - val_loss: 1.8075 - val_accuracy: 0.5240\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.0864 - accuracy: 0.5965 - val_loss: 1.8070 - val_accuracy: 0.5240\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 2s 890us/step - loss: 1.0992 - accuracy: 0.5775 - val_loss: 1.8072 - val_accuracy: 0.5220\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0915 - accuracy: 0.5805 - val_loss: 1.8067 - val_accuracy: 0.5240\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 348us/step - loss: 1.0673 - accuracy: 0.5915 - val_loss: 1.8067 - val_accuracy: 0.5240\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 339us/step - loss: 1.1146 - accuracy: 0.5860 - val_loss: 1.8084 - val_accuracy: 0.5240\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0975 - accuracy: 0.5925 - val_loss: 1.8073 - val_accuracy: 0.5240\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0810 - accuracy: 0.5810 - val_loss: 1.8103 - val_accuracy: 0.5240\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0937 - accuracy: 0.6015 - val_loss: 1.8122 - val_accuracy: 0.5240\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.0610 - accuracy: 0.5885 - val_loss: 1.8109 - val_accuracy: 0.5240\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0874 - accuracy: 0.5950 - val_loss: 1.8118 - val_accuracy: 0.5240\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0880 - accuracy: 0.6050 - val_loss: 1.8125 - val_accuracy: 0.5240\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0764 - accuracy: 0.5965 - val_loss: 1.8125 - val_accuracy: 0.5240\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.1037 - accuracy: 0.5875 - val_loss: 1.8117 - val_accuracy: 0.5240\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0804 - accuracy: 0.6015 - val_loss: 1.8100 - val_accuracy: 0.5240\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0912 - accuracy: 0.5930 - val_loss: 1.8104 - val_accuracy: 0.5260\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.1132 - accuracy: 0.5805 - val_loss: 1.8095 - val_accuracy: 0.5260\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0789 - accuracy: 0.5980 - val_loss: 1.8095 - val_accuracy: 0.5260\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.0949 - accuracy: 0.5870 - val_loss: 1.8103 - val_accuracy: 0.5260\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.0782 - accuracy: 0.5965 - val_loss: 1.8097 - val_accuracy: 0.5260\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0933 - accuracy: 0.5820 - val_loss: 1.8100 - val_accuracy: 0.5260\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.0733 - accuracy: 0.5905 - val_loss: 1.8104 - val_accuracy: 0.5260\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0990 - accuracy: 0.5900 - val_loss: 1.8099 - val_accuracy: 0.5260\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0677 - accuracy: 0.5935 - val_loss: 1.8097 - val_accuracy: 0.5260\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.0893 - accuracy: 0.5955 - val_loss: 1.8106 - val_accuracy: 0.5240\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.1304 - accuracy: 0.5755 - val_loss: 1.8107 - val_accuracy: 0.5240\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0933 - accuracy: 0.5930 - val_loss: 1.8124 - val_accuracy: 0.5240\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.0686 - accuracy: 0.6140 - val_loss: 1.8134 - val_accuracy: 0.5240\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0748 - accuracy: 0.6055 - val_loss: 1.8142 - val_accuracy: 0.5240\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0729 - accuracy: 0.6015 - val_loss: 1.8149 - val_accuracy: 0.5240\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.0787 - accuracy: 0.6080 - val_loss: 1.8171 - val_accuracy: 0.5240\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.0414 - accuracy: 0.6200 - val_loss: 1.8161 - val_accuracy: 0.5220\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.1134 - accuracy: 0.5875 - val_loss: 1.8153 - val_accuracy: 0.5240\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0452 - accuracy: 0.6160 - val_loss: 1.8133 - val_accuracy: 0.5240\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.0833 - accuracy: 0.5920 - val_loss: 1.8128 - val_accuracy: 0.5240\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0691 - accuracy: 0.6010 - val_loss: 1.8141 - val_accuracy: 0.5240\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0900 - accuracy: 0.5940 - val_loss: 1.8142 - val_accuracy: 0.5220\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.0793 - accuracy: 0.5770 - val_loss: 1.8148 - val_accuracy: 0.5220\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0818 - accuracy: 0.6030 - val_loss: 1.8157 - val_accuracy: 0.5220\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0743 - accuracy: 0.5935 - val_loss: 1.8161 - val_accuracy: 0.5220\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0953 - accuracy: 0.5875 - val_loss: 1.8166 - val_accuracy: 0.5220\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.0856 - accuracy: 0.5995 - val_loss: 1.8168 - val_accuracy: 0.5220\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.0669 - accuracy: 0.5955 - val_loss: 1.8148 - val_accuracy: 0.5220\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.1139 - accuracy: 0.5780 - val_loss: 1.8158 - val_accuracy: 0.5220\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.1111 - accuracy: 0.5865 - val_loss: 1.8165 - val_accuracy: 0.5220\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.0655 - accuracy: 0.6015 - val_loss: 1.8171 - val_accuracy: 0.5240\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.1172 - accuracy: 0.5800 - val_loss: 1.8166 - val_accuracy: 0.5260\n",
      "Epoch 46/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.0941 - accuracy: 0.5875 - val_loss: 1.8159 - val_accuracy: 0.5260\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0901 - accuracy: 0.5975 - val_loss: 1.8157 - val_accuracy: 0.5240\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0700 - accuracy: 0.6050 - val_loss: 1.8158 - val_accuracy: 0.5240\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0549 - accuracy: 0.6020 - val_loss: 1.8169 - val_accuracy: 0.5240\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.0605 - accuracy: 0.6040 - val_loss: 1.8166 - val_accuracy: 0.5240\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.0585 - accuracy: 0.6100 - val_loss: 1.8179 - val_accuracy: 0.5260\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0991 - accuracy: 0.6010 - val_loss: 1.8172 - val_accuracy: 0.5240\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 342us/step - loss: 1.0815 - accuracy: 0.5860 - val_loss: 1.8174 - val_accuracy: 0.5280\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0887 - accuracy: 0.5955 - val_loss: 1.8171 - val_accuracy: 0.5280\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.1230 - accuracy: 0.5835 - val_loss: 1.8168 - val_accuracy: 0.5280\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0930 - accuracy: 0.5880 - val_loss: 1.8163 - val_accuracy: 0.5280\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0932 - accuracy: 0.5870 - val_loss: 1.8161 - val_accuracy: 0.5280\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0613 - accuracy: 0.6125 - val_loss: 1.8162 - val_accuracy: 0.5280\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0755 - accuracy: 0.6050 - val_loss: 1.8156 - val_accuracy: 0.5260\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.0696 - accuracy: 0.5900 - val_loss: 1.8157 - val_accuracy: 0.5260\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.0647 - accuracy: 0.6100 - val_loss: 1.8132 - val_accuracy: 0.5240\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0570 - accuracy: 0.5955 - val_loss: 1.8141 - val_accuracy: 0.5280\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0905 - accuracy: 0.5860 - val_loss: 1.8147 - val_accuracy: 0.5280\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.0977 - accuracy: 0.5820 - val_loss: 1.8149 - val_accuracy: 0.5280\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.0790 - accuracy: 0.5905 - val_loss: 1.8136 - val_accuracy: 0.5240\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0934 - accuracy: 0.5900 - val_loss: 1.8148 - val_accuracy: 0.5240\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 343us/step - loss: 1.0897 - accuracy: 0.5990 - val_loss: 1.8156 - val_accuracy: 0.5260\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0898 - accuracy: 0.5975 - val_loss: 1.8151 - val_accuracy: 0.5240\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.0816 - accuracy: 0.5950 - val_loss: 1.8162 - val_accuracy: 0.5220\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.1239 - accuracy: 0.5810 - val_loss: 1.8144 - val_accuracy: 0.5240\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.0603 - accuracy: 0.6040 - val_loss: 1.8156 - val_accuracy: 0.5220\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0698 - accuracy: 0.6135 - val_loss: 1.8151 - val_accuracy: 0.5220\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.1007 - accuracy: 0.5930 - val_loss: 1.8162 - val_accuracy: 0.5220\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0868 - accuracy: 0.59 - 1s 311us/step - loss: 1.0857 - accuracy: 0.5940 - val_loss: 1.8155 - val_accuracy: 0.5220\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 341us/step - loss: 1.0597 - accuracy: 0.5955 - val_loss: 1.8160 - val_accuracy: 0.5220\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.1183 - accuracy: 0.5735 - val_loss: 1.8157 - val_accuracy: 0.5220\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 356us/step - loss: 1.0730 - accuracy: 0.5885 - val_loss: 1.8154 - val_accuracy: 0.5220\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 354us/step - loss: 1.0869 - accuracy: 0.5905 - val_loss: 1.8150 - val_accuracy: 0.5220\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 355us/step - loss: 1.0744 - accuracy: 0.6020 - val_loss: 1.8155 - val_accuracy: 0.5240\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0594 - accuracy: 0.6140 - val_loss: 1.8154 - val_accuracy: 0.5260\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 345us/step - loss: 1.0737 - accuracy: 0.6035 - val_loss: 1.8160 - val_accuracy: 0.5240\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.1086 - accuracy: 0.5835 - val_loss: 1.8149 - val_accuracy: 0.5280\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.1008 - accuracy: 0.5960 - val_loss: 1.8151 - val_accuracy: 0.5260\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.0431 - accuracy: 0.6075 - val_loss: 1.8143 - val_accuracy: 0.5260\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.1064 - accuracy: 0.6005 - val_loss: 1.8122 - val_accuracy: 0.5240\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.1296 - accuracy: 0.5860 - val_loss: 1.8128 - val_accuracy: 0.5260\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.1399 - accuracy: 0.5765 - val_loss: 1.8144 - val_accuracy: 0.5240\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.1106 - accuracy: 0.5875 - val_loss: 1.8133 - val_accuracy: 0.5240\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.1282 - accuracy: 0.5795 - val_loss: 1.8124 - val_accuracy: 0.5240\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 1.0753 - accuracy: 0.6125 - val_loss: 1.8135 - val_accuracy: 0.5240\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 337us/step - loss: 1.1058 - accuracy: 0.5725 - val_loss: 1.8131 - val_accuracy: 0.5240\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.0719 - accuracy: 0.5845 - val_loss: 1.8129 - val_accuracy: 0.5240\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 1.1212 - accuracy: 0.5925 - val_loss: 1.8128 - val_accuracy: 0.5240\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 347us/step - loss: 1.0698 - accuracy: 0.6055 - val_loss: 1.8125 - val_accuracy: 0.5240\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0499 - accuracy: 0.5960 - val_loss: 1.8132 - val_accuracy: 0.5260\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 339us/step - loss: 1.0932 - accuracy: 0.5860 - val_loss: 1.8132 - val_accuracy: 0.5240\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.0817 - accuracy: 0.5980 - val_loss: 1.8144 - val_accuracy: 0.5260\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 333us/step - loss: 1.1326 - accuracy: 0.5860 - val_loss: 1.8123 - val_accuracy: 0.5260\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0673 - accuracy: 0.5870 - val_loss: 1.8137 - val_accuracy: 0.5240\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0485 - accuracy: 0.6005 - val_loss: 1.8148 - val_accuracy: 0.5240\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.0985 - accuracy: 0.5950 - val_loss: 1.8137 - val_accuracy: 0.5240\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.0830 - accuracy: 0.5975 - val_loss: 1.8156 - val_accuracy: 0.5220\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 346us/step - loss: 1.0618 - accuracy: 0.5935 - val_loss: 1.8157 - val_accuracy: 0.5220\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.0839 - accuracy: 0.6060 - val_loss: 1.8174 - val_accuracy: 0.5220\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.0846 - accuracy: 0.6055 - val_loss: 1.8167 - val_accuracy: 0.5220\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0714 - accuracy: 0.6065 - val_loss: 1.8155 - val_accuracy: 0.5260\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0920 - accuracy: 0.5925 - val_loss: 1.8157 - val_accuracy: 0.5260\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 1.1006 - accuracy: 0.5905 - val_loss: 1.8159 - val_accuracy: 0.5260\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 368us/step - loss: 1.1406 - accuracy: 0.5835 - val_loss: 1.8156 - val_accuracy: 0.5260\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 358us/step - loss: 1.1011 - accuracy: 0.5910 - val_loss: 1.8149 - val_accuracy: 0.5240\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 335us/step - loss: 1.0873 - accuracy: 0.5795 - val_loss: 1.8154 - val_accuracy: 0.5240\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 348us/step - loss: 1.1137 - accuracy: 0.5875 - val_loss: 1.8143 - val_accuracy: 0.5200\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.0792 - accuracy: 0.5935 - val_loss: 1.8148 - val_accuracy: 0.5200\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0566 - accuracy: 0.5925 - val_loss: 1.8141 - val_accuracy: 0.5240\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0553 - accuracy: 0.5950 - val_loss: 1.8143 - val_accuracy: 0.5240\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0409 - accuracy: 0.6055 - val_loss: 1.8153 - val_accuracy: 0.5240\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0506 - accuracy: 0.6055 - val_loss: 1.8153 - val_accuracy: 0.5240\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0879 - accuracy: 0.5775 - val_loss: 1.8155 - val_accuracy: 0.5220\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0931 - accuracy: 0.5805 - val_loss: 1.8158 - val_accuracy: 0.5200\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.0819 - accuracy: 0.5875 - val_loss: 1.8155 - val_accuracy: 0.5220\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.0770 - accuracy: 0.5940 - val_loss: 1.8159 - val_accuracy: 0.5220\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 337us/step - loss: 1.1059 - accuracy: 0.5930 - val_loss: 1.8159 - val_accuracy: 0.5220\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.0595 - accuracy: 0.5915 - val_loss: 1.8158 - val_accuracy: 0.5220\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.1079 - accuracy: 0.5865 - val_loss: 1.8166 - val_accuracy: 0.5260\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0958 - accuracy: 0.5890 - val_loss: 1.8164 - val_accuracy: 0.5220\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.1061 - accuracy: 0.6000 - val_loss: 1.8160 - val_accuracy: 0.5200\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 329us/step - loss: 1.1088 - accuracy: 0.6000 - val_loss: 1.8158 - val_accuracy: 0.5260\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0575 - accuracy: 0.6035 - val_loss: 1.8152 - val_accuracy: 0.5240\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0527 - accuracy: 0.6195 - val_loss: 1.8136 - val_accuracy: 0.5220\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.1047 - accuracy: 0.5910 - val_loss: 1.8155 - val_accuracy: 0.5200\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 334us/step - loss: 1.1148 - accuracy: 0.5955 - val_loss: 1.8165 - val_accuracy: 0.5220\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 342us/step - loss: 1.0923 - accuracy: 0.5900 - val_loss: 1.8177 - val_accuracy: 0.5220\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.0819 - accuracy: 0.5910 - val_loss: 1.8173 - val_accuracy: 0.5240\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.0663 - accuracy: 0.5995 - val_loss: 1.8174 - val_accuracy: 0.5220\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.0333 - accuracy: 0.6180 - val_loss: 1.8169 - val_accuracy: 0.5220\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0743 - accuracy: 0.5940 - val_loss: 1.8158 - val_accuracy: 0.5220\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 337us/step - loss: 1.0690 - accuracy: 0.6025 - val_loss: 1.8172 - val_accuracy: 0.5260\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 352us/step - loss: 1.0721 - accuracy: 0.5935 - val_loss: 1.8173 - val_accuracy: 0.5260\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 348us/step - loss: 1.0945 - accuracy: 0.5910 - val_loss: 1.8170 - val_accuracy: 0.5260\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.0584 - accuracy: 0.5995 - val_loss: 1.8170 - val_accuracy: 0.5260\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.0468 - accuracy: 0.6140 - val_loss: 1.8151 - val_accuracy: 0.5240\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.1164 - accuracy: 0.5950 - val_loss: 1.8167 - val_accuracy: 0.5260\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0682 - accuracy: 0.6020 - val_loss: 1.8160 - val_accuracy: 0.5260\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 341us/step - loss: 1.0611 - accuracy: 0.5925 - val_loss: 1.8163 - val_accuracy: 0.5220\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.0927 - accuracy: 0.5920 - val_loss: 1.8153 - val_accuracy: 0.5220\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0775 - accuracy: 0.6060 - val_loss: 1.8147 - val_accuracy: 0.5220\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 339us/step - loss: 1.1035 - accuracy: 0.5990 - val_loss: 1.8150 - val_accuracy: 0.5220\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 342us/step - loss: 1.1043 - accuracy: 0.5925 - val_loss: 1.8147 - val_accuracy: 0.5220\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 339us/step - loss: 1.0745 - accuracy: 0.5875 - val_loss: 1.8122 - val_accuracy: 0.5220\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0834 - accuracy: 0.6070 - val_loss: 1.8145 - val_accuracy: 0.5200\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 323us/step - loss: 1.1036 - accuracy: 0.5825 - val_loss: 1.8147 - val_accuracy: 0.5220\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 345us/step - loss: 1.0956 - accuracy: 0.5895 - val_loss: 1.8138 - val_accuracy: 0.5220\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 345us/step - loss: 1.0794 - accuracy: 0.6045 - val_loss: 1.8135 - val_accuracy: 0.5220\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 390us/step - loss: 1.0476 - accuracy: 0.6155 - val_loss: 1.8135 - val_accuracy: 0.5220\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 380us/step - loss: 1.0984 - accuracy: 0.5895 - val_loss: 1.8138 - val_accuracy: 0.5220\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 428us/step - loss: 1.0668 - accuracy: 0.6090 - val_loss: 1.8132 - val_accuracy: 0.5240\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 1.0917 - accuracy: 0.5885 - val_loss: 1.8139 - val_accuracy: 0.5240\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 1.0886 - accuracy: 0.5910 - val_loss: 1.8153 - val_accuracy: 0.5220\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 338us/step - loss: 1.1118 - accuracy: 0.6000 - val_loss: 1.8183 - val_accuracy: 0.5220\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.0641 - accuracy: 0.5900 - val_loss: 1.8178 - val_accuracy: 0.5220\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0697 - accuracy: 0.5975 - val_loss: 1.8186 - val_accuracy: 0.5220\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0892 - accuracy: 0.5895 - val_loss: 1.8210 - val_accuracy: 0.5220\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0867 - accuracy: 0.6040 - val_loss: 1.8203 - val_accuracy: 0.5220\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 1.1053 - accuracy: 0.5865 - val_loss: 1.8210 - val_accuracy: 0.5240\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.0683 - accuracy: 0.6125 - val_loss: 1.8223 - val_accuracy: 0.5220\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 362us/step - loss: 1.1189 - accuracy: 0.5775 - val_loss: 1.8229 - val_accuracy: 0.5240\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 1.0709 - accuracy: 0.5895 - val_loss: 1.8217 - val_accuracy: 0.5260\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 324us/step - loss: 1.0863 - accuracy: 0.5975 - val_loss: 1.8209 - val_accuracy: 0.5220\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0916 - accuracy: 0.5815 - val_loss: 1.8210 - val_accuracy: 0.5240\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0535 - accuracy: 0.6100 - val_loss: 1.8189 - val_accuracy: 0.5240\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0587 - accuracy: 0.5905 - val_loss: 1.8198 - val_accuracy: 0.5240\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0806 - accuracy: 0.5865 - val_loss: 1.8197 - val_accuracy: 0.5220\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 262us/step - loss: 1.0442 - accuracy: 0.5955 - val_loss: 1.8194 - val_accuracy: 0.5220\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 287us/step - loss: 1.0566 - accuracy: 0.5975 - val_loss: 1.8190 - val_accuracy: 0.5240\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 281us/step - loss: 1.0816 - accuracy: 0.5890 - val_loss: 1.8191 - val_accuracy: 0.5220\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.0864 - accuracy: 0.5915 - val_loss: 1.8187 - val_accuracy: 0.5220\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.1206 - accuracy: 0.5815 - val_loss: 1.8201 - val_accuracy: 0.5220\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0873 - accuracy: 0.5900 - val_loss: 1.8172 - val_accuracy: 0.5220\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 1.1232 - accuracy: 0.5770 - val_loss: 1.8181 - val_accuracy: 0.5220\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0818 - accuracy: 0.5850 - val_loss: 1.8183 - val_accuracy: 0.5240\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0807 - accuracy: 0.6015 - val_loss: 1.8194 - val_accuracy: 0.5220\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.1033 - accuracy: 0.5790 - val_loss: 1.8200 - val_accuracy: 0.5220\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0853 - accuracy: 0.5945 - val_loss: 1.8202 - val_accuracy: 0.5240\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.0408 - accuracy: 0.6260 - val_loss: 1.8210 - val_accuracy: 0.5240\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.0372 - accuracy: 0.6040 - val_loss: 1.8200 - val_accuracy: 0.5240\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.1187 - accuracy: 0.5860 - val_loss: 1.8187 - val_accuracy: 0.5240\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.1076 - accuracy: 0.5915 - val_loss: 1.8193 - val_accuracy: 0.5240\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 327us/step - loss: 1.0701 - accuracy: 0.6075 - val_loss: 1.8195 - val_accuracy: 0.5220\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.1087 - accuracy: 0.5845 - val_loss: 1.8185 - val_accuracy: 0.5220\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.0367 - accuracy: 0.6170 - val_loss: 1.8159 - val_accuracy: 0.5220\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.0728 - accuracy: 0.6000 - val_loss: 1.8164 - val_accuracy: 0.5220\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.0584 - accuracy: 0.6050 - val_loss: 1.8159 - val_accuracy: 0.5240\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0855 - accuracy: 0.5900 - val_loss: 1.8154 - val_accuracy: 0.5200\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.1025 - accuracy: 0.5815 - val_loss: 1.8151 - val_accuracy: 0.5200\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0974 - accuracy: 0.5980 - val_loss: 1.8164 - val_accuracy: 0.5220\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 331us/step - loss: 1.0883 - accuracy: 0.5990 - val_loss: 1.8170 - val_accuracy: 0.5240\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 328us/step - loss: 1.0906 - accuracy: 0.5825 - val_loss: 1.8178 - val_accuracy: 0.5260\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0674 - accuracy: 0.6025 - val_loss: 1.8181 - val_accuracy: 0.5260\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0658 - accuracy: 0.5940 - val_loss: 1.8180 - val_accuracy: 0.5240\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 1.0655 - accuracy: 0.5905 - val_loss: 1.8189 - val_accuracy: 0.5240\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 2s 875us/step - loss: 1.0337 - accuracy: 0.6110 - val_loss: 1.8631 - val_accuracy: 0.5420\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.1320 - accuracy: 0.5770 - val_loss: 1.8760 - val_accuracy: 0.5360\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0936 - accuracy: 0.5830 - val_loss: 1.8539 - val_accuracy: 0.5340\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.1274 - accuracy: 0.5695 - val_loss: 1.8404 - val_accuracy: 0.5320\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.0748 - accuracy: 0.5845 - val_loss: 1.8287 - val_accuracy: 0.5340\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.0482 - accuracy: 0.6070 - val_loss: 1.8255 - val_accuracy: 0.5380\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0654 - accuracy: 0.5955 - val_loss: 1.8414 - val_accuracy: 0.5280\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 1.0473 - accuracy: 0.6065 - val_loss: 1.8500 - val_accuracy: 0.5300\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 316us/step - loss: 1.0649 - accuracy: 0.6065 - val_loss: 1.8490 - val_accuracy: 0.5360\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 1.0761 - accuracy: 0.5965 - val_loss: 1.8469 - val_accuracy: 0.5400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0717 - accuracy: 0.6020 - val_loss: 1.8414 - val_accuracy: 0.5340\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0837 - accuracy: 0.6025 - val_loss: 1.8404 - val_accuracy: 0.5360\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.0849 - accuracy: 0.5940 - val_loss: 1.8140 - val_accuracy: 0.5300\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 1.1132 - accuracy: 0.5790 - val_loss: 1.8110 - val_accuracy: 0.5280\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.1160 - accuracy: 0.5795 - val_loss: 1.8155 - val_accuracy: 0.5300\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0622 - accuracy: 0.5885 - val_loss: 1.8278 - val_accuracy: 0.5200\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0713 - accuracy: 0.5930 - val_loss: 1.8310 - val_accuracy: 0.5260\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.0640 - accuracy: 0.6035 - val_loss: 1.8271 - val_accuracy: 0.5300\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.0734 - accuracy: 0.5885 - val_loss: 1.8360 - val_accuracy: 0.5260\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.0758 - accuracy: 0.6040 - val_loss: 1.8463 - val_accuracy: 0.5220\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 1.1072 - accuracy: 0.5980 - val_loss: 1.8281 - val_accuracy: 0.5280\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.0561 - accuracy: 0.6095 - val_loss: 1.8213 - val_accuracy: 0.5400\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.0723 - accuracy: 0.5905 - val_loss: 1.8315 - val_accuracy: 0.5360\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.0787 - accuracy: 0.5870 - val_loss: 1.8490 - val_accuracy: 0.5340\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0691 - accuracy: 0.6090 - val_loss: 1.8722 - val_accuracy: 0.5280\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0722 - accuracy: 0.6085 - val_loss: 1.8830 - val_accuracy: 0.5260\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.0797 - accuracy: 0.5925 - val_loss: 1.8622 - val_accuracy: 0.5220\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 269us/step - loss: 1.0494 - accuracy: 0.6100 - val_loss: 1.8517 - val_accuracy: 0.5320\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0804 - accuracy: 0.6005 - val_loss: 1.8530 - val_accuracy: 0.5320\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0750 - accuracy: 0.5950 - val_loss: 1.8497 - val_accuracy: 0.5340\n",
      "Epoch 31/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.0444 - accuracy: 0.6200 - val_loss: 1.8489 - val_accuracy: 0.5380\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.1143 - accuracy: 0.5795 - val_loss: 1.8630 - val_accuracy: 0.5220\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.0887 - accuracy: 0.5960 - val_loss: 1.8710 - val_accuracy: 0.5180\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.0920 - accuracy: 0.5995 - val_loss: 1.8616 - val_accuracy: 0.5200\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 1.0319 - accuracy: 0.6180 - val_loss: 1.8551 - val_accuracy: 0.5240\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0411 - accuracy: 0.6000 - val_loss: 1.8573 - val_accuracy: 0.5280\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.0615 - accuracy: 0.6010 - val_loss: 1.8472 - val_accuracy: 0.5320\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0838 - accuracy: 0.5870 - val_loss: 1.8524 - val_accuracy: 0.5300\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0932 - accuracy: 0.5875 - val_loss: 1.8539 - val_accuracy: 0.5240\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.0441 - accuracy: 0.6115 - val_loss: 1.8593 - val_accuracy: 0.5220\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.0831 - accuracy: 0.5845 - val_loss: 1.8504 - val_accuracy: 0.5300\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.0364 - accuracy: 0.6090 - val_loss: 1.8471 - val_accuracy: 0.5280\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.0614 - accuracy: 0.5990 - val_loss: 1.8662 - val_accuracy: 0.5300\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.0905 - accuracy: 0.5830 - val_loss: 1.8646 - val_accuracy: 0.5200\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0630 - accuracy: 0.5935 - val_loss: 1.8588 - val_accuracy: 0.5180\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0709 - accuracy: 0.5975 - val_loss: 1.8397 - val_accuracy: 0.5240\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0837 - accuracy: 0.5825 - val_loss: 1.8402 - val_accuracy: 0.5220\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.0952 - accuracy: 0.5890 - val_loss: 1.8499 - val_accuracy: 0.5280\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 359us/step - loss: 1.0613 - accuracy: 0.6045 - val_loss: 1.8597 - val_accuracy: 0.5420\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0555 - accuracy: 0.6090 - val_loss: 1.8478 - val_accuracy: 0.5260\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 1.0489 - accuracy: 0.6100 - val_loss: 1.8410 - val_accuracy: 0.5200\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0680 - accuracy: 0.6025 - val_loss: 1.8459 - val_accuracy: 0.5300\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0597 - accuracy: 0.6155 - val_loss: 1.8667 - val_accuracy: 0.5300\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.1005 - accuracy: 0.5805 - val_loss: 1.8648 - val_accuracy: 0.5300\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0981 - accuracy: 0.5935 - val_loss: 1.8751 - val_accuracy: 0.5260\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0447 - accuracy: 0.6060 - val_loss: 1.8594 - val_accuracy: 0.5300\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0517 - accuracy: 0.6115 - val_loss: 1.8671 - val_accuracy: 0.5320\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.1072 - accuracy: 0.5975 - val_loss: 1.8794 - val_accuracy: 0.5300\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.0566 - accuracy: 0.6115 - val_loss: 1.8839 - val_accuracy: 0.5340\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0604 - accuracy: 0.6035 - val_loss: 1.8826 - val_accuracy: 0.5320\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0474 - accuracy: 0.5855 - val_loss: 1.8807 - val_accuracy: 0.5280\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.1077 - accuracy: 0.5890 - val_loss: 1.8870 - val_accuracy: 0.5260\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 1.1037 - accuracy: 0.5805 - val_loss: 1.8956 - val_accuracy: 0.5260\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0651 - accuracy: 0.5950 - val_loss: 1.8966 - val_accuracy: 0.5300\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.0460 - accuracy: 0.6165 - val_loss: 1.8954 - val_accuracy: 0.5380\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0485 - accuracy: 0.6135 - val_loss: 1.8891 - val_accuracy: 0.5380\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 286us/step - loss: 1.0180 - accuracy: 0.6195 - val_loss: 1.9037 - val_accuracy: 0.5340\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.0532 - accuracy: 0.6075 - val_loss: 1.9253 - val_accuracy: 0.5320\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.0614 - accuracy: 0.6135 - val_loss: 1.9041 - val_accuracy: 0.5360\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0310 - accuracy: 0.6065 - val_loss: 1.8798 - val_accuracy: 0.5360\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.0677 - accuracy: 0.6015 - val_loss: 1.8673 - val_accuracy: 0.5380\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.0632 - accuracy: 0.6000 - val_loss: 1.8731 - val_accuracy: 0.5340\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.0868 - accuracy: 0.5975 - val_loss: 1.8891 - val_accuracy: 0.5320\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 1.0360 - accuracy: 0.6160 - val_loss: 1.8944 - val_accuracy: 0.5240\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.0443 - accuracy: 0.6140 - val_loss: 1.8739 - val_accuracy: 0.5260\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0457 - accuracy: 0.6055 - val_loss: 1.8729 - val_accuracy: 0.5400\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 271us/step - loss: 1.0290 - accuracy: 0.6185 - val_loss: 1.8887 - val_accuracy: 0.5340\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.0371 - accuracy: 0.6220 - val_loss: 1.9111 - val_accuracy: 0.5400\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0433 - accuracy: 0.6040 - val_loss: 1.9176 - val_accuracy: 0.5360\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.0531 - accuracy: 0.6050 - val_loss: 1.9199 - val_accuracy: 0.5340\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.0217 - accuracy: 0.6135 - val_loss: 1.9358 - val_accuracy: 0.5300\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0577 - accuracy: 0.6035 - val_loss: 1.9426 - val_accuracy: 0.5360\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0435 - accuracy: 0.6165 - val_loss: 1.9359 - val_accuracy: 0.5320\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 1.0703 - accuracy: 0.5995 - val_loss: 1.9237 - val_accuracy: 0.5300\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0276 - accuracy: 0.6260 - val_loss: 1.9467 - val_accuracy: 0.5260\n",
      "Epoch 86/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.9918 - accuracy: 0.6360 - val_loss: 1.9541 - val_accuracy: 0.5260\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.0640 - accuracy: 0.6040 - val_loss: 1.9358 - val_accuracy: 0.5340\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0818 - accuracy: 0.6030 - val_loss: 1.9137 - val_accuracy: 0.5320\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 1.0514 - accuracy: 0.6010 - val_loss: 1.9040 - val_accuracy: 0.5260\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.0570 - accuracy: 0.6135 - val_loss: 1.8995 - val_accuracy: 0.5260\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.0729 - accuracy: 0.5970 - val_loss: 1.9185 - val_accuracy: 0.5160\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.0688 - accuracy: 0.6165 - val_loss: 1.9413 - val_accuracy: 0.5220\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0399 - accuracy: 0.6080 - val_loss: 1.9515 - val_accuracy: 0.5220\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 322us/step - loss: 1.0137 - accuracy: 0.6150 - val_loss: 1.9445 - val_accuracy: 0.5280\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.0543 - accuracy: 0.6070 - val_loss: 1.9326 - val_accuracy: 0.5320\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0277 - accuracy: 0.6085 - val_loss: 1.9147 - val_accuracy: 0.5300\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 1.0460 - accuracy: 0.5950 - val_loss: 1.9117 - val_accuracy: 0.5320\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0165 - accuracy: 0.6175 - val_loss: 1.9019 - val_accuracy: 0.5200\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: 1.0611 - accuracy: 0.6020 - val_loss: 1.8987 - val_accuracy: 0.5180\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 1.0657 - accuracy: 0.6020 - val_loss: 1.9039 - val_accuracy: 0.5220\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.0524 - accuracy: 0.6060 - val_loss: 1.9166 - val_accuracy: 0.5260\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 1.0534 - accuracy: 0.6010 - val_loss: 1.9147 - val_accuracy: 0.5240\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0411 - accuracy: 0.6020 - val_loss: 1.9187 - val_accuracy: 0.5280\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0386 - accuracy: 0.6125 - val_loss: 1.9121 - val_accuracy: 0.5280\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.0528 - accuracy: 0.6110 - val_loss: 1.9237 - val_accuracy: 0.5280\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 1.0445 - accuracy: 0.5990 - val_loss: 1.9363 - val_accuracy: 0.5240\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0214 - accuracy: 0.6090 - val_loss: 1.9167 - val_accuracy: 0.5200\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.0574 - accuracy: 0.5960 - val_loss: 1.9101 - val_accuracy: 0.5260\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 1.0592 - accuracy: 0.5865 - val_loss: 1.9040 - val_accuracy: 0.5140\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 1.0414 - accuracy: 0.6175 - val_loss: 1.9151 - val_accuracy: 0.5240\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.0142 - accuracy: 0.6235 - val_loss: 1.9351 - val_accuracy: 0.5180\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0222 - accuracy: 0.6015 - val_loss: 1.9353 - val_accuracy: 0.5200\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.0395 - accuracy: 0.6070 - val_loss: 1.9321 - val_accuracy: 0.5180\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0736 - accuracy: 0.5955 - val_loss: 1.9180 - val_accuracy: 0.5160\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 279us/step - loss: 1.0609 - accuracy: 0.6255 - val_loss: 1.9238 - val_accuracy: 0.5200\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 1.0450 - accuracy: 0.6040 - val_loss: 1.9239 - val_accuracy: 0.5200\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.0590 - accuracy: 0.5990 - val_loss: 1.9340 - val_accuracy: 0.5200\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.0412 - accuracy: 0.6080 - val_loss: 1.9244 - val_accuracy: 0.5140\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0475 - accuracy: 0.5965 - val_loss: 1.9384 - val_accuracy: 0.5200\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 286us/step - loss: 1.0467 - accuracy: 0.6080 - val_loss: 1.9662 - val_accuracy: 0.5160\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0414 - accuracy: 0.6095 - val_loss: 1.9766 - val_accuracy: 0.5140\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0256 - accuracy: 0.6230 - val_loss: 1.9750 - val_accuracy: 0.5200\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.0071 - accuracy: 0.6115 - val_loss: 1.9752 - val_accuracy: 0.5220\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.0045 - accuracy: 0.6285 - val_loss: 1.9454 - val_accuracy: 0.5180\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.0215 - accuracy: 0.6205 - val_loss: 1.9201 - val_accuracy: 0.5220\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0174 - accuracy: 0.6205 - val_loss: 1.9048 - val_accuracy: 0.5260\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.0072 - accuracy: 0.6300 - val_loss: 1.9180 - val_accuracy: 0.5340\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 311us/step - loss: 1.0384 - accuracy: 0.6000 - val_loss: 1.9347 - val_accuracy: 0.5260\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 0.9965 - accuracy: 0.6335 - val_loss: 1.9411 - val_accuracy: 0.5160\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 1.0330 - accuracy: 0.6160 - val_loss: 1.9439 - val_accuracy: 0.5220\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0276 - accuracy: 0.6020 - val_loss: 1.9526 - val_accuracy: 0.5120\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.9790 - accuracy: 0.6435 - val_loss: 1.9622 - val_accuracy: 0.5200\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.0451 - accuracy: 0.6120 - val_loss: 1.9566 - val_accuracy: 0.5160\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 0.9765 - accuracy: 0.6305 - val_loss: 1.9481 - val_accuracy: 0.5160\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.9867 - accuracy: 0.6280 - val_loss: 1.9543 - val_accuracy: 0.5120\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 0.9634 - accuracy: 0.6395 - val_loss: 1.9470 - val_accuracy: 0.5160\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0277 - accuracy: 0.6325 - val_loss: 1.9453 - val_accuracy: 0.5280\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 1.0266 - accuracy: 0.6200 - val_loss: 1.9432 - val_accuracy: 0.5340\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0008 - accuracy: 0.6215 - val_loss: 1.9570 - val_accuracy: 0.5240\n",
      "Epoch 140/200\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 1.0299 - accuracy: 0.6205 - val_loss: 1.9713 - val_accuracy: 0.5200\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 0.9772 - accuracy: 0.6275 - val_loss: 1.9682 - val_accuracy: 0.5200\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0106 - accuracy: 0.6255 - val_loss: 1.9705 - val_accuracy: 0.5180\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 1.0397 - accuracy: 0.6040 - val_loss: 1.9687 - val_accuracy: 0.5280\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.0077 - accuracy: 0.6235 - val_loss: 1.9703 - val_accuracy: 0.5200\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 1.0219 - accuracy: 0.6220 - val_loss: 1.9734 - val_accuracy: 0.5220\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0586 - accuracy: 0.6050 - val_loss: 1.9491 - val_accuracy: 0.5260\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.0153 - accuracy: 0.6170 - val_loss: 1.9429 - val_accuracy: 0.5280\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 0.9940 - accuracy: 0.6195 - val_loss: 1.9629 - val_accuracy: 0.5340\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.9975 - accuracy: 0.6225 - val_loss: 1.9652 - val_accuracy: 0.5240\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.9893 - accuracy: 0.6350 - val_loss: 1.9849 - val_accuracy: 0.5180\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.9932 - accuracy: 0.6290 - val_loss: 2.0082 - val_accuracy: 0.5220\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 0.9856 - accuracy: 0.6365 - val_loss: 2.0095 - val_accuracy: 0.5200\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.0270 - accuracy: 0.6260 - val_loss: 1.9982 - val_accuracy: 0.5180\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 0.9872 - accuracy: 0.6360 - val_loss: 1.9923 - val_accuracy: 0.5300\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0613 - accuracy: 0.6015 - val_loss: 2.0020 - val_accuracy: 0.5220\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 1.0578 - accuracy: 0.6050 - val_loss: 2.0210 - val_accuracy: 0.5260\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0123 - accuracy: 0.6150 - val_loss: 2.0337 - val_accuracy: 0.5320\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 1.0372 - accuracy: 0.6110 - val_loss: 2.0391 - val_accuracy: 0.5240\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0288 - accuracy: 0.6165 - val_loss: 2.0347 - val_accuracy: 0.5180\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 336us/step - loss: 1.0428 - accuracy: 0.6105 - val_loss: 2.0317 - val_accuracy: 0.5080\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 1.0279 - accuracy: 0.6035 - val_loss: 2.0168 - val_accuracy: 0.5060\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 1.0355 - accuracy: 0.6215 - val_loss: 1.9801 - val_accuracy: 0.5060\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 280us/step - loss: 1.0042 - accuracy: 0.6230 - val_loss: 1.9646 - val_accuracy: 0.5080\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0579 - accuracy: 0.6040 - val_loss: 1.9740 - val_accuracy: 0.5080\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 281us/step - loss: 1.0186 - accuracy: 0.6240 - val_loss: 1.9795 - val_accuracy: 0.5140\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 283us/step - loss: 0.9949 - accuracy: 0.6250 - val_loss: 1.9709 - val_accuracy: 0.5120\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 308us/step - loss: 1.0191 - accuracy: 0.6205 - val_loss: 1.9799 - val_accuracy: 0.5240\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 1.0061 - accuracy: 0.6315 - val_loss: 2.0007 - val_accuracy: 0.5240\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 313us/step - loss: 1.0234 - accuracy: 0.6255 - val_loss: 2.0096 - val_accuracy: 0.5300\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.0256 - accuracy: 0.6115 - val_loss: 2.0226 - val_accuracy: 0.5300\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.9958 - accuracy: 0.6265 - val_loss: 2.0238 - val_accuracy: 0.5240\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0231 - accuracy: 0.6250 - val_loss: 2.0103 - val_accuracy: 0.5200\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.0293 - accuracy: 0.6120 - val_loss: 2.0071 - val_accuracy: 0.5220\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 310us/step - loss: 1.0043 - accuracy: 0.6245 - val_loss: 2.0035 - val_accuracy: 0.5340\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0211 - accuracy: 0.6175 - val_loss: 2.0158 - val_accuracy: 0.5340\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 308us/step - loss: 0.9878 - accuracy: 0.6295 - val_loss: 2.0222 - val_accuracy: 0.5380\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 309us/step - loss: 1.0108 - accuracy: 0.6240 - val_loss: 2.0262 - val_accuracy: 0.5360\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 1.0317 - accuracy: 0.6060 - val_loss: 2.0364 - val_accuracy: 0.5300\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 1.0081 - accuracy: 0.6265 - val_loss: 2.0570 - val_accuracy: 0.5260\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 312us/step - loss: 1.0454 - accuracy: 0.6165 - val_loss: 2.0631 - val_accuracy: 0.5180\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 0.9894 - accuracy: 0.6270 - val_loss: 2.0564 - val_accuracy: 0.5320\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 320us/step - loss: 1.0195 - accuracy: 0.6045 - val_loss: 2.0496 - val_accuracy: 0.5300\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 1.0209 - accuracy: 0.6190 - val_loss: 2.0397 - val_accuracy: 0.5180\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 1.0485 - accuracy: 0.6070 - val_loss: 2.0306 - val_accuracy: 0.5260\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0765 - accuracy: 0.6020 - val_loss: 2.0298 - val_accuracy: 0.5300\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0309 - accuracy: 0.6205 - val_loss: 2.0161 - val_accuracy: 0.5220\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 319us/step - loss: 0.9901 - accuracy: 0.6360 - val_loss: 2.0281 - val_accuracy: 0.5180\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.9792 - accuracy: 0.6360 - val_loss: 2.0483 - val_accuracy: 0.5220\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 314us/step - loss: 0.9808 - accuracy: 0.6390 - val_loss: 2.0630 - val_accuracy: 0.5220\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 1.0096 - accuracy: 0.6110 - val_loss: 2.0583 - val_accuracy: 0.5160\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.9719 - accuracy: 0.6215 - val_loss: 2.0348 - val_accuracy: 0.5140\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 0.9865 - accuracy: 0.6340 - val_loss: 2.0344 - val_accuracy: 0.5200\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 0.9906 - accuracy: 0.6320 - val_loss: 2.0436 - val_accuracy: 0.5220\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 1.0390 - accuracy: 0.6005 - val_loss: 2.0653 - val_accuracy: 0.5220\n",
      "Epoch 195/200\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.9789 - accuracy: 0.6315 - val_loss: 2.0834 - val_accuracy: 0.5200\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 343us/step - loss: 1.0132 - accuracy: 0.6095 - val_loss: 2.0797 - val_accuracy: 0.5240\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 0.9861 - accuracy: 0.6325 - val_loss: 2.0391 - val_accuracy: 0.5240\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.9934 - accuracy: 0.6130 - val_loss: 2.0391 - val_accuracy: 0.5340\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 0.9825 - accuracy: 0.6310 - val_loss: 2.0310 - val_accuracy: 0.5280\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 326us/step - loss: 0.9818 - accuracy: 0.6320 - val_loss: 2.0130 - val_accuracy: 0.5260\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/200\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 1.0012 - accuracy: 0.6230 - val_loss: 2.0156 - val_accuracy: 0.5280\n",
      "Epoch 2/200\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 1.0160 - accuracy: 0.6330 - val_loss: 2.0192 - val_accuracy: 0.5220\n",
      "Epoch 3/200\n",
      "2000/2000 [==============================] - 1s 484us/step - loss: 0.9732 - accuracy: 0.6390 - val_loss: 2.0200 - val_accuracy: 0.5200\n",
      "Epoch 4/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 1.0099 - accuracy: 0.6285 - val_loss: 2.0222 - val_accuracy: 0.5200\n",
      "Epoch 5/200\n",
      "2000/2000 [==============================] - 1s 514us/step - loss: 1.0173 - accuracy: 0.6220 - val_loss: 2.0246 - val_accuracy: 0.5240\n",
      "Epoch 6/200\n",
      "2000/2000 [==============================] - 1s 429us/step - loss: 1.0128 - accuracy: 0.6230 - val_loss: 2.0254 - val_accuracy: 0.5300\n",
      "Epoch 7/200\n",
      "2000/2000 [==============================] - 1s 573us/step - loss: 1.0331 - accuracy: 0.6250 - val_loss: 2.0262 - val_accuracy: 0.5300\n",
      "Epoch 8/200\n",
      "2000/2000 [==============================] - 1s 489us/step - loss: 0.9895 - accuracy: 0.6210 - val_loss: 2.0251 - val_accuracy: 0.5260\n",
      "Epoch 9/200\n",
      "2000/2000 [==============================] - 1s 471us/step - loss: 0.9839 - accuracy: 0.6340 - val_loss: 2.0265 - val_accuracy: 0.5280\n",
      "Epoch 10/200\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 1.0269 - accuracy: 0.6145 - val_loss: 2.0276 - val_accuracy: 0.5240\n",
      "Epoch 11/200\n",
      "2000/2000 [==============================] - 1s 470us/step - loss: 0.9976 - accuracy: 0.6395 - val_loss: 2.0296 - val_accuracy: 0.5220\n",
      "Epoch 12/200\n",
      "2000/2000 [==============================] - 1s 478us/step - loss: 0.9951 - accuracy: 0.6325 - val_loss: 2.0297 - val_accuracy: 0.5220\n",
      "Epoch 13/200\n",
      "2000/2000 [==============================] - 1s 498us/step - loss: 0.9870 - accuracy: 0.6245 - val_loss: 2.0271 - val_accuracy: 0.5220\n",
      "Epoch 14/200\n",
      "2000/2000 [==============================] - 1s 423us/step - loss: 0.9540 - accuracy: 0.6430 - val_loss: 2.0260 - val_accuracy: 0.5300\n",
      "Epoch 15/200\n",
      "2000/2000 [==============================] - 1s 437us/step - loss: 1.0088 - accuracy: 0.6315 - val_loss: 2.0258 - val_accuracy: 0.5280\n",
      "Epoch 16/200\n",
      "2000/2000 [==============================] - 1s 432us/step - loss: 1.0289 - accuracy: 0.6185 - val_loss: 2.0229 - val_accuracy: 0.5280\n",
      "Epoch 17/200\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 1.0422 - accuracy: 0.6295 - val_loss: 2.0230 - val_accuracy: 0.5260\n",
      "Epoch 18/200\n",
      "2000/2000 [==============================] - 1s 441us/step - loss: 0.9994 - accuracy: 0.6250 - val_loss: 2.0244 - val_accuracy: 0.5280\n",
      "Epoch 19/200\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.9720 - accuracy: 0.6370 - val_loss: 2.0236 - val_accuracy: 0.5280\n",
      "Epoch 20/200\n",
      "2000/2000 [==============================] - 1s 474us/step - loss: 1.0038 - accuracy: 0.6295 - val_loss: 2.0215 - val_accuracy: 0.5300\n",
      "Epoch 21/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.9583 - accuracy: 0.6390 - val_loss: 2.0213 - val_accuracy: 0.5280\n",
      "Epoch 22/200\n",
      "2000/2000 [==============================] - 1s 436us/step - loss: 1.0454 - accuracy: 0.6195 - val_loss: 2.0212 - val_accuracy: 0.5300\n",
      "Epoch 23/200\n",
      "2000/2000 [==============================] - 1s 437us/step - loss: 0.9864 - accuracy: 0.6235 - val_loss: 2.0226 - val_accuracy: 0.5300\n",
      "Epoch 24/200\n",
      "2000/2000 [==============================] - 1s 470us/step - loss: 0.9835 - accuracy: 0.6250 - val_loss: 2.0241 - val_accuracy: 0.5280\n",
      "Epoch 25/200\n",
      "2000/2000 [==============================] - 1s 482us/step - loss: 1.0199 - accuracy: 0.6205 - val_loss: 2.0246 - val_accuracy: 0.5260\n",
      "Epoch 26/200\n",
      "2000/2000 [==============================] - 1s 492us/step - loss: 1.0025 - accuracy: 0.6180 - val_loss: 2.0289 - val_accuracy: 0.5300\n",
      "Epoch 27/200\n",
      "2000/2000 [==============================] - 1s 489us/step - loss: 0.9847 - accuracy: 0.6310 - val_loss: 2.0286 - val_accuracy: 0.5300\n",
      "Epoch 28/200\n",
      "2000/2000 [==============================] - 1s 472us/step - loss: 1.0633 - accuracy: 0.6055 - val_loss: 2.0316 - val_accuracy: 0.5300\n",
      "Epoch 29/200\n",
      "2000/2000 [==============================] - 1s 477us/step - loss: 0.9890 - accuracy: 0.6200 - val_loss: 2.0317 - val_accuracy: 0.5300\n",
      "Epoch 30/200\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 1.0015 - accuracy: 0.6240 - val_loss: 2.0339 - val_accuracy: 0.5300\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 424us/step - loss: 1.0120 - accuracy: 0.6235 - val_loss: 2.0357 - val_accuracy: 0.5240\n",
      "Epoch 32/200\n",
      "2000/2000 [==============================] - 1s 360us/step - loss: 0.9957 - accuracy: 0.6370 - val_loss: 2.0377 - val_accuracy: 0.5220\n",
      "Epoch 33/200\n",
      "2000/2000 [==============================] - 1s 330us/step - loss: 1.0232 - accuracy: 0.6285 - val_loss: 2.0389 - val_accuracy: 0.5180\n",
      "Epoch 34/200\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 1.0061 - accuracy: 0.6345 - val_loss: 2.0343 - val_accuracy: 0.5180\n",
      "Epoch 35/200\n",
      "2000/2000 [==============================] - 1s 317us/step - loss: 1.0127 - accuracy: 0.6315 - val_loss: 2.0362 - val_accuracy: 0.5160\n",
      "Epoch 36/200\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0205 - accuracy: 0.6225 - val_loss: 2.0365 - val_accuracy: 0.5180\n",
      "Epoch 37/200\n",
      "2000/2000 [==============================] - 1s 321us/step - loss: 0.9868 - accuracy: 0.6385 - val_loss: 2.0372 - val_accuracy: 0.5160\n",
      "Epoch 38/200\n",
      "2000/2000 [==============================] - 1s 315us/step - loss: 1.0014 - accuracy: 0.6290 - val_loss: 2.0366 - val_accuracy: 0.5180\n",
      "Epoch 39/200\n",
      "2000/2000 [==============================] - 1s 318us/step - loss: 0.9937 - accuracy: 0.6330 - val_loss: 2.0395 - val_accuracy: 0.5180\n",
      "Epoch 40/200\n",
      "2000/2000 [==============================] - 1s 346us/step - loss: 1.0418 - accuracy: 0.6055 - val_loss: 2.0372 - val_accuracy: 0.5160\n",
      "Epoch 41/200\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 1.0088 - accuracy: 0.6305 - val_loss: 2.0366 - val_accuracy: 0.5180\n",
      "Epoch 42/200\n",
      "2000/2000 [==============================] - 1s 429us/step - loss: 0.9262 - accuracy: 0.6455 - val_loss: 2.0393 - val_accuracy: 0.5180\n",
      "Epoch 43/200\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 1.0368 - accuracy: 0.6130 - val_loss: 2.0373 - val_accuracy: 0.5160\n",
      "Epoch 44/200\n",
      "2000/2000 [==============================] - 1s 443us/step - loss: 0.9382 - accuracy: 0.6365 - val_loss: 2.0405 - val_accuracy: 0.5160\n",
      "Epoch 45/200\n",
      "2000/2000 [==============================] - 1s 458us/step - loss: 1.0132 - accuracy: 0.6225 - val_loss: 2.0431 - val_accuracy: 0.5180\n",
      "Epoch 46/200\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 1.0212 - accuracy: 0.6205 - val_loss: 2.0445 - val_accuracy: 0.5180\n",
      "Epoch 47/200\n",
      "2000/2000 [==============================] - 1s 428us/step - loss: 0.9725 - accuracy: 0.6310 - val_loss: 2.0419 - val_accuracy: 0.5200\n",
      "Epoch 48/200\n",
      "2000/2000 [==============================] - 1s 458us/step - loss: 0.9861 - accuracy: 0.6295 - val_loss: 2.0387 - val_accuracy: 0.5200\n",
      "Epoch 49/200\n",
      "2000/2000 [==============================] - 1s 451us/step - loss: 1.0345 - accuracy: 0.6225 - val_loss: 2.0376 - val_accuracy: 0.5200\n",
      "Epoch 50/200\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.9502 - accuracy: 0.6460 - val_loss: 2.0362 - val_accuracy: 0.5220\n",
      "Epoch 51/200\n",
      "2000/2000 [==============================] - 1s 471us/step - loss: 0.9863 - accuracy: 0.6325 - val_loss: 2.0365 - val_accuracy: 0.5240\n",
      "Epoch 52/200\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 0.9919 - accuracy: 0.6225 - val_loss: 2.0375 - val_accuracy: 0.5240\n",
      "Epoch 53/200\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.9840 - accuracy: 0.6265 - val_loss: 2.0370 - val_accuracy: 0.5260\n",
      "Epoch 54/200\n",
      "2000/2000 [==============================] - 1s 476us/step - loss: 0.9972 - accuracy: 0.6240 - val_loss: 2.0375 - val_accuracy: 0.5260\n",
      "Epoch 55/200\n",
      "2000/2000 [==============================] - 1s 536us/step - loss: 1.0626 - accuracy: 0.6040 - val_loss: 2.0367 - val_accuracy: 0.5240\n",
      "Epoch 56/200\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.9593 - accuracy: 0.6425 - val_loss: 2.0344 - val_accuracy: 0.5240\n",
      "Epoch 57/200\n",
      "2000/2000 [==============================] - 1s 446us/step - loss: 0.9631 - accuracy: 0.6410 - val_loss: 2.0355 - val_accuracy: 0.5220\n",
      "Epoch 58/200\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.9817 - accuracy: 0.6400 - val_loss: 2.0384 - val_accuracy: 0.5260\n",
      "Epoch 59/200\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 1.0145 - accuracy: 0.6380 - val_loss: 2.0395 - val_accuracy: 0.5240\n",
      "Epoch 60/200\n",
      "2000/2000 [==============================] - 1s 479us/step - loss: 1.0024 - accuracy: 0.6250 - val_loss: 2.0396 - val_accuracy: 0.5240\n",
      "Epoch 61/200\n",
      "2000/2000 [==============================] - 1s 471us/step - loss: 0.9979 - accuracy: 0.6315 - val_loss: 2.0376 - val_accuracy: 0.5240\n",
      "Epoch 62/200\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 1.0094 - accuracy: 0.6145 - val_loss: 2.0355 - val_accuracy: 0.5220\n",
      "Epoch 63/200\n",
      "2000/2000 [==============================] - 1s 488us/step - loss: 1.0232 - accuracy: 0.6285 - val_loss: 2.0346 - val_accuracy: 0.5220\n",
      "Epoch 64/200\n",
      "2000/2000 [==============================] - 1s 463us/step - loss: 1.0150 - accuracy: 0.6090 - val_loss: 2.0365 - val_accuracy: 0.5220\n",
      "Epoch 65/200\n",
      "2000/2000 [==============================] - 1s 511us/step - loss: 1.0004 - accuracy: 0.6250 - val_loss: 2.0368 - val_accuracy: 0.5220\n",
      "Epoch 66/200\n",
      "2000/2000 [==============================] - 1s 471us/step - loss: 0.9848 - accuracy: 0.6290 - val_loss: 2.0366 - val_accuracy: 0.5220\n",
      "Epoch 67/200\n",
      "2000/2000 [==============================] - 1s 422us/step - loss: 1.0011 - accuracy: 0.6235 - val_loss: 2.0365 - val_accuracy: 0.5220\n",
      "Epoch 68/200\n",
      "2000/2000 [==============================] - 1s 468us/step - loss: 0.9913 - accuracy: 0.6415 - val_loss: 2.0341 - val_accuracy: 0.5220\n",
      "Epoch 69/200\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 1.0136 - accuracy: 0.6150 - val_loss: 2.0321 - val_accuracy: 0.5260\n",
      "Epoch 70/200\n",
      "2000/2000 [==============================] - 1s 478us/step - loss: 0.9951 - accuracy: 0.6405 - val_loss: 2.0312 - val_accuracy: 0.5300\n",
      "Epoch 71/200\n",
      "2000/2000 [==============================] - 1s 473us/step - loss: 1.0065 - accuracy: 0.6200 - val_loss: 2.0292 - val_accuracy: 0.5280\n",
      "Epoch 72/200\n",
      "2000/2000 [==============================] - 1s 471us/step - loss: 1.0033 - accuracy: 0.6220 - val_loss: 2.0323 - val_accuracy: 0.5220\n",
      "Epoch 73/200\n",
      "2000/2000 [==============================] - 1s 471us/step - loss: 0.9827 - accuracy: 0.6450 - val_loss: 2.0326 - val_accuracy: 0.5220\n",
      "Epoch 74/200\n",
      "2000/2000 [==============================] - 1s 476us/step - loss: 1.0060 - accuracy: 0.6180 - val_loss: 2.0333 - val_accuracy: 0.5240\n",
      "Epoch 75/200\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.9865 - accuracy: 0.6240 - val_loss: 2.0311 - val_accuracy: 0.5240\n",
      "Epoch 76/200\n",
      "2000/2000 [==============================] - 1s 463us/step - loss: 0.9892 - accuracy: 0.6340 - val_loss: 2.0288 - val_accuracy: 0.5220\n",
      "Epoch 77/200\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 1.0019 - accuracy: 0.6190 - val_loss: 2.0297 - val_accuracy: 0.5220\n",
      "Epoch 78/200\n",
      "2000/2000 [==============================] - 1s 489us/step - loss: 1.0029 - accuracy: 0.6290 - val_loss: 2.0322 - val_accuracy: 0.5240\n",
      "Epoch 79/200\n",
      "2000/2000 [==============================] - 1s 433us/step - loss: 1.0133 - accuracy: 0.6210 - val_loss: 2.0326 - val_accuracy: 0.5240\n",
      "Epoch 80/200\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 1.0219 - accuracy: 0.6135 - val_loss: 2.0321 - val_accuracy: 0.5240\n",
      "Epoch 81/200\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 1.0076 - accuracy: 0.6265 - val_loss: 2.0290 - val_accuracy: 0.5240\n",
      "Epoch 82/200\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.9873 - accuracy: 0.6210 - val_loss: 2.0287 - val_accuracy: 0.5280\n",
      "Epoch 83/200\n",
      "2000/2000 [==============================] - 1s 435us/step - loss: 0.9718 - accuracy: 0.6365 - val_loss: 2.0319 - val_accuracy: 0.5280\n",
      "Epoch 84/200\n",
      "2000/2000 [==============================] - 1s 427us/step - loss: 1.0259 - accuracy: 0.6215 - val_loss: 2.0348 - val_accuracy: 0.5280\n",
      "Epoch 85/200\n",
      "2000/2000 [==============================] - 1s 444us/step - loss: 1.0206 - accuracy: 0.6170 - val_loss: 2.0368 - val_accuracy: 0.5240\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 540us/step - loss: 0.9799 - accuracy: 0.6350 - val_loss: 2.0378 - val_accuracy: 0.5240\n",
      "Epoch 87/200\n",
      "2000/2000 [==============================] - 1s 484us/step - loss: 1.0172 - accuracy: 0.6310 - val_loss: 2.0371 - val_accuracy: 0.5260\n",
      "Epoch 88/200\n",
      "2000/2000 [==============================] - 1s 487us/step - loss: 0.9406 - accuracy: 0.6395 - val_loss: 2.0367 - val_accuracy: 0.5280\n",
      "Epoch 89/200\n",
      "2000/2000 [==============================] - 1s 481us/step - loss: 1.0149 - accuracy: 0.6240 - val_loss: 2.0354 - val_accuracy: 0.5300\n",
      "Epoch 90/200\n",
      "2000/2000 [==============================] - 1s 456us/step - loss: 1.0127 - accuracy: 0.6200 - val_loss: 2.0353 - val_accuracy: 0.5280\n",
      "Epoch 91/200\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 1.0169 - accuracy: 0.6245 - val_loss: 2.0356 - val_accuracy: 0.5300\n",
      "Epoch 92/200\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.9871 - accuracy: 0.6205 - val_loss: 2.0360 - val_accuracy: 0.5300\n",
      "Epoch 93/200\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.9874 - accuracy: 0.6255 - val_loss: 2.0370 - val_accuracy: 0.5300\n",
      "Epoch 94/200\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 1.0012 - accuracy: 0.6315 - val_loss: 2.0335 - val_accuracy: 0.5300\n",
      "Epoch 95/200\n",
      "2000/2000 [==============================] - 1s 458us/step - loss: 0.9639 - accuracy: 0.6290 - val_loss: 2.0351 - val_accuracy: 0.5280\n",
      "Epoch 96/200\n",
      "2000/2000 [==============================] - 1s 474us/step - loss: 1.0188 - accuracy: 0.6225 - val_loss: 2.0362 - val_accuracy: 0.5260\n",
      "Epoch 97/200\n",
      "2000/2000 [==============================] - 1s 489us/step - loss: 1.0144 - accuracy: 0.6350 - val_loss: 2.0351 - val_accuracy: 0.5280\n",
      "Epoch 98/200\n",
      "2000/2000 [==============================] - 1s 433us/step - loss: 0.9894 - accuracy: 0.6335 - val_loss: 2.0373 - val_accuracy: 0.5280\n",
      "Epoch 99/200\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 1.0007 - accuracy: 0.6210 - val_loss: 2.0341 - val_accuracy: 0.5280\n",
      "Epoch 100/200\n",
      "2000/2000 [==============================] - 1s 437us/step - loss: 1.0104 - accuracy: 0.6370 - val_loss: 2.0339 - val_accuracy: 0.5280\n",
      "Epoch 101/200\n",
      "2000/2000 [==============================] - 1s 471us/step - loss: 1.0083 - accuracy: 0.6210 - val_loss: 2.0370 - val_accuracy: 0.5300\n",
      "Epoch 102/200\n",
      "2000/2000 [==============================] - 1s 481us/step - loss: 0.9839 - accuracy: 0.6495 - val_loss: 2.0392 - val_accuracy: 0.5280\n",
      "Epoch 103/200\n",
      "2000/2000 [==============================] - 1s 448us/step - loss: 1.0137 - accuracy: 0.6230 - val_loss: 2.0428 - val_accuracy: 0.5260\n",
      "Epoch 104/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9988 - accuracy: 0.62 - 1s 455us/step - loss: 0.9911 - accuracy: 0.6225 - val_loss: 2.0418 - val_accuracy: 0.5280\n",
      "Epoch 105/200\n",
      "2000/2000 [==============================] - 1s 488us/step - loss: 0.9677 - accuracy: 0.6385 - val_loss: 2.0409 - val_accuracy: 0.5240\n",
      "Epoch 106/200\n",
      "2000/2000 [==============================] - 1s 490us/step - loss: 0.9746 - accuracy: 0.6415 - val_loss: 2.0408 - val_accuracy: 0.5260\n",
      "Epoch 107/200\n",
      "2000/2000 [==============================] - 1s 446us/step - loss: 0.9987 - accuracy: 0.6435 - val_loss: 2.0409 - val_accuracy: 0.5280\n",
      "Epoch 108/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.9638 - accuracy: 0.6415 - val_loss: 2.0419 - val_accuracy: 0.5300\n",
      "Epoch 109/200\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 1.0012 - accuracy: 0.6180 - val_loss: 2.0445 - val_accuracy: 0.5280\n",
      "Epoch 110/200\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.9863 - accuracy: 0.6380 - val_loss: 2.0441 - val_accuracy: 0.5300\n",
      "Epoch 111/200\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.9854 - accuracy: 0.6380 - val_loss: 2.0433 - val_accuracy: 0.5320\n",
      "Epoch 112/200\n",
      "2000/2000 [==============================] - 1s 464us/step - loss: 0.9916 - accuracy: 0.6400 - val_loss: 2.0419 - val_accuracy: 0.5300\n",
      "Epoch 113/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.9413 - accuracy: 0.6580 - val_loss: 2.0413 - val_accuracy: 0.5260\n",
      "Epoch 114/200\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 1.0132 - accuracy: 0.6280 - val_loss: 2.0403 - val_accuracy: 0.5220\n",
      "Epoch 115/200\n",
      "2000/2000 [==============================] - 1s 451us/step - loss: 0.9941 - accuracy: 0.6345 - val_loss: 2.0362 - val_accuracy: 0.5240\n",
      "Epoch 116/200\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9989 - accuracy: 0.6294 ETA: 0s - loss: 1.0183 - accu - 1s 470us/step - loss: 1.0043 - accuracy: 0.6265 - val_loss: 2.0365 - val_accuracy: 0.5240\n",
      "Epoch 117/200\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 1.0147 - accuracy: 0.6190 - val_loss: 2.0346 - val_accuracy: 0.5240\n",
      "Epoch 118/200\n",
      "2000/2000 [==============================] - 1s 468us/step - loss: 1.0064 - accuracy: 0.6320 - val_loss: 2.0347 - val_accuracy: 0.5260\n",
      "Epoch 119/200\n",
      "2000/2000 [==============================] - 1s 451us/step - loss: 0.9964 - accuracy: 0.6340 - val_loss: 2.0346 - val_accuracy: 0.5260\n",
      "Epoch 120/200\n",
      "2000/2000 [==============================] - 1s 481us/step - loss: 1.0042 - accuracy: 0.6305 - val_loss: 2.0345 - val_accuracy: 0.5280\n",
      "Epoch 121/200\n",
      "2000/2000 [==============================] - 1s 494us/step - loss: 0.9795 - accuracy: 0.6380 - val_loss: 2.0391 - val_accuracy: 0.5240\n",
      "Epoch 122/200\n",
      "2000/2000 [==============================] - 1s 487us/step - loss: 1.0259 - accuracy: 0.6190 - val_loss: 2.0393 - val_accuracy: 0.5220\n",
      "Epoch 123/200\n",
      "2000/2000 [==============================] - 1s 487us/step - loss: 0.9637 - accuracy: 0.6375 - val_loss: 2.0367 - val_accuracy: 0.5260\n",
      "Epoch 124/200\n",
      "2000/2000 [==============================] - 1s 464us/step - loss: 0.9749 - accuracy: 0.6375 - val_loss: 2.0384 - val_accuracy: 0.5240\n",
      "Epoch 125/200\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 1.0148 - accuracy: 0.6260 - val_loss: 2.0432 - val_accuracy: 0.5240\n",
      "Epoch 126/200\n",
      "2000/2000 [==============================] - 1s 477us/step - loss: 1.0047 - accuracy: 0.6330 - val_loss: 2.0461 - val_accuracy: 0.5240\n",
      "Epoch 127/200\n",
      "2000/2000 [==============================] - 1s 503us/step - loss: 0.9362 - accuracy: 0.6475 - val_loss: 2.0491 - val_accuracy: 0.5240\n",
      "Epoch 128/200\n",
      "2000/2000 [==============================] - 1s 465us/step - loss: 0.9899 - accuracy: 0.6250 - val_loss: 2.0504 - val_accuracy: 0.5240\n",
      "Epoch 129/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.9786 - accuracy: 0.6390 - val_loss: 2.0514 - val_accuracy: 0.5260\n",
      "Epoch 130/200\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 1.0134 - accuracy: 0.6200 - val_loss: 2.0524 - val_accuracy: 0.5240\n",
      "Epoch 131/200\n",
      "2000/2000 [==============================] - 1s 438us/step - loss: 0.9835 - accuracy: 0.6385 - val_loss: 2.0493 - val_accuracy: 0.5280\n",
      "Epoch 132/200\n",
      "2000/2000 [==============================] - 1s 488us/step - loss: 0.9947 - accuracy: 0.6145 - val_loss: 2.0505 - val_accuracy: 0.5280\n",
      "Epoch 133/200\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 1.0207 - accuracy: 0.6230 - val_loss: 2.0494 - val_accuracy: 0.5280\n",
      "Epoch 134/200\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 1.0068 - accuracy: 0.6250 - val_loss: 2.0462 - val_accuracy: 0.5260\n",
      "Epoch 135/200\n",
      "2000/2000 [==============================] - 1s 430us/step - loss: 0.9528 - accuracy: 0.6400 - val_loss: 2.0464 - val_accuracy: 0.5260\n",
      "Epoch 136/200\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.9705 - accuracy: 0.6365 - val_loss: 2.0467 - val_accuracy: 0.5260\n",
      "Epoch 137/200\n",
      "2000/2000 [==============================] - 1s 462us/step - loss: 1.0049 - accuracy: 0.6385 - val_loss: 2.0460 - val_accuracy: 0.5280\n",
      "Epoch 138/200\n",
      "2000/2000 [==============================] - 1s 478us/step - loss: 1.0053 - accuracy: 0.6285 - val_loss: 2.0457 - val_accuracy: 0.5300\n",
      "Epoch 139/200\n",
      "2000/2000 [==============================] - 1s 472us/step - loss: 0.9922 - accuracy: 0.6370 - val_loss: 2.0467 - val_accuracy: 0.5280\n",
      "Epoch 140/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.9688 - accuracy: 0.6400 - val_loss: 2.0456 - val_accuracy: 0.5280\n",
      "Epoch 141/200\n",
      "2000/2000 [==============================] - 1s 463us/step - loss: 0.9768 - accuracy: 0.6245 - val_loss: 2.0453 - val_accuracy: 0.5260\n",
      "Epoch 142/200\n",
      "2000/2000 [==============================] - 1s 462us/step - loss: 0.9895 - accuracy: 0.6215 - val_loss: 2.0443 - val_accuracy: 0.5280\n",
      "Epoch 143/200\n",
      "2000/2000 [==============================] - 1s 477us/step - loss: 1.0028 - accuracy: 0.6295 - val_loss: 2.0460 - val_accuracy: 0.5280\n",
      "Epoch 144/200\n",
      "2000/2000 [==============================] - 1s 481us/step - loss: 1.0256 - accuracy: 0.6190 - val_loss: 2.0486 - val_accuracy: 0.5280\n",
      "Epoch 145/200\n",
      "2000/2000 [==============================] - 1s 492us/step - loss: 0.9928 - accuracy: 0.6305 - val_loss: 2.0517 - val_accuracy: 0.5280\n",
      "Epoch 146/200\n",
      "2000/2000 [==============================] - 1s 443us/step - loss: 0.9906 - accuracy: 0.6075 - val_loss: 2.0521 - val_accuracy: 0.5300\n",
      "Epoch 147/200\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 1.0165 - accuracy: 0.6230 - val_loss: 2.0532 - val_accuracy: 0.5280\n",
      "Epoch 148/200\n",
      "2000/2000 [==============================] - 1s 498us/step - loss: 1.0251 - accuracy: 0.6305 - val_loss: 2.0486 - val_accuracy: 0.5280\n",
      "Epoch 149/200\n",
      "2000/2000 [==============================] - 1s 498us/step - loss: 0.9970 - accuracy: 0.6325 - val_loss: 2.0489 - val_accuracy: 0.5280\n",
      "Epoch 150/200\n",
      "2000/2000 [==============================] - 1s 430us/step - loss: 0.9639 - accuracy: 0.6460 - val_loss: 2.0481 - val_accuracy: 0.5300\n",
      "Epoch 151/200\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 1.0025 - accuracy: 0.6325 - val_loss: 2.0491 - val_accuracy: 0.5300\n",
      "Epoch 152/200\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 1.0037 - accuracy: 0.6285 - val_loss: 2.0486 - val_accuracy: 0.5300\n",
      "Epoch 153/200\n",
      "2000/2000 [==============================] - 1s 506us/step - loss: 0.9990 - accuracy: 0.6260 - val_loss: 2.0471 - val_accuracy: 0.5320\n",
      "Epoch 154/200\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.9926 - accuracy: 0.6230 - val_loss: 2.0467 - val_accuracy: 0.5300\n",
      "Epoch 155/200\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 0.9741 - accuracy: 0.6340 - val_loss: 2.0478 - val_accuracy: 0.5280\n",
      "Epoch 156/200\n",
      "2000/2000 [==============================] - 1s 465us/step - loss: 1.0207 - accuracy: 0.6220 - val_loss: 2.0483 - val_accuracy: 0.5280\n",
      "Epoch 157/200\n",
      "2000/2000 [==============================] - 1s 468us/step - loss: 1.0309 - accuracy: 0.6185 - val_loss: 2.0471 - val_accuracy: 0.5300\n",
      "Epoch 158/200\n",
      "2000/2000 [==============================] - 1s 451us/step - loss: 0.9686 - accuracy: 0.6400 - val_loss: 2.0468 - val_accuracy: 0.5280\n",
      "Epoch 159/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.9956 - accuracy: 0.6355 - val_loss: 2.0492 - val_accuracy: 0.5280\n",
      "Epoch 160/200\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 1.0126 - accuracy: 0.6230 - val_loss: 2.0511 - val_accuracy: 0.5300\n",
      "Epoch 161/200\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.9582 - accuracy: 0.6410 - val_loss: 2.0529 - val_accuracy: 0.5300\n",
      "Epoch 162/200\n",
      "2000/2000 [==============================] - 1s 479us/step - loss: 0.9873 - accuracy: 0.6235 - val_loss: 2.0541 - val_accuracy: 0.5300\n",
      "Epoch 163/200\n",
      "2000/2000 [==============================] - 1s 470us/step - loss: 1.0296 - accuracy: 0.6155 - val_loss: 2.0523 - val_accuracy: 0.5280\n",
      "Epoch 164/200\n",
      "2000/2000 [==============================] - 1s 450us/step - loss: 0.9980 - accuracy: 0.6280 - val_loss: 2.0529 - val_accuracy: 0.5280\n",
      "Epoch 165/200\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.9835 - accuracy: 0.6360 - val_loss: 2.0547 - val_accuracy: 0.5240\n",
      "Epoch 166/200\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 0.9907 - accuracy: 0.6430 - val_loss: 2.0544 - val_accuracy: 0.5220\n",
      "Epoch 167/200\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 0.9814 - accuracy: 0.6330 - val_loss: 2.0550 - val_accuracy: 0.5220\n",
      "Epoch 168/200\n",
      "2000/2000 [==============================] - 1s 516us/step - loss: 0.9459 - accuracy: 0.6605 - val_loss: 2.0578 - val_accuracy: 0.5180\n",
      "Epoch 169/200\n",
      "2000/2000 [==============================] - 1s 446us/step - loss: 0.9715 - accuracy: 0.6405 - val_loss: 2.0591 - val_accuracy: 0.5240\n",
      "Epoch 170/200\n",
      "2000/2000 [==============================] - 1s 430us/step - loss: 0.9859 - accuracy: 0.6335 - val_loss: 2.0620 - val_accuracy: 0.5260\n",
      "Epoch 171/200\n",
      "2000/2000 [==============================] - 1s 471us/step - loss: 0.9862 - accuracy: 0.6410 - val_loss: 2.0585 - val_accuracy: 0.5300\n",
      "Epoch 172/200\n",
      "2000/2000 [==============================] - 1s 506us/step - loss: 0.9734 - accuracy: 0.6330 - val_loss: 2.0551 - val_accuracy: 0.5300\n",
      "Epoch 173/200\n",
      "2000/2000 [==============================] - 1s 507us/step - loss: 0.9846 - accuracy: 0.6340 - val_loss: 2.0570 - val_accuracy: 0.5280\n",
      "Epoch 174/200\n",
      "2000/2000 [==============================] - 1s 498us/step - loss: 0.9919 - accuracy: 0.6340 - val_loss: 2.0573 - val_accuracy: 0.5300\n",
      "Epoch 175/200\n",
      "2000/2000 [==============================] - 1s 473us/step - loss: 0.9742 - accuracy: 0.6370 - val_loss: 2.0575 - val_accuracy: 0.5280\n",
      "Epoch 176/200\n",
      "2000/2000 [==============================] - 1s 485us/step - loss: 0.9546 - accuracy: 0.6500 - val_loss: 2.0565 - val_accuracy: 0.5280\n",
      "Epoch 177/200\n",
      "2000/2000 [==============================] - 1s 481us/step - loss: 0.9869 - accuracy: 0.6345 - val_loss: 2.0563 - val_accuracy: 0.5280\n",
      "Epoch 178/200\n",
      "2000/2000 [==============================] - 1s 479us/step - loss: 1.0094 - accuracy: 0.6385 - val_loss: 2.0561 - val_accuracy: 0.5280\n",
      "Epoch 179/200\n",
      "2000/2000 [==============================] - 1s 474us/step - loss: 0.9704 - accuracy: 0.6480 - val_loss: 2.0573 - val_accuracy: 0.5300\n",
      "Epoch 180/200\n",
      "2000/2000 [==============================] - 1s 486us/step - loss: 0.9859 - accuracy: 0.6280 - val_loss: 2.0564 - val_accuracy: 0.5300\n",
      "Epoch 181/200\n",
      "2000/2000 [==============================] - 1s 464us/step - loss: 1.0026 - accuracy: 0.6235 - val_loss: 2.0559 - val_accuracy: 0.5280\n",
      "Epoch 182/200\n",
      "2000/2000 [==============================] - 1s 478us/step - loss: 0.9907 - accuracy: 0.6150 - val_loss: 2.0596 - val_accuracy: 0.5260\n",
      "Epoch 183/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 1.0174 - accuracy: 0.6200 - val_loss: 2.0603 - val_accuracy: 0.5280\n",
      "Epoch 184/200\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 1.0122 - accuracy: 0.6200 - val_loss: 2.0588 - val_accuracy: 0.5280\n",
      "Epoch 185/200\n",
      "2000/2000 [==============================] - 1s 465us/step - loss: 1.0085 - accuracy: 0.6175 - val_loss: 2.0572 - val_accuracy: 0.5280\n",
      "Epoch 186/200\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.9755 - accuracy: 0.6440 - val_loss: 2.0540 - val_accuracy: 0.5240\n",
      "Epoch 187/200\n",
      "2000/2000 [==============================] - 1s 460us/step - loss: 1.0238 - accuracy: 0.6255 - val_loss: 2.0547 - val_accuracy: 0.5240\n",
      "Epoch 188/200\n",
      "2000/2000 [==============================] - 1s 484us/step - loss: 0.9574 - accuracy: 0.6285 - val_loss: 2.0566 - val_accuracy: 0.5260\n",
      "Epoch 189/200\n",
      "2000/2000 [==============================] - 1s 489us/step - loss: 0.9989 - accuracy: 0.6290 - val_loss: 2.0593 - val_accuracy: 0.5240\n",
      "Epoch 190/200\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 0.9731 - accuracy: 0.6380 - val_loss: 2.0598 - val_accuracy: 0.5260\n",
      "Epoch 191/200\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 1.0027 - accuracy: 0.6195 - val_loss: 2.0596 - val_accuracy: 0.5320\n",
      "Epoch 192/200\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.9495 - accuracy: 0.6570 - val_loss: 2.0600 - val_accuracy: 0.5320\n",
      "Epoch 193/200\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.9854 - accuracy: 0.6310 - val_loss: 2.0599 - val_accuracy: 0.5300\n",
      "Epoch 194/200\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.9803 - accuracy: 0.6485 - val_loss: 2.0617 - val_accuracy: 0.5300\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 461us/step - loss: 1.0062 - accuracy: 0.6370 - val_loss: 2.0631 - val_accuracy: 0.5280\n",
      "Epoch 196/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 1.0081 - accuracy: 0.6130 - val_loss: 2.0633 - val_accuracy: 0.5280\n",
      "Epoch 197/200\n",
      "2000/2000 [==============================] - 1s 479us/step - loss: 0.9874 - accuracy: 0.6235 - val_loss: 2.0622 - val_accuracy: 0.5260\n",
      "Epoch 198/200\n",
      "2000/2000 [==============================] - 1s 447us/step - loss: 0.9884 - accuracy: 0.6345 - val_loss: 2.0639 - val_accuracy: 0.5260\n",
      "Epoch 199/200\n",
      "2000/2000 [==============================] - 1s 479us/step - loss: 0.9607 - accuracy: 0.6375 - val_loss: 2.0653 - val_accuracy: 0.5240\n",
      "Epoch 200/200\n",
      "2000/2000 [==============================] - 1s 466us/step - loss: 0.9767 - accuracy: 0.6345 - val_loss: 2.0652 - val_accuracy: 0.5240\n",
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 3s 2ms/step - loss: 0.9924 - accuracy: 0.6315 - val_loss: 2.0652 - val_accuracy: 0.5240\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 1s 348us/step - loss: 1.0022 - accuracy: 0.6215 - val_loss: 2.0669 - val_accuracy: 0.5240\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 1s 332us/step - loss: 1.0003 - accuracy: 0.6350 - val_loss: 2.0659 - val_accuracy: 0.5240\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 1s 350us/step - loss: 1.0251 - accuracy: 0.6290 - val_loss: 2.0648 - val_accuracy: 0.5240\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 1s 325us/step - loss: 1.0404 - accuracy: 0.6200 - val_loss: 2.0637 - val_accuracy: 0.5240\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 1s 355us/step - loss: 1.0423 - accuracy: 0.6125 - val_loss: 2.0643 - val_accuracy: 0.5240\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 1s 363us/step - loss: 0.9982 - accuracy: 0.6485 - val_loss: 2.0632 - val_accuracy: 0.5240\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 1.0086 - accuracy: 0.6210 - val_loss: 2.0652 - val_accuracy: 0.5240\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.9712 - accuracy: 0.6450 - val_loss: 2.0628 - val_accuracy: 0.5240\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 1s 339us/step - loss: 0.9830 - accuracy: 0.6295 - val_loss: 2.0613 - val_accuracy: 0.5240\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9764 - accuracy: 0.64 - 1s 310us/step - loss: 0.9748 - accuracy: 0.6465 - val_loss: 2.0615 - val_accuracy: 0.5240\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 1.0021 - accuracy: 0.6125 - val_loss: 2.0595 - val_accuracy: 0.5240\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.9635 - accuracy: 0.6315 - val_loss: 2.0583 - val_accuracy: 0.5260\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.9564 - accuracy: 0.6315 - val_loss: 2.0579 - val_accuracy: 0.5260\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 0.9967 - accuracy: 0.6325 - val_loss: 2.0571 - val_accuracy: 0.5240\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 1s 464us/step - loss: 0.9798 - accuracy: 0.6240 - val_loss: 2.0561 - val_accuracy: 0.5260\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 1s 469us/step - loss: 0.9705 - accuracy: 0.6435 - val_loss: 2.0554 - val_accuracy: 0.5260\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 1s 465us/step - loss: 0.9667 - accuracy: 0.6315 - val_loss: 2.0540 - val_accuracy: 0.5260\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.9598 - accuracy: 0.6370 - val_loss: 2.0546 - val_accuracy: 0.5240\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 1s 429us/step - loss: 1.0335 - accuracy: 0.6275 - val_loss: 2.0550 - val_accuracy: 0.5260\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 1s 421us/step - loss: 1.0026 - accuracy: 0.6225 - val_loss: 2.0538 - val_accuracy: 0.5260\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.9984 - accuracy: 0.6360 - val_loss: 2.0542 - val_accuracy: 0.5240\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 1s 476us/step - loss: 1.0419 - accuracy: 0.6165 - val_loss: 2.0522 - val_accuracy: 0.5240\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 1s 488us/step - loss: 0.9623 - accuracy: 0.6350 - val_loss: 2.0531 - val_accuracy: 0.5240\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 1s 443us/step - loss: 0.9999 - accuracy: 0.6250 - val_loss: 2.0541 - val_accuracy: 0.5240\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 1.0004 - accuracy: 0.6255 - val_loss: 2.0543 - val_accuracy: 0.5300\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 1.0342 - accuracy: 0.6170 - val_loss: 2.0546 - val_accuracy: 0.5300\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 1s 389us/step - loss: 0.9627 - accuracy: 0.6460 - val_loss: 2.0552 - val_accuracy: 0.5240\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 1s 414us/step - loss: 0.9945 - accuracy: 0.6265 - val_loss: 2.0561 - val_accuracy: 0.5260\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 1s 406us/step - loss: 1.0101 - accuracy: 0.6250 - val_loss: 2.0541 - val_accuracy: 0.5260\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 1s 410us/step - loss: 1.0011 - accuracy: 0.6365 - val_loss: 2.0532 - val_accuracy: 0.5260\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 1s 420us/step - loss: 0.9553 - accuracy: 0.6455 - val_loss: 2.0528 - val_accuracy: 0.5260\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 1s 444us/step - loss: 0.9441 - accuracy: 0.6460 - val_loss: 2.0538 - val_accuracy: 0.5260\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.9783 - accuracy: 0.6320 - val_loss: 2.0560 - val_accuracy: 0.5280\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.9791 - accuracy: 0.6250 - val_loss: 2.0561 - val_accuracy: 0.5280\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 1s 491us/step - loss: 0.9849 - accuracy: 0.6435 - val_loss: 2.0563 - val_accuracy: 0.5280\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 1s 518us/step - loss: 1.0544 - accuracy: 0.6275 - val_loss: 2.0573 - val_accuracy: 0.5280\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 1.0147 - accuracy: 0.6215 - val_loss: 2.0577 - val_accuracy: 0.5280\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 1s 484us/step - loss: 0.9820 - accuracy: 0.6340 - val_loss: 2.0577 - val_accuracy: 0.5280\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.9748 - accuracy: 0.6420 - val_loss: 2.0561 - val_accuracy: 0.5280\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 1s 462us/step - loss: 0.9371 - accuracy: 0.6470 - val_loss: 2.0555 - val_accuracy: 0.5280\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 1s 484us/step - loss: 0.9912 - accuracy: 0.6300 - val_loss: 2.0566 - val_accuracy: 0.5280\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 1s 478us/step - loss: 0.9736 - accuracy: 0.6365 - val_loss: 2.0562 - val_accuracy: 0.5280\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 1s 486us/step - loss: 1.0013 - accuracy: 0.6220 - val_loss: 2.0582 - val_accuracy: 0.5260\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 1s 460us/step - loss: 1.0480 - accuracy: 0.6035 - val_loss: 2.0581 - val_accuracy: 0.5320\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 1s 452us/step - loss: 1.0135 - accuracy: 0.6375 - val_loss: 2.0572 - val_accuracy: 0.5300\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 1s 488us/step - loss: 1.0297 - accuracy: 0.6150 - val_loss: 2.0580 - val_accuracy: 0.5320\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 1s 528us/step - loss: 1.0023 - accuracy: 0.6320 - val_loss: 2.0594 - val_accuracy: 0.5300\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 1s 532us/step - loss: 0.9812 - accuracy: 0.6345 - val_loss: 2.0599 - val_accuracy: 0.5320\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 506us/step - loss: 0.9812 - accuracy: 0.6365 - val_loss: 2.0592 - val_accuracy: 0.5320\n",
      "--- 806.7281172275543 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.01),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data=[X_test,y_test],epochs=50, batch_size=300)\n",
    "# print('lr=0.01, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data=[X_test,y_test],epochs=200, batch_size=250)\n",
    "# print('lr=0.001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data=[X_test,y_test],epochs=200, batch_size=200)\n",
    "# print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.00001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data=[X_test,y_test],epochs=200, batch_size=200)\n",
    "# print('lr=0.00001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data=[X_test,y_test],epochs=200, batch_size=250)\n",
    "# print('lr=0.001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.0001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data=[X_test,y_test],epochs=200, batch_size=200)\n",
    "# print('lr=0.0001, train complete')\n",
    "model.compile(loss='categorical_crossentropy',optimizer = Adam(lr=0.00001),metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data=[X_test,y_test],epochs=50, batch_size=200)\n",
    "# print('lr=0.00001, train complete')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1503237f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pred.argmax(axis=1)\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(model,'../output/nn.m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
